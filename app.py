import streamlit as st
import pandas as pd
import os
from datetime import datetime, date, timezone, timedelta
import io
import math
import boto3

KST = timezone(timedelta(hours=9))

def now_kst_str() -> str:
    """í•œêµ­ ì‹œê°„(KST) í˜„ì¬ ì‹œê°ì„ 'YYYY-MM-DD HH:MM:SS' ë¬¸ìì—´ë¡œ ë°˜í™˜."""
    return datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    
# ==============================
# ì‚¬ìš©ì ê³„ì • (ë¡œê·¸ì¸ìš©)
# ==============================
USER_ACCOUNTS = {
    "ps": {"password": "0000", "display_name": "ì„í•„ì„ "},
    "by": {"password": "0000", "display_name": "ê°•ë´‰ì—°"},
    "hn": {"password": "0000", "display_name": "ê¹€í•œë‚˜"},
}

# ==============================
# ê¸°ë³¸ ì„¤ì • + CSS
# ==============================
st.set_page_config(page_title="ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

st.markdown(
    """
    <style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ ì¹¸ì€ í™”ë©´ í­ê³¼ ìƒê´€ì—†ì´ ê³ ì • í¬ê¸° + í™•ì¥ ê¸ˆì§€ */
    .stTextInput > div {
        flex: 0 0 auto !important;
    }
    .stTextInput > div > div > input {
        width: 160px !important;
        max-width: 160px !important;
        min-width: 160px !important;
    }

    /* ğŸ”¹ st.form í…Œë‘ë¦¬/ë°°ê²½ ì œê±° */
    .stForm {
        border: none !important;
        box-shadow: none !important;
        padding: 0 !important;
        background-color: transparent !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


CSV_PATH = "bulk_drums_extended.csv"   # í’ˆëª©ì½”ë“œ~í˜„ì¬ìœ„ì¹˜ê¹Œì§€ ë“¤ì–´ìˆëŠ” íŒŒì¼
PRODUCTION_FILE = "production.xlsx"    # ìì‚¬: ì‘ì—…ë²ˆí˜¸ â†’ ë¡œíŠ¸/ì œì¡°ëŸ‰
MOVE_LOG_CSV = "bulk_move_log.csv"     # ì´ë™ ì´ë ¥
RECEIVE_FILE = "receive.xlsx"          # ì‚¬ê¸‰: ì…í•˜ë²ˆí˜¸ ê¸°ë°˜
STOCK_FILE = "stock.xlsx"              # ì „ì‚° ì¬ê³ 

# ======
# ì´ë™ê¸°ë¡ ë²„íŠ¼ í¬ê¸°
# ======
# HTML ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬
query_params = st.query_params

if "log_prev" in query_params:
    if ss["log_page"] > 1:
        ss["log_page"] -= 1
    st.query_params.clear()   # í´ë¦°
    st.rerun()

if "log_next" in query_params:
    if ss["log_page"] < total_pages:
        ss["log_page"] += 1
    st.query_params.clear()
    st.rerun()

st.markdown(
    """
    <style>
    /* ì´ë™ ì´ë ¥ í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ë§Œ ì•½ê°„ ì‘ê²Œ */
    div.stButton > button[kind="secondary"] {
        font-size: 0.8rem !important;
        padding: 0.2rem 0.6rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ==============================
# S3 ì—°ë™ ì„¤ì •
# ==============================
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "bulk-system-enc")
S3_PREFIX = os.getenv("S3_PREFIX", "bulk-app/")  # í´ë” ê²½ë¡œ


def s3_enabled() -> bool:
    return bool(S3_BUCKET_NAME)


@st.cache_resource(show_spinner=False)
def get_s3_client():
    try:
        session = boto3.session.Session()
        client = session.client("s3")
        return client
    except Exception:
        return None


def _s3_key(filename: str) -> str:
    """
    S3ì—ì„œ ì €ì¥ë˜ëŠ” ê²½ë¡œë¥¼ ê²°ì •.
    ì˜ˆ: filename="bulk_drums_extended.csv" â†’ "bulk-app/bulk_drums_extended.csv"
    """
    prefix = S3_PREFIX.rstrip("/")
    return f"{prefix}/{filename}" if prefix else filename


def s3_upload_bytes(filename: str, data: bytes):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ë°”ì´íŠ¸ë¥¼ S3ì— ì €ì¥.
    filename: ë¡œì»¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” íŒŒì¼ëª…ì„ ê·¸ëŒ€ë¡œ ë„˜ê¸°ë©´ _s3_keyë¡œ S3 ê²½ë¡œ ë³€í™˜.
    """
    if not s3_enabled():
        return
    client = get_s3_client()
    if not client:
        return
    try:
        client.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=_s3_key(filename),
            Body=data,
        )
    except Exception:
        # S3 ì˜¤ë¥˜ê°€ ë‚˜ë”ë¼ë„ ì•± ì „ì²´ëŠ” ì£½ì§€ ì•Šê²Œ ì¡°ìš©íˆ ë¬´ì‹œ
        pass


def s3_download_bytes(filename: str):
    """
    S3ì—ì„œ íŒŒì¼ì„ ì½ì–´ì™€ì„œ bytesë¡œ ë°˜í™˜.
    ì—†ê±°ë‚˜ ì˜¤ë¥˜ë©´ None ë°˜í™˜.
    """
    if not s3_enabled():
        return None
    client = get_s3_client()
    if not client:
        return None
    try:
        resp = client.get_object(
            Bucket=S3_BUCKET_NAME,
            Key=_s3_key(filename),
        )
        return resp["Body"].read()
    except Exception:
        return None


# ==============================
# ê³µí†µ ìœ í‹¸ (ì—…ë¡œë“œ/ë¡œì»¬/S3 ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_drums_core(bulk_bytes):
    """bulk_drums_extended.csv ë¡œë“œ (ì„¸ì…˜ ì—…ë¡œë“œ > ë¡œì»¬ > S3 ìˆœì„œ)."""
    # 1) ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©
    if bulk_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(bulk_bytes))
        except Exception as e:
            st.error(f"ì—…ë¡œë“œí•œ bulk_drums_extended.csvë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ",
                    "í’ˆëª…",
                    "ë¡œíŠ¸ë²ˆí˜¸",
                    "ì œí’ˆë¼ì¸",
                    "ì œì¡°ì¼ì",
                    "ìƒíƒœ",
                    "í†µë²ˆí˜¸",
                    "í†µìš©ëŸ‰",
                    "í˜„ì¬ìœ„ì¹˜",
                ]
            )
    # 2) ì—…ë¡œë“œ íŒŒì¼ì´ ì—†ê³ , ë¡œì»¬ CSVê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
    elif os.path.exists(CSV_PATH):
        try:
            df = pd.read_csv(CSV_PATH)
        except Exception as e:
            st.error(f"CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ",
                    "í’ˆëª…",
                    "ë¡œíŠ¸ë²ˆí˜¸",
                    "ì œí’ˆë¼ì¸",
                    "ì œì¡°ì¼ì",
                    "ìƒíƒœ",
                    "í†µë²ˆí˜¸",
                    "í†µìš©ëŸ‰",
                    "í˜„ì¬ìœ„ì¹˜",
                ]
            )
    # 3) ë¡œì»¬ë„ ì—†ìœ¼ë©´ S3ì—ì„œ ì‹œë„
    else:
        s3_bytes = s3_download_bytes(CSV_PATH)
        if s3_bytes is not None:
            try:
                df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ bulk_drums_extended.csvë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame(
                    columns=[
                        "í’ˆëª©ì½”ë“œ",
                        "í’ˆëª…",
                        "ë¡œíŠ¸ë²ˆí˜¸",
                        "ì œí’ˆë¼ì¸",
                        "ì œì¡°ì¼ì",
                        "ìƒíƒœ",
                        "í†µë²ˆí˜¸",
                        "í†µìš©ëŸ‰",
                        "í˜„ì¬ìœ„ì¹˜",
                    ]
                )
        else:
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ",
                    "í’ˆëª…",
                    "ë¡œíŠ¸ë²ˆí˜¸",
                    "ì œí’ˆë¼ì¸",
                    "ì œì¡°ì¼ì",
                    "ìƒíƒœ",
                    "í†µë²ˆí˜¸",
                    "í†µìš©ëŸ‰",
                    "í˜„ì¬ìœ„ì¹˜",
                ]
            )

    required_cols = [
        "í’ˆëª©ì½”ë“œ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "ì œí’ˆë¼ì¸",
        "ì œì¡°ì¼ì",
        "ìƒíƒœ",
        "í†µë²ˆí˜¸",
        "í†µìš©ëŸ‰",
        "í˜„ì¬ìœ„ì¹˜",
    ]
    for c in required_cols:
        if c not in df.columns:
            st.error(f"CSVì— '{c}' ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ì—ì„œ ë‹¤ì‹œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.")
            return pd.DataFrame(columns=required_cols)

    df["í†µë²ˆí˜¸"] = pd.to_numeric(df["í†µë²ˆí˜¸"], errors="coerce").fillna(0).astype(int)
    df["í†µìš©ëŸ‰"] = pd.to_numeric(df["í†µìš©ëŸ‰"], errors="coerce").fillna(0.0).astype(float)

    def norm_loc(x: str) -> str:
        if pd.isna(x):
            return ""
        s = str(x).strip()
        if "-" not in s:
            if s in ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"]:
                return f"{s}-A1"
        return s

    df["í˜„ì¬ìœ„ì¹˜"] = df["í˜„ì¬ìœ„ì¹˜"].apply(norm_loc)

    return df


def load_drums() -> pd.DataFrame:
    """ì„¸ì…˜ ìƒíƒœë¥¼ ê°ì•ˆí•´ì„œ bulk DFë¥¼ ê°€ì ¸ì˜¤ëŠ” ì™¸ë¶€ìš© í•¨ìˆ˜."""
    ss = st.session_state
    bulk_bytes = ss.get("bulk_csv_bytes", None)
    return _load_drums_core(bulk_bytes)


def save_drums(df: pd.DataFrame):
    """
    í˜„ì¬ DFë¥¼ bulk_drums_extended.csvë¡œ ì €ì¥.
    - ì„¸ì…˜ ë©”ëª¨ë¦¬(ì—…ë¡œë“œ ë°©ì‹) ê°±ì‹ 
    - ë¡œì»¬ íŒŒì¼ë„ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸° (ë¡œì»¬ ì‹¤í–‰ìš©)
    - S3ì—ë„ ì—…ë¡œë“œ
    """
    # 1) ì„¸ì…˜ ë©”ëª¨ë¦¬ ê°±ì‹ 
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()
    st.session_state["bulk_csv_bytes"] = data

    # ìºì‹œ ë¬´íš¨í™”
    _load_drums_core.clear()

    # 2) ë¡œì»¬ CSVë¡œë„ ì €ì¥ (ìˆìœ¼ë©´)
    try:
        df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
    except Exception:
        # Cloud í™˜ê²½ì—ì„œëŠ” ë³´í†µ ê¶Œí•œ/ê²½ë¡œê°€ ì—†ìœ¼ë‹ˆ ì¡°ìš©íˆ ë¬´ì‹œ
        pass

    # 3) S3 ì—…ë¡œë“œ
    s3_upload_bytes(CSV_PATH, data)


@st.cache_data(show_spinner=False)
def _load_production_core(prod_bytes):
    if prod_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(prod_bytes))
        except Exception:
            return pd.DataFrame()
    elif os.path.exists(PRODUCTION_FILE):
        try:
            df = pd.read_excel(PRODUCTION_FILE)
        except Exception:
            return pd.DataFrame()
    else:
        # ë¡œì»¬ë„ ì—†ìœ¼ë©´ S3 ì‹œë„
        s3_bytes = s3_download_bytes(PRODUCTION_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception:
                return pd.DataFrame()
        else:
            return pd.DataFrame()

    required = ["ì‘ì—…ë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "LOTNO", "ì§€ì‹œìˆ˜ëŸ‰", "ì œì¡°ëŸ‰", "ì‘ì—…ì¼ì"]
    for c in required:
        if c not in df.columns:
            return pd.DataFrame()
    return df[required].copy()


def load_production():
    ss = st.session_state
    prod_bytes = ss.get("prod_xlsx_bytes", None)
    return _load_production_core(prod_bytes)


@st.cache_data(show_spinner=False)
def _load_receive_core(recv_bytes):
    if recv_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(recv_bytes))
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(RECEIVE_FILE):
        try:
            df = pd.read_excel(RECEIVE_FILE)
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(RECEIVE_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ receive.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame()
        else:
            return pd.DataFrame()
    return df


def load_receive():
    ss = st.session_state
    recv_bytes = ss.get("recv_xlsx_bytes", None)
    return _load_receive_core(recv_bytes)


@st.cache_data(show_spinner=False)
def _load_stock_core(stock_bytes):
    if stock_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(stock_bytes))
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(STOCK_FILE):
        try:
            df = pd.read_excel(STOCK_FILE)
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(STOCK_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ stock.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame()
        else:
            return pd.DataFrame()
    return df


def load_stock() -> pd.DataFrame:
    ss = st.session_state
    stock_bytes = ss.get("stock_xlsx_bytes", None)
    return _load_stock_core(stock_bytes)


# ==============================
# ìì‚¬ í’ˆë²ˆë³„ ì œí’ˆë¼ì¸ ìë™ ë¶„ë¥˜
# ==============================
NEEDLESHOT_CODES = {
    "3VTCLOS-010",
    "3VTCLOS-006",
    "3VTCLOS-007",
    "3VTCLOS-008",
    "3VTCLOS-011",
    "3VTCLOS-013",
    "3VTCLOS-047",
}

FACIAL_CODES = {
    "3VTCLOS-023",
    "3VTCLOS-024",
    "3VTCLOS-060",
    "3VTCLOS-061",
    "3VTCLOS-062",
    "3VTCLOS-063",
    "3VTCLOS-064",
    "3VTCLOS-065",
}


def classify_product_line(item_code: str) -> str:
    if not isinstance(item_code, str):
        return ""
    code = item_code.strip()
    if code in NEEDLESHOT_CODES:
        return "ë¦¬ë“¤ìƒ·"
    if code in FACIAL_CODES:
        return "í˜ì´ì…œ"
    return ""


def add_tat_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    dfì— 'TAT' ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ ì œì¡°ì¼ìë¡œë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ê²½ê³¼ ê°œì›” ìˆ˜ë¥¼ ì±„ì›Œì¤€ë‹¤.
    - ì œì¡°ì¼ìê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒŒì‹± ë¶ˆê°€í•˜ë©´ TATëŠ” <NA>
    """
    if "ì œì¡°ì¼ì" not in df.columns:
        df["TAT"] = pd.NA
        return df

    # ì œì¡°ì¼ìë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ (ì—¬ëŸ¬ í¬ë§· í—ˆìš©)
    mfg_dt = pd.to_datetime(df["ì œì¡°ì¼ì"], errors="coerce")

    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = date.today()

    # ì—°/ì›” ì°¨ì´ë¡œ ê°œì›” ìˆ˜ ê³„ì‚°
    years_diff = today.year - mfg_dt.dt.year
    months_diff = today.month - mfg_dt.dt.month
    tat_months = years_diff * 12 + months_diff

    # ìŒìˆ˜ ë°©ì§€
    tat_months = tat_months.clip(lower=0)

    # ë‚ ì§œ ì—†ëŠ” ê³³ì€ NAë¡œ
    tat_months = tat_months.where(~mfg_dt.isna(), pd.NA)

    # nullable ì •ìˆ˜ë¡œ ì €ì¥
    df = df.copy()
    df["TAT"] = tat_months.astype("Int64")

    return df


def generate_drums(prod_qty_kg: float):
    """ì œì¡°ëŸ‰(kg)ì„ ë°›ì•„ì„œ í†µë²ˆí˜¸/ìš©ëŸ‰ì„ ìë™ ìƒì„±."""
    if prod_qty_kg is None:
        return []

    try:
        qty = float(prod_qty_kg)
    except Exception:
        return []

    if qty <= 0:
        return []

    drums = []
    if qty < 200:
        drums.append({"í†µë²ˆí˜¸": 1, "í†µìš©ëŸ‰": qty})
        return drums

    full = int(qty // 1000)
    rem = qty % 1000

    for i in range(full):
        drums.append({"í†µë²ˆí˜¸": i + 1, "í†µìš©ëŸ‰": 1000})

    if rem > 0:
        drums.append({"í†µë²ˆí˜¸": full + 1, "í†µìš©ëŸ‰": rem})

    return drums


def ensure_lot_in_csv(
    df: pd.DataFrame,
    lot: str,
    item_code: str,
    item_name: str,
    line: str,
    mfg_date: str,
    initial_status: str = "ìƒì‚°ëŒ€ê¸°",
    prod_qty: float = None,
) -> pd.DataFrame:
    """ì—†ë˜ ë¡œíŠ¸ë©´ í†µ ìë™ ìƒì„±í•´ì„œ CSVì— ì¶”ê°€."""
    if (df["ë¡œíŠ¸ë²ˆí˜¸"] == lot).any():
        return df

    drums = generate_drums(prod_qty)
    if not drums:
        return df

    new_rows = []
    for d in drums:
        new_rows.append(
            {
                "í’ˆëª©ì½”ë“œ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "ì œí’ˆë¼ì¸": line or "",
                "ì œì¡°ì¼ì": mfg_date or "",
                "ìƒíƒœ": initial_status or "ìƒì‚°ëŒ€ê¸°",
                "í†µë²ˆí˜¸": int(d["í†µë²ˆí˜¸"]),
                "í†µìš©ëŸ‰": float(d["í†µìš©ëŸ‰"]),
                "í˜„ì¬ìœ„ì¹˜": "ë¯¸ì§€ì •",
            }
        )

    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)
    return df


# ==============================
# ì´ë™ LOG ìœ í‹¸ (ID í¬í•¨, ì—…ë¡œë“œ/ì„¸ì…˜/S3 ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_move_log_core(move_bytes):
    """ì´ë™ ì´ë ¥ CSV ë¡œë“œ."""
    default_cols = [
        "ì‹œê°„",
        "ID",          # ì´ë™ ê¸°ë¡ ì‘ì„±ì (í‘œì‹œìš© ì´ë¦„)
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]

    if move_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(move_bytes))
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            df = pd.read_csv(MOVE_LOG_CSV)
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    else:
        s3_bytes = s3_download_bytes(MOVE_LOG_CSV)
        if s3_bytes is not None:
            try:
                df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ ì´ë™ ì´ë ¥ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame(columns=default_cols)
        else:
            return pd.DataFrame(columns=default_cols)

    # ì˜ˆì „ ë¡œê·¸ì— IDì—´ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë³´ì •
    for c in default_cols:
        if c not in df.columns:
            if c == "ID":
                df[c] = ""
            else:
                df[c] = pd.NA

    return df[default_cols]


def load_move_log() -> pd.DataFrame:
    ss = st.session_state
    move_bytes = ss.get("move_log_csv_bytes", None)
    return _load_move_log_core(move_bytes)

def save_move_log(df: pd.DataFrame):
    """
    ì´ë™ ì´ë ¥ DataFrame ì „ì²´ë¥¼ bulk_move_log.csv ë° ì„¸ì…˜/S3ì— ì €ì¥.
    (ê¸°ì¡´ ë‚´ìš©ì„ ìœ ì§€í•œ ì±„ ë®ì–´ì“°ê¸° ë°©ì‹ìœ¼ë¡œ ì „ì²´ ì €ì¥)
    """
    ss = st.session_state

    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()

    # ì„¸ì…˜ì— ë°˜ì˜
    ss["move_log_csv_bytes"] = data

    # ìºì‹œ í´ë¦¬ì–´
    _load_move_log_core.clear()

    # ë¡œì»¬ CSV ì €ì¥
    try:
        df.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
    except Exception:
        pass

    # S3 ì—…ë¡œë“œ
    s3_upload_bytes(MOVE_LOG_CSV, data)



def write_move_log(item_code: str, item_name: str, lot: str, drum_infos, from_zone: str, to_zone: str):
    """
    ì´ë™ ì´ë ¥ì„ bulk_move_log.csvì— ê¸°ë¡.
    drum_infos:
      - ì˜› í˜•ì‹: (í†µë²ˆí˜¸, moved_qty, old_qty, new_qty)
      - ìƒˆ í˜•ì‹: (í†µë²ˆí˜¸, moved_qty, old_qty, new_qty, old_loc)
    ID ì—´ì—ëŠ” ë¡œê·¸ì¸í•œ ì‚¬ìš©ìì˜ 'í‘œì‹œ ì´ë¦„'ì„ ë‚¨ê¸´ë‹¤.
    """
    if not drum_infos:
        return

    ss = st.session_state
    user_display_name = ss.get("user_name", "")

    ts = now_kst_str()  # ğŸ”¹ í•œêµ­ ì‹œê°„ ê¸°ì¤€

    rows = []
    for info in drum_infos:
        # ğŸ”¹ íŠœí”Œ ê¸¸ì´ì— ë”°ë¼ ë¶„ê¸° (ì˜› ë°ì´í„°ì™€ í˜¸í™˜)
        if len(info) == 4:
            drum_no, moved_qty, old_qty, new_qty = info
            old_loc = from_zone
        else:
            drum_no, moved_qty, old_qty, new_qty, old_loc = info

        rows.append(
            {
                "ì‹œê°„": ts,
                "ID": user_display_name,
                "í’ˆë²ˆ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "í†µë²ˆí˜¸": drum_no,
                "ë³€ê²½ ì „ ìš©ëŸ‰": old_qty,
                "ë³€ê²½ í›„ ìš©ëŸ‰": new_qty,
                "ë³€í™”ëŸ‰": moved_qty,
                "ë³€ê²½ ì „ ìœ„ì¹˜": old_loc,
                "ë³€ê²½ í›„ ìœ„ì¹˜": to_zone,
            }
        )

    new_df = pd.DataFrame(rows)

    # ê¸°ì¡´ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì„¸ì…˜/ë¡œì»¬/S3)
    if "move_log_csv_bytes" in ss:
        try:
            old_df = pd.read_csv(io.BytesIO(ss["move_log_csv_bytes"]))
        except Exception:
            old_df = pd.DataFrame()
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            old_df = pd.read_csv(MOVE_LOG_CSV)
        except Exception:
            old_df = pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(MOVE_LOG_CSV)
        if s3_bytes is not None:
            try:
                old_df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception:
                old_df = pd.DataFrame()
        else:
            old_df = pd.DataFrame()

    log_df = pd.concat([old_df, new_df], ignore_index=True)

    # 1) ì„¸ì…˜ì— ë‹¤ì‹œ ì €ì¥
    buf = io.BytesIO()
    log_df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()
    ss["move_log_csv_bytes"] = data

    _load_move_log_core.clear()

    # 2) ë¡œì»¬ CSVì—ë„ ì €ì¥ (ë¡œì»¬ ì‹¤í–‰ìš©)
    try:
        log_df.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
    except Exception:
        pass

    # 3) S3 ì—…ë¡œë“œ
    s3_upload_bytes(MOVE_LOG_CSV, data)


# ==============================
# ì—…ë¡œë“œ ì‹œê°„ í‘œì‹œ ìœ í‹¸  (S3 â†’ ë¡œì»¬ ìˆœìœ¼ë¡œ í™•ì¸)
# ==============================
from datetime import datetime as dt_for_caption


@st.cache_data(show_spinner=False, ttl=60)
def last_upload_caption(filename: str) -> str:
    """
    íŒŒì¼ì˜ ë§ˆì§€ë§‰ ì—…ë¡œë“œ ì‹œê°„ì„ KST(UTC+9) ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
    1) S3 â†’ 2) ë¡œì»¬ íŒŒì¼ â†’ 3) ì—†ìœ¼ë©´ í‘œì‹œ ì—†ìŒ
    """
    from datetime import timezone, timedelta, datetime as dt

    # KST timezone
    KST = timezone(timedelta(hours=9))

    # ------------------------
    # 1) S3 timestamp
    # ------------------------
    try:
        if s3_enabled():
            client = get_s3_client()
            if client:
                s3_path = _s3_key(filename)
                resp = client.head_object(Bucket=S3_BUCKET_NAME, Key=s3_path)

                lm = resp["LastModified"]     # timezone-aware datetime
                lm_kst = lm.astimezone(KST)   # ğŸ‘‰ KST ë¡œ ë³€í™˜

                return f"S3 ë§ˆì§€ë§‰ ìˆ˜ì •: {lm_kst.strftime('%Y-%m-%d %H:%M:%S')}"
    except Exception:
        pass

    # ------------------------
    # 2) Local file timestamp
    # ------------------------
    if os.path.exists(filename):
        try:
            ts = os.path.getmtime(filename)        # float (UTC ê¸°ì¤€ timestamp)
            lm_kst = dt.fromtimestamp(ts, KST)     # ğŸ‘‰ timestamp ë¥¼ KST ë¡œ ë³€í™˜
            return f"ë¡œì»¬ ë§ˆì§€ë§‰ ìˆ˜ì •: {lm_kst.strftime('%Y-%m-%d %H:%M:%S')}"
        except Exception:
            return "ë¡œì»¬ íŒŒì¼ ì‹œê°„ ì½ê¸° ì˜¤ë¥˜"

    # ------------------------
    # 3) No file
    # ------------------------
    return "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

# ==============================
# ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í™”ë©´ (ìµœì´ˆ 1íšŒìš©)
# ==============================
def render_file_loader():
    ss = st.session_state

    st.title("ğŸ“ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown(
        """
        Streamlit Cloud ë˜ëŠ” ì´ˆê¸° ì„¤ì • ì‹œ, GitHubì— ì˜¬ë¦¬ê¸° ì–´ë ¤ìš´ CSV/ì—‘ì…€ íŒŒì¼ë“¤ì„
        ì—¬ê¸°ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.

        ì•„ë˜ 4ê°œ íŒŒì¼ì€ **í•„ìˆ˜**ì´ê³ , ì´ë™ ì´ë ¥(`bulk_move_log.csv`)ì€ **ìˆìœ¼ë©´ ì—…ë¡œë“œ, ì—†ìœ¼ë©´ ìƒëµ**í•´ë„ ë©ë‹ˆë‹¤.
        """
    )

    col_left, col_right = st.columns(2)

    with col_left:
        bulk_file = st.file_uploader(
            "1) bulk_drums_extended.csv (í•„ìˆ˜)",
            type=["csv"],
            key="first_up_bulk",
        )
        st.caption(last_upload_caption(CSV_PATH))

        prod_file = st.file_uploader(
            "2) production.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        recv_file = st.file_uploader(
            "3) receive.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        stock_file = st.file_uploader(
            "4) stock.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

    with col_right:
        move_file = st.file_uploader(
            "5) bulk_move_log.csv (ì„ íƒ)",
            type=["csv"],
            key="first_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))
        st.caption("â€» ì—†ìœ¼ë©´ ì—…ë¡œë“œ ì•ˆ í•´ë„ ë©ë‹ˆë‹¤. ìƒˆ ë¡œê·¸ë¡œ ì‹œì‘í•´ìš”.")

    if st.button("ì—…ë¡œë“œ ì™„ë£Œ", key="first_upload_done"):
        missing = []
        if bulk_file is None:
            missing.append("bulk_drums_extended.csv")
        if prod_file is None:
            missing.append("production.xlsx")
        if recv_file is None:
            missing.append("receive.xlsx")
        if stock_file is None:
            missing.append("stock.xlsx")

        if missing:
            st.error("ë‹¤ìŒ í•„ìˆ˜ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”: " + ", ".join(missing))
            return

        # ---------- 1) ì—…ë¡œë“œ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ì„¸ì…˜ì— ì €ì¥ ----------
        bulk_bytes = bulk_file.read()
        prod_bytes = prod_file.read()
        recv_bytes = recv_file.read()
        stock_bytes = stock_file.read()
        move_bytes = move_file.read() if move_file is not None else None

        ss["bulk_csv_bytes"] = bulk_bytes
        ss["prod_xlsx_bytes"] = prod_bytes
        ss["recv_xlsx_bytes"] = recv_bytes
        ss["stock_xlsx_bytes"] = stock_bytes
        if move_bytes is not None:
            ss["move_log_csv_bytes"] = move_bytes

        # ğŸ”¹ S3 ì—…ë¡œë“œ (ì›ë³¸ ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ ë³´ê´€)
        s3_upload_bytes(CSV_PATH, bulk_bytes)
        s3_upload_bytes(PRODUCTION_FILE, prod_bytes)
        s3_upload_bytes(RECEIVE_FILE, recv_bytes)
        s3_upload_bytes(STOCK_FILE, stock_bytes)
        if move_bytes is not None:
            s3_upload_bytes(MOVE_LOG_CSV, move_bytes)

        # ---------- 2) ì„œë²„ ë¡œì»¬ íŒŒì¼ë¡œë„ ì €ì¥ (ì´í›„ ì„¸ì…˜ì—ì„œ ì¬ì‚¬ìš©) ----------
        try:
            _load_drums_core.clear()
            df_bulk = _load_drums_core(bulk_bytes)
            df_bulk.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
        except Exception:
            pass

        try:
            _load_production_core.clear()
            df_prod = _load_production_core(prod_bytes)
            df_prod.to_excel(PRODUCTION_FILE, index=False)
        except Exception:
            pass

        try:
            _load_receive_core.clear()
            df_recv = _load_receive_core(recv_bytes)
            df_recv.to_excel(RECEIVE_FILE, index=False)
        except Exception:
            pass

        try:
            _load_stock_core.clear()
            df_stock = _load_stock_core(stock_bytes)
            df_stock.to_excel(STOCK_FILE, index=False)
        except Exception:
            pass

        if move_bytes is not None:
            try:
                _load_move_log_core.clear()
                df_move = _load_move_log_core(move_bytes)
                df_move.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
            except Exception:
                pass

        # ---------- 3) í”Œë˜ê·¸ ì„¸íŒ… í›„ ë©”ì¸ìœ¼ë¡œ ----------
        ss["data_initialized"] = True

        st.success("íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.rerun()


# ==============================
# ë¡œê·¸ì¸ í™”ë©´
# ==============================
def render_login():
    ss = st.session_state

    # ğŸ”¹ ì´ì „ì— ë¡œê·¸ì¸í–ˆë˜ IDê°€ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ê¸°
    #    (ë‹¨, ì´ë²ˆ ì„¸ì…˜ì—ì„œ login_idê°€ ì•„ì§ ì•ˆ ë§Œë“¤ì–´ì¡Œì„ ë•Œë§Œ)
    if "last_login_id" in ss and "login_id" not in ss:
        ss["login_id"] = ss["last_login_id"]

    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë¡œê·¸ì¸")
    st.markdown("ì‘ì—… ì „ IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    # âœ… form ì‚¬ìš©: ì—”í„°ë¡œë„ ë¡œê·¸ì¸, ë²„íŠ¼ìœ¼ë¡œë„ ë¡œê·¸ì¸
    with st.form("login_form"):
        login_id = st.text_input("ID", key="login_id")
        login_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")

        login_submitted = st.form_submit_button("ë¡œê·¸ì¸")

    # í¼ ì œì¶œ(ì—”í„° ë˜ëŠ” ë²„íŠ¼ í´ë¦­) ì‹œ ë¡œê·¸ì¸ ì²˜ë¦¬
    if login_submitted:
        user = USER_ACCOUNTS.get((login_id or "").strip())

        if user and login_pw == user["password"]:
            ss["user_id"] = (login_id or "").strip()
            ss["user_name"] = user["display_name"]

            # ğŸ”¹ ë§ˆì§€ë§‰ì— ì„±ê³µì ìœ¼ë¡œ ë¡œê·¸ì¸í•œ ID ê¸°ì–µ
            ss["last_login_id"] = (login_id or "").strip()

            # í˜¹ì‹œ ì˜ˆì „ì— ì“°ë˜ ë¡œê·¸ì¸ ìœ ì§€ ê´€ë ¨ í‚¤ê°€ ìˆë‹¤ë©´ ì •ë¦¬ (ì„ íƒ ì‚¬í•­)
            for k in ["remember_me", "login_remember_checkbox"]:
                if k in ss:
                    del ss[k]

            st.success(f"{user['display_name']}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.")
            st.rerun()
        else:
            st.error("ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ==============================
# stock.xlsx ê¸°ë°˜ ì „ì‚° ì¬ê³  ìš”ì•½
# ==============================
def get_stock_summary(item_code: str, lot: str):
    """
    stock.xlsxì—ì„œ
      - í’ˆë²ˆ(Cì—´) == item_code
      - ë¡œíŠ¸ë²ˆí˜¸(Gì—´) == lot
      - ì‹¤ì¬ê³ ìˆ˜ëŸ‰(Kì—´) != 0
    ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì „ì‚°ì¬ê³ ë¥¼ ì°¾ì•„
      'ëŒ€ë¶„ë¥˜(ì°½ê³ ëª…) ì‹¤ì¬ê³ ìˆ˜ëŸ‰kg'
    í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•œë‹¤.
    """

    stock_df = load_stock()
    if stock_df is None or stock_df.empty:
        return None, ""

    if not item_code or not lot:
        return None, ""

    cols = list(stock_df.columns)
    # ì—´ ì´ë¦„ ì„¤ì • (í•œê¸€ì´ ì—†ìœ¼ë©´ ìœ„ì¹˜(index) ê¸°ì¤€)
    try:
        col_code = "ì°½ê³ ì½”ë“œ" if "ì°½ê³ ì½”ë“œ" in cols else cols[0]      # Aì—´
        col_name = "ì°½ê³ ëª…"   if "ì°½ê³ ëª…"   in cols else cols[1]      # Bì—´
        col_item = "í’ˆë²ˆ"     if "í’ˆë²ˆ"     in cols else cols[2]      # Cì—´
        col_lot  = "ë¡œíŠ¸ë²ˆí˜¸" if "ë¡œíŠ¸ë²ˆí˜¸" in cols else cols[6]      # Gì—´
        col_qty  = "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" if "ì‹¤ì¬ê³ ìˆ˜ëŸ‰" in cols else cols[10] # Kì—´
    except Exception:
        return None, ""

    df = stock_df.copy()

    # ë¹„êµìš©ìœ¼ë¡œ ë¬¸ìì—´ ì •ë¦¬
    df[col_item] = df[col_item].astype(str).str.strip().str.lower()
    df[col_lot]  = df[col_lot].astype(str).str.strip().str.lower()

    item_key = str(item_code).strip().lower()
    lot_key  = str(lot).strip().lower()

    # ì‹¤ì¬ê³ ìˆ˜ëŸ‰ numeric ë³€í™˜
    df[col_qty] = pd.to_numeric(df[col_qty], errors="coerce").fillna(0)

    # ì¡°ê±´ í•„í„°
    mask = (
        (df[col_item] == item_key) &
        (df[col_lot] == lot_key) &
        (df[col_qty] != 0)
    )
    sub = df[mask].copy()
    if sub.empty:
        return None, ""

    # ----- Aì—´ ì½”ë“œ ë¶„ë¥˜ -----
    JASA = {"WC301", "WC501", "WC502", "WC503", "WC504"}
    WAREHOUSE = {"WH201", "WH701", "WH301", "WH601", "WH401", "WH506"}
    BAD = {"WH001", "WH102", "WH202"}

    def classify(code):
        c = str(code).strip()
        if c in JASA:
            return "ìì‚¬"
        if c in WAREHOUSE:
            return "ì°½ê³ "
        if c in BAD:
            return "ë¶ˆëŸ‰"
        return "ì™¸ì£¼"

    sub["ì°½ê³ ì½”ë“œ"] = sub[col_code].astype(str).str.strip()
    sub["ì°½ê³ ëª…"] = sub[col_name].astype(str).str.strip()
    sub["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"] = pd.to_numeric(sub[col_qty], errors="coerce").fillna(0.0)
    sub["ëŒ€ë¶„ë¥˜"] = sub["ì°½ê³ ì½”ë“œ"].apply(classify)

    # ëŒ€ë¶„ë¥˜ + ì°½ê³ ëª… ê¸°ì¤€ í•©ì‚°
    grouped = (
        sub.groupby(["ëŒ€ë¶„ë¥˜", "ì°½ê³ ì½”ë“œ", "ì°½ê³ ëª…"], as_index=False)["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
        .sum()
    )

    # ìˆ˜ëŸ‰ í¬ë§·
    def fmt(v):
        f = float(v)
        return str(int(f)) if f.is_integer() else str(f)

    # ìµœì¢… í‘œì‹œ ë¬¸êµ¬ ìƒì„±: ëŒ€ë¶„ë¥˜(ì°½ê³ ëª…) ì‹¤ì¬ê³ ìˆ˜ëŸ‰kg
    grouped["í‘œì‹œ"] = grouped.apply(
        lambda r: f"{r['ëŒ€ë¶„ë¥˜']}({r['ì°½ê³ ëª…']}) {fmt(r['ì‹¤ì¬ê³ ìˆ˜ëŸ‰'])}kg",
        axis=1,
    )

    detail_df = grouped[["ëŒ€ë¶„ë¥˜", "ì°½ê³ ì½”ë“œ", "ì°½ê³ ëª…", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]].copy()
    detail_df = detail_df.sort_values(["ëŒ€ë¶„ë¥˜", "ì°½ê³ ì½”ë“œ"])

    summary_text = " / ".join(grouped["í‘œì‹œ"].tolist())

    return detail_df, summary_text


# ==============================
# íƒ­ 1: ì´ë™ - ì…ë ¥ê°’ ì´ˆê¸°í™”
# ==============================
def clear_move_inputs():
    """ì´ë™ íƒ­ ì…ë ¥ê°’ ì´ˆê¸°í™” ì½œë°±."""
    ss = st.session_state

    for k in [
        "mv_barcode",
        "mv_lot",
        "mv_last_lot",
        "mv_last_barcode",
        "mv_search_by_lot",
        "mv_searched_csv",
        "mv_show_stock_detail",
        "mv_show_move_history_here",
        "clicked_zone_csv",
        "mv_just_searched",
    ]:
        if k in ss:
            del ss[k]

# ==============================
# íƒ­ 1: ì´ë™
# ==============================
def render_tab_move():
    st.markdown("### ğŸ“¦ ë²Œí¬ ì´ë™")

    ss = st.session_state
    ss.setdefault("mv_searched_csv", False)
    ss.setdefault("mv_search_by_lot", False)
    ss.setdefault("mv_show_stock_detail", False)
    ss.setdefault("mv_show_move_history_here", False)

    # ================== ê²€ìƒ‰ í¼ (ì—”í„° + ë²„íŠ¼ ë‘˜ ë‹¤ ê°€ëŠ¥) ==================
    with st.form("move_search_form"):
        bulk_type = st.radio(
            "ë²Œí¬ êµ¬ë¶„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            ["ìì‚¬", "ì‚¬ê¸‰"],
            horizontal=True,
            key="mv_bulk_type_csv",
        )

        barcode_label = "ì‘ì—…ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”." if bulk_type == "ìì‚¬" else "ì…í•˜ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."

        # ğŸ”¹ ì…ë ¥ì¹¸ ë‘ ê°œ ë‚˜ë€íˆ (ì˜ˆì „ ë„ˆë¹„ ëŠë‚Œ ìœ ì§€)
        col_in1, col_in2, _sp = st.columns([0.45, 0.45, 2.5])
        with col_in1:
            barcode = st.text_input(
                barcode_label,
                key="mv_barcode",
                placeholder="ì˜ˆ: W24012345",
            )
        with col_in2:
            lot_input = st.text_input(
                "ë¡œíŠ¸ë²ˆí˜¸",
                key="mv_lot",
                placeholder="ì˜ˆ: 2E075K",
            )

        # ğŸ”¹ ì¡°íšŒí•˜ê¸° / ì´ˆê¸°í™” ë²„íŠ¼ í•œ ì¤„
        col_b1, col_b2, _sp2 = st.columns([1, 1, 6])
        with col_b1:
            search_submit = st.form_submit_button("ì¡°íšŒí•˜ê¸°", use_container_width=True)
        with col_b2:
            reset_submit = st.form_submit_button("ì´ˆê¸°í™”", use_container_width=True)

    # ----- ì´ˆê¸°í™” ë²„íŠ¼ -----
    if reset_submit:
        clear_move_inputs()
        st.rerun()

    # ----- ì¡°íšŒ ë²„íŠ¼: ì´ë²ˆ ì…ë ¥ì„ "ë§ˆì§€ë§‰ ì¡°íšŒ ì¡°ê±´"ìœ¼ë¡œ ì €ì¥ -----
    if search_submit:
        lot_val = (lot_input or "").strip()
        barcode_val = (barcode or "").strip()

        ss["mv_last_lot"] = lot_val
        ss["mv_last_barcode"] = barcode_val
        ss["mv_search_by_lot"] = bool(lot_val)  # ë¡œíŠ¸ê°€ ìˆìœ¼ë©´ ë¡œíŠ¸ ê¸°ì¤€ ì¡°íšŒ
        ss["mv_searched_csv"] = True
        ss["mv_just_searched"] = True  # ì´ë²ˆì— ë§‰ ì¡°íšŒí•¨ í‘œì‹œ

    # ğŸ”¹ í•œ ë²ˆë„ ì¡°íšŒí•œ ì  ì—†ìœ¼ë©´ ì•„ë˜ëŠ” ì•ˆ ê·¸ë¦¼
    if not ss.get("mv_searched_csv", False):
        return

    # ì—¬ê¸°ë¶€í„°ëŠ” "ë§ˆì§€ë§‰ ì¡°íšŒ ì¡°ê±´" ê¸°ë°˜ìœ¼ë¡œ í•­ìƒ í™”ë©´ ê·¸ë¦¼
    bulk_type = ss.get("mv_bulk_type_csv", "ìì‚¬")
    df = load_drums()
    prod_df = load_production()
    recv_df = load_receive()

    lot = ""
    item_code = ""
    item_name = ""
    prod_date = ""
    prod_qty = None
    line = ""
    barcode_used = ""
    lot_lower = ""

    search_by_lot = ss.get("mv_search_by_lot", False)

    # ================== ë¡œíŠ¸ / ì‘ì—…ë²ˆí˜¸ / ì…í•˜ë²ˆí˜¸ í•´ì„ ==================
    if search_by_lot:
        lot_input = (ss.get("mv_last_lot") or "").strip()
        if not lot_input:
            st.warning("ë¡œíŠ¸ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return

        lot = lot_input
        lot_lower = lot_input.lower()
        barcode_used = lot_input

    else:
        barcode_query = (ss.get("mv_last_barcode") or "").strip()
        if not barcode_query:
            st.warning("ì‘ì—…ë²ˆí˜¸/ì…í•˜ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return

        barcode_used = barcode_query
        q = barcode_query.lower()

        if bulk_type == "ìì‚¬":
            # ğŸŸ¡ ìì‚¬: ì‘ì—…ë²ˆí˜¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if prod_df.empty:
                st.error("production.xlsx íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ì„œ ì‘ì—…ë²ˆí˜¸ ê¸°ë°˜ ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            hit = prod_df[prod_df["ì‘ì—…ë²ˆí˜¸"].astype(str).str.lower() == q]
            if hit.empty:
                st.warning("í•´ë‹¹ ì‘ì—…ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]
            lot = str(r["LOTNO"])
            item_code = str(r["í’ˆë²ˆ"])
            item_name = str(r["í’ˆëª…"])
            prod_qty = float(r["ì œì¡°ëŸ‰"]) if not pd.isna(r["ì œì¡°ëŸ‰"]) else None
            prod_date = str(r["ì‘ì—…ì¼ì"])
            line = classify_product_line(item_code)

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

        else:
            # ğŸŸ¡ ì‚¬ê¸‰: ì…í•˜ë²ˆí˜¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if recv_df.empty:
                st.error("receive.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            if "ì…í•˜ë²ˆí˜¸" not in recv_df.columns:
                st.error("receive.xlsxì— 'ì…í•˜ë²ˆí˜¸' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            hit = recv_df[recv_df["ì…í•˜ë²ˆí˜¸"].astype(str).str.lower() == q]
            if hit.empty:
                st.warning("í•´ë‹¹ ì…í•˜ë²ˆí˜¸ë¥¼ receive.xlsxì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]
            if "í’ˆë²ˆ" not in recv_df.columns or "í’ˆëª…" not in recv_df.columns or "ë¡œíŠ¸ë²ˆí˜¸" not in recv_df.columns:
                st.error("receive.xlsxì— í’ˆë²ˆ/í’ˆëª…/ë¡œíŠ¸ë²ˆí˜¸ ê´€ë ¨ ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            item_code = str(r["í’ˆë²ˆ"])
            item_name = str(r["í’ˆëª…"])
            lot = str(r["ë¡œíŠ¸ë²ˆí˜¸"])

            if "ì…í•˜ëŸ‰" in recv_df.columns:
                prod_qty = float(r["ì…í•˜ëŸ‰"]) if not pd.isna(r["ì…í•˜ëŸ‰"]) else None
            else:
                prod_qty = None

            if "ì œì¡°ì¼ì" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ì¼ì"]) else str(r["ì œì¡°ì¼ì"])
            elif "ì œì¡°ë…„ì›”ì¼" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ë…„ì›”ì¼"]) else str(r["ì œì¡°ë…„ì›”ì¼"])
            else:
                prod_date = ""

            trade_type = str(r.get("ìœ /ë¬´ìƒ", "")).strip()
            if trade_type == "ìœ ìƒ":
                line = "ì‚¬ê¸‰(ìœ ìƒ)"
            elif trade_type == "ë¬´ìƒ":
                line = "ì‚¬ê¸‰(ë¬´ìƒ)"
            else:
                line = "ì‚¬ê¸‰"

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

        lot_lower = (lot or "").lower()

    # ---------- LOT ê¸°ì¤€ìœ¼ë¡œ CSV ì¡°íšŒ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) ----------
    df = load_drums()
    df["lot_lower"] = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
    lot_df = df[df["lot_lower"] == lot_lower].copy()

    if lot_df.empty:
        st.warning("CSVì—ì„œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ í†µ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ss["mv_searched_csv"] = False
        return

    combos = lot_df[["í’ˆëª©ì½”ë“œ", "í’ˆëª…"]].drop_duplicates().reset_index(drop=True)
    if len(combos) == 1:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])
    elif len(combos) > 1 and ss.get("mv_search_by_lot", False):
        st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì— ì—¬ëŸ¬ í’ˆëª…ì´ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        options = [
            f"{row['í’ˆëª©ì½”ë“œ']} / {row['í’ˆëª…']}"
            for _, row in combos.iterrows()
        ]
        selected_label = st.selectbox(
            "í’ˆëª…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            options,
            key=f"mv_lot_item_select_{lot}",
        )
        sel_idx = options.index(selected_label)
        item_code = str(combos.at[sel_idx, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[sel_idx, "í’ˆëª…"])
        lot_df = lot_df[
            (lot_df["í’ˆëª©ì½”ë“œ"].astype(str) == item_code)
            & (lot_df["í’ˆëª…"].astype(str) == item_name)
        ].copy()
    else:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])

    if not prod_date:
        dates = (
            lot_df["ì œì¡°ì¼ì"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if dates:
            prod_date = dates[0]

    if not line:
        lines = (
            lot_df["ì œí’ˆë¼ì¸"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if lines:
            line = lines[0]

    lot_df = lot_df.sort_values("í†µë²ˆí˜¸")

    loc_unique = lot_df["í˜„ì¬ìœ„ì¹˜"].dropna().unique().tolist()
    if len(loc_unique) == 1:
        current_zone = loc_unique[0]
    elif len(loc_unique) == 0:
        current_zone = "ë¯¸ì§€ì •"
    else:
        current_zone = "í˜¼í•©"

    stock_summary_df, stock_summary_text = get_stock_summary(item_code, lot)

    if stock_summary_text:  # ìš”ì•½ ë¬¸ìì—´ ìˆìœ¼ë©´ ê·¸ê±¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # ì˜ˆ: "ì°½ê³ (ë¶€ìì¬ì°½ê³ ) 10kg / ì™¸ì£¼(ìœ„ë“œë§˜) 20kg"
        stock_loc_display = stock_summary_text
    else:
        stock_loc_display = current_zone

    col_left2, col_right2 = st.columns(2)

    # ===== ì™¼ìª½: ì¡°íšŒ ì •ë³´ + í†µ ì„ íƒ =====
    with col_left2:
        st.markdown("### ğŸ§¾ ì¡°íšŒ ì •ë³´")
        st.success("ì¡°íšŒê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.markdown(
            f"""
            **ë²Œí¬ êµ¬ë¶„:** {bulk_type}  
            **ì‹ë³„ê°’:** {barcode_used}  
            **í’ˆëª©ì½”ë“œ:** {item_code}  
            **í’ˆëª…:** {item_name}  
            **ë¡œíŠ¸ë²ˆí˜¸:** {lot}  
            **ì œì¡°ì¼ì:** {prod_date}  
            """
        )

        # í˜„ì¬ ìœ„ì¹˜ + [ìƒì„¸ë³´ê¸°] + [ì´ë™ì´ë ¥]
        loc_col1, loc_col2 = st.columns([3, 2])
        with loc_col1:
            st.markdown(f"**í˜„ì¬ ìœ„ì¹˜(ì „ì‚° ê¸°ì¤€):** {stock_loc_display}")
        with loc_col2:
            b1_col, b_sp, b2_col = st.columns([1, 0.05, 1])
            with b1_col:
                if st.button("ìƒì„¸ë³´ê¸°", key=f"stock_detail_btn_{lot}"):
                    ss["mv_show_stock_detail"] = not ss.get("mv_show_stock_detail", False)
            with b2_col:
                if st.button("ì´ë™ì´ë ¥", key=f"move_hist_btn_{lot}"):
                    ss["mv_show_move_history_here"] = not ss.get("mv_show_move_history_here", False)

        if ss.get("mv_show_stock_detail", False):
            if stock_summary_df is not None and not stock_summary_df.empty:
                st.markdown("#### ğŸ” ì „ì‚° ì¬ê³  ìƒì„¸")

                # í–‰ ìˆ˜ ê¸°ë°˜ ë†’ì´ ìë™ ì¡°ì • (í–‰ë‹¹ ì•½ 35px + í—¤ë” 40px)
                n_rows = len(stock_summary_df)
                row_h = 35
                header_h = 40
                height = header_h + row_h * (n_rows + 1)

                st.dataframe(
                    stock_summary_df,
                    use_container_width=True,
                    height=height
                )
            else:
                st.info("ì „ì‚° ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


        st.markdown("### ğŸ›¢ í†µ ì„ íƒ ë° ì”ëŸ‰ ì…ë ¥")

        selected_drums = []
        drum_new_qty = {}

        drum_list = lot_df["í†µë²ˆí˜¸"].tolist()
        c1, c_sp, c2, _c_gap = st.columns([2, 0.5, 2, 7])
        with c1:
            if st.button("ëª¨ë‘ ì„ íƒ", key=f"mv_select_all_{lot}", use_container_width=False):
                for dn in drum_list:
                    st.session_state[f"mv_sel_{lot}_{dn}"] = True
        with c2:
            if st.button("ëª¨ë‘ í•´ì œ", key=f"mv_select_none_{lot}", use_container_width=False):
                for dn in drum_list:
                    st.session_state[f"mv_sel_{lot}_{dn}"] = False

        for _, row in lot_df.iterrows():
            drum_no = int(row["í†µë²ˆí˜¸"])
            old_qty = float(row["í†µìš©ëŸ‰"])
            drum_loc = str(row.get("í˜„ì¬ìœ„ì¹˜", "") or "").strip()

            if drum_loc:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg (ìœ„ì¹˜: {drum_loc})"
            else:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg"

            cb_key = f"mv_sel_{lot}_{drum_no}"
            checked = st.checkbox(label, key=cb_key)
            if checked:
                selected_drums.append(drum_no)
                new_val = st.number_input(
                    f"í†µ {drum_no}ì˜ í˜„ì¬ ìš©ëŸ‰(kg)",
                    min_value=0.0,
                    max_value=old_qty,
                    value=old_qty,
                    step=10.0,
                    format="%.0f",
                    key=f"mv_qty_{lot}_{drum_no}",
                )
                drum_new_qty[drum_no] = float(new_val)

    # ===== ì˜¤ë¥¸ìª½: ì´ë™ ìœ„ì¹˜ + ìƒíƒœ + ë¹„ê³  + ì €ì¥ =====
    with col_right2:
        st.markdown("### ğŸšš ì´ë™ ìœ„ì¹˜ ì„ íƒ")

        col1, col2 = st.columns(2)
        with col1:
            from_zone = st.text_input(
                "í˜„ì¬ ìœ„ì¹˜",
                value=current_zone if current_zone != "í˜¼í•©" else "",
                help="ì˜ˆ: 4ì¸µ-A1, ì™¸ì£¼ ë“±",
                key="mv_from_zone_csv",
            )
        with col2:
            floor_list = ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ", "ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]
            sel_floor = st.selectbox(
                "ì´ë™í•˜ì‹¤ ì¸µ/êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", floor_list, key="mv_floor_csv"
            )
            if sel_floor in ["ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]:
                sel_zone = ""
            else:
                zone_list = ["A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"]
                sel_zone = st.selectbox(
                    "ì´ë™í•˜ì‹¤ êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", zone_list, key="mv_zone_csv"
                )

            if sel_floor in ["ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]:
                to_zone = sel_floor
            else:
                to_zone = f"{sel_floor}-{sel_zone}"

        if to_zone == "ì™¸ì£¼":
            move_status = "ì™¸ì£¼"
            st.info("ì´ë™ ìœ„ì¹˜ê°€ 'ì™¸ì£¼'ì´ë¯€ë¡œ ìƒíƒœëŠ” ìë™ìœ¼ë¡œ 'ì™¸ì£¼'ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
        else:
            move_status = st.radio(
                "ì´ë™ í›„ ìƒíƒœë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
                ["ì”ëŸ‰", "ìƒì‚°ì¢…ë£Œ"],
                horizontal=True,
                key="mv_status_csv",
            )

        note = st.text_area("ë¹„ê³ (ì„ íƒ ì…ë ¥)", height=80, key="mv_note_csv")

        # ================== ì´ë™ ë‚´ìš© ì €ì¥ ë²„íŠ¼ ==================
        if st.button("ì´ë™ ë‚´ìš© ì €ì¥ (CSV ë°˜ì˜)", key="mv_save_csv"):
            if not selected_drums:
                st.warning("ì´ë™í•˜ì‹¤ í†µì„ í•œ ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                return

            df_all = load_drums()
            df_all["lot_lower"] = df_all["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
            lot_mask = df_all["lot_lower"] == lot_lower

            drum_logs = []

            for dn in selected_drums:
                idx = df_all.index[lot_mask & (df_all["í†µë²ˆí˜¸"] == dn)]
                if len(idx) == 0:
                    continue
                i = idx[0]

                # ğŸ”¹ ë³€ê²½ ì „ ìœ„ì¹˜(í†µë§ˆë‹¤) ë¨¼ì € í™•ë³´
                old_loc = str(df_all.at[i, "í˜„ì¬ìœ„ì¹˜"] or "")

                old_qty = float(df_all.at[i, "í†µìš©ëŸ‰"])
                new_qty = drum_new_qty.get(dn, old_qty)
                moved = old_qty - new_qty

                # CSV ì—…ë°ì´íŠ¸
                df_all.at[i, "í†µìš©ëŸ‰"] = new_qty
                df_all.at[i, "í˜„ì¬ìœ„ì¹˜"] = to_zone

                if to_zone == "ì™¸ì£¼":
                    df_all.at[i, "ìƒíƒœ"] = "ì™¸ì£¼"
                else:
                    df_all.at[i, "ìƒíƒœ"] = move_status

                # ğŸ”¹ í†µë²ˆí˜¸, ë³€í™”ëŸ‰, ì „/í›„ ìš©ëŸ‰, ë³€ê²½ ì „ ìœ„ì¹˜ê¹Œì§€ ë‹´ì•„ì„œ ë¡œê·¸ë¡œ ë³´ëƒ„
                drum_logs.append((dn, moved, old_qty, new_qty, old_loc))

            save_drums(df_all)

            write_move_log(
                item_code=item_code,
                item_name=item_name,
                lot=lot,
                drum_infos=drum_logs,
                from_zone=from_zone,  # ì—†ë˜ ì˜› í˜•ì‹ê³¼ë„ í˜¸í™˜ìš©ìœ¼ë¡œ ìœ ì§€
                to_zone=to_zone,
            )

            st.success(f"ì´ {len(drum_logs)}ê°œì˜ í†µ ì •ë³´ê°€ CSV ë° ì´ë™ ì´ë ¥ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")


    # ================== ì´ë™ íƒ­ ë‚´ë¶€ LOT ì´ë™ ì´ë ¥ ==================
    if ss.get("mv_show_move_history_here", False):
        log_df = load_move_log()
        if log_df.empty:
            st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sub = log_df[log_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower() == lot_lower].copy()
            if sub.empty:
                st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("### ğŸ“œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ ì´ë™ ì´ë ¥")
                sub = sub.sort_values("ì‹œê°„", ascending=False).head(50)
                st.dataframe(sub, use_container_width=True)

# ==============================
# íƒ­ 2: ì¡°íšŒ
# ==============================
def render_tab_lookup():
    st.markdown("### ğŸ” ë²Œí¬ ì¡°íšŒ")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì œì¡°ì¼ì ê¸°ì¤€ TAT(ê°œì›”) ì»¬ëŸ¼ ì¶”ê°€
    df = add_tat_column(df)

    query = st.text_input("ë¡œíŠ¸ë²ˆí˜¸, í’ˆëª©ì½”ë“œ ë˜ëŠ” í’ˆëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    if query:
        q = query.strip()
        mask = (
            df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.contains(q, case=False, na=False)
            | df["í’ˆëª©ì½”ë“œ"].astype(str).str.contains(q, case=False, na=False)
            | df["í’ˆëª…"].astype(str).str.contains(q, case=False, na=False)
        )
        df_view = df[mask]
    else:
        df_view = df

    # ìš©ëŸ‰ 0 í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: ë¯¸í¬í•¨)
    include_zero = st.checkbox("ìš©ëŸ‰ 0 í¬í•¨", value=False)

    if not include_zero:
        df_view = df_view[df_view["í†µìš©ëŸ‰"] > 0]

    if df_view.empty:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("#### ğŸ“„ í–‰ë³„ ìƒì„¸")
    st.dataframe(df_view, use_container_width=True)

    st.markdown("---")
    st.markdown("#### ğŸ“Š í˜„ì¬ìœ„ì¹˜ë³„ ìš©ëŸ‰ ìš”ì•½")

    def show_summary_table(df_part: pd.DataFrame, title: str, width: int = 400):
        st.markdown(f"##### {title}")
        if df_part.empty:
            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        summary = (
            df_part.groupby("í˜„ì¬ìœ„ì¹˜", dropna=False)
            .agg(
                í†µê°œìˆ˜=("í†µë²ˆí˜¸", "count"),
                ì´ìš©ëŸ‰_kg=("í†µìš©ëŸ‰", "sum"),
            )
            .reset_index()
            .sort_values("í˜„ì¬ìœ„ì¹˜")
        )

        # í•©ê³„ í–‰ ì¶”ê°€
        total_row = pd.DataFrame({
            "í˜„ì¬ìœ„ì¹˜": ["í•©ê³„"],
            "í†µê°œìˆ˜": [summary["í†µê°œìˆ˜"].sum()],
            "ì´ìš©ëŸ‰_kg": [summary["ì´ìš©ëŸ‰_kg"].sum()],
        })
        summary = pd.concat([summary, total_row], ignore_index=True)

        row_height = 35
        header_height = 40
        dynamic_height = header_height + row_height * (len(summary) + 1)

        st.dataframe(summary, width=width, height=dynamic_height)

    # ì¸µ(ë˜ëŠ” êµ¬ì—­) ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜ìš© ì»¬ëŸ¼
    tmp = df_view.copy()
    tmp["ì¸µ"] = tmp["í˜„ì¬ìœ„ì¹˜"].astype(str).str.split("-").str[0]

    # 1) ìì‚¬ ìœ„ì¹˜: 2ì¸µ, 4ì¸µ, 5ì¸µ, 6ì¸µ
    df_onsite = tmp[tmp["ì¸µ"].isin(["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"])]

    # 2) ì™¸ì£¼
    df_outsourcing = tmp[tmp["ì¸µ"] == "ì™¸ì£¼"]

    # 3) ì°½ê³ 
    df_warehouse = tmp[tmp["ì¸µ"] == "ì°½ê³ "]

    # 4) ì†Œì§„ + íê¸°
    df_consumed = tmp[tmp["ì¸µ"].isin(["ì†Œì§„", "íê¸°"])]

    # í‘œ 4ê°œ ì¶œë ¥
    show_summary_table(df_onsite, "1) ìì‚¬ ìœ„ì¹˜ (2ì¸µ / 4ì¸µ / 5ì¸µ / 6ì¸µ)")
    show_summary_table(df_outsourcing, "2) ì™¸ì£¼")
    show_summary_table(df_warehouse, "3) ì°½ê³ ")
    show_summary_table(df_consumed, "4) ì†Œì§„ / íê¸°")

    st.markdown("---")
    if st.button("í˜„ì¬ CSVë¥¼ ê·¸ëŒ€ë¡œ ë°±ì—… ì €ì¥í•˜ê¸°"):
        KST = timezone(timedelta(hours=9))
        ts = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        backup_name = f"bulk_drums_extended_backup_{ts}.csv"

        df.to_csv(backup_name, index=False, encoding="utf-8-sig")
        st.success(f"ë°±ì—… íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {backup_name}")



# ==============================
# íƒ­ 3: ì§€ë„ (A1~C3 ë²„íŠ¼)
# ==============================
def render_tab_map():
    st.markdown("### ğŸ—º ë²Œí¬ ìœ„ì¹˜ ì§€ë„ (CSV ê¸°ì¤€)")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    def get_floor(loc: str) -> str:
        if pd.isna(loc):
            return ""
        s = str(loc).strip()
        if "-" in s:
            return s.split("-")[0]
        return s

    df["ì¸µ"] = df["í˜„ì¬ìœ„ì¹˜"].apply(get_floor)

    floors = (
        df["ì¸µ"]
        .dropna()
        .astype(str)
        .replace("", pd.NA)
        .dropna()
        .unique()
        .tolist()
    )
    floors = sorted(floors)

    if not floors:
        st.info("ì¸µ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    sel_floor = st.selectbox("í™•ì¸í•˜ì‹¤ ì¸µ/êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", floors, key="map_floor_csv")

    fdf = df[df["ì¸µ"] == sel_floor].copy()
    if fdf.empty:
        st.info("í•´ë‹¹ ì¸µ/êµ¬ì—­ì— ë“±ë¡ëœ ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì†Œì§„ / ë¯¸ì§€ì • / íê¸° / ì™¸ì£¼ / ì°½ê³  ëŠ” ë‹¨ì¼ êµ¬ì—­ìœ¼ë¡œ ì²˜ë¦¬
    special_floors = {"ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼", "ì°½ê³ "}
    if sel_floor in special_floors:
        st.markdown(f"#### {sel_floor} êµ¬ì—­ í˜„í™©")

        drums = len(fdf)
        vol = fdf["í†µìš©ëŸ‰"].sum()

        st.write(f"**í†µ ê°œìˆ˜:** {drums}í†µ")
        st.write(f"**ì´ ìš©ëŸ‰:** {int(vol)}kg")

        st.markdown("---")
        st.markdown("### ğŸ” ìƒì„¸ ëª©ë¡")

        show_cols = [
            "í’ˆëª©ì½”ë“œ",
            "í’ˆëª…",
            "ë¡œíŠ¸ë²ˆí˜¸",
            "ì œí’ˆë¼ì¸",
            "ì œì¡°ì¼ì",
            "ìƒíƒœ",
            "í˜„ì¬ìœ„ì¹˜",
            "í†µë²ˆí˜¸",
            "í†µìš©ëŸ‰",
        ]
        st.dataframe(
            fdf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
            use_container_width=True,
        )
        return

    def get_zone_label(loc: str) -> str:
        if pd.isna(loc):
            return ""
        s = str(loc).strip()
        if "-" in s:
            return s.split("-")[1]
        if s in ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"]:
            return "A1"
        return s

    fdf["zone_label"] = fdf["í˜„ì¬ìœ„ì¹˜"].apply(get_zone_label)

    labels_all = [f"{r}{c}" for r in ["A", "B", "C"] for c in [1, 2, 3]]

    zone_stats = {}
    max_vol = 0.0
    for label in labels_all:
        sub = fdf[fdf["zone_label"] == label]
        drums = len(sub)
        vol = sub["í†µìš©ëŸ‰"].sum()
        zone_stats[label] = {"drums": drums, "volume": vol}
        max_vol = max(max_vol, vol)

    def badge(volume):
        if volume <= 0:
            return "âšª"
        if max_vol <= 0:
            return "ğŸŸ¡"
        ratio = volume / max_vol
        if ratio > 0.7:
            return "ğŸ”´"
        elif ratio > 0.3:
            return "ğŸŸ "
        else:
            return "ğŸŸ¡"

    st.markdown(f"#### {sel_floor} Zoneë³„ í˜„í™© (í†µ ê°œìˆ˜ / ì´ ìš©ëŸ‰)")

    for row in ["A", "B", "C"]:
        cols = st.columns(3)
        for i, col in enumerate(cols):
            label = f"{row}{i+1}"
            info = zone_stats.get(label, {"drums": 0, "volume": 0})
            txt = (
                f"{label} {badge(info['volume'])}\n"
                f"{info['drums']}í†µ / {int(info['volume'])}kg"
            )
            if col.button(txt, key=f"map_btn_{sel_floor}_{label}"):
                st.session_state["clicked_zone_csv"] = f"{sel_floor}-{label}"

    st.markdown("---")
    st.markdown("### ğŸ” Zone ìƒì„¸ ë³´ê¸°")

    clicked = st.session_state.get("clicked_zone_csv", None)
    if not clicked:
        st.info("í™•ì¸í•˜ì‹¤ Zone ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
        return

    st.success(f"ì„ íƒëœ Zone: {clicked}")
    _, cz_label = clicked.split("-")

    ddf = fdf[fdf["zone_label"] == cz_label].copy()
    if ddf.empty:
        st.info("í•´ë‹¹ Zoneì—ëŠ” ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    show_cols = [
        "í’ˆëª©ì½”ë“œ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "ì œí’ˆë¼ì¸",
        "ì œì¡°ì¼ì",
        "ìƒíƒœ",
        "í˜„ì¬ìœ„ì¹˜",
        "í†µë²ˆí˜¸",
        "í†µìš©ëŸ‰",
    ]
    st.dataframe(
        ddf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
        use_container_width=True,
    )


# ==============================
# íƒ­ 4: ì´ë™ ì´ë ¥ (ìˆ˜ì • + í–‰ ì‚­ì œ ê°€ëŠ¥)
# ==============================
def render_tab_move_log():
    st.markdown("### ğŸ“œ ì´ë™ ì´ë ¥ (ë¡¤ë°± ì „ìš© / ì‚­ì œë§Œ ê°€ëŠ¥)")

    df = load_move_log()
    if df.empty:
        st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    ss = st.session_state
    ss.setdefault("log_lot_filter", "")
    ss.setdefault("log_page", 1)

    def reset_log_filter():
        ss["log_lot_filter"] = ""
        ss["log_page"] = 1

    col1, col2 = st.columns([3, 1])
    with col1:
        lot_filter = st.text_input(
            "ë¡œíŠ¸ë²ˆí˜¸ë¡œ ê²€ìƒ‰ (ë¶€ë¶„ ì¼ì¹˜)",
            key="log_lot_filter",
            placeholder="ì˜ˆ: 2E075K",
        )
    with col2:
        st.button("ê²€ìƒ‰ ì´ˆê¸°í™”", key="log_reset", on_click=reset_log_filter)

    if lot_filter:
        q = lot_filter.strip().lower()
        df["lot_lower"] = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
        mask = df["lot_lower"].str.contains(q, na=False)
        df_view = df[mask].copy()
    else:
        df_view = df.copy()

    if df_view.empty:
        st.info("ê²€ìƒ‰ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_view = df_view.sort_values("ì‹œê°„", ascending=False)

    page_size = 50
    total_rows = len(df_view)
    total_pages = max(1, math.ceil(total_rows / page_size))

    # í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ ë³´ì •
    ss["log_page"] = min(max(1, ss.get("log_page", 1)), total_pages)

    # ğŸ”¹ í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ (ì´ì „ / í˜ì´ì§€ / ë‹¤ìŒ) â€“ í•œ ì¤„ ë°°ì¹˜ ì‹œë„
    colp1, colp2, colp3 = st.columns([1, 2, 1])

    with colp1:
        prev_clicked = st.button("â—€ ì´ì „", key="log_prev")

    with colp2:
        st.markdown(
            f"<div style='text-align:center; font-size:0.85rem;'>"
            f"í˜ì´ì§€ {ss['log_page']} / {total_pages}<br>(ì´ {total_rows}ê±´)"
            f"</div>",
            unsafe_allow_html=True,
        )

    with colp3:
        next_clicked = st.button("ë‹¤ìŒ â–¶", key="log_next")

    if prev_clicked and ss["log_page"] > 1:
        ss["log_page"] -= 1
        st.experimental_rerun()
    if next_clicked and ss["log_page"] < total_pages:
        ss["log_page"] += 1
        st.experimental_rerun()

    # ğŸ”¹ í˜„ì¬ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” êµ¬ê°„ë§Œ ì˜ë¼ì„œ í‘œì‹œ
    start = (ss["log_page"] - 1) * page_size
    end = start + page_size
    page_df = df_view.iloc[start:end].copy()
    
    start = (ss["log_page"] - 1) * page_size
    end = start + page_size
    page_df = df_view.iloc[start:end].copy()

    cols_order = [
        "ì‹œê°„",
        "ID",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]
    page_df = page_df[cols_order]

    delete_col = "ì‚­ì œ"
    if delete_col not in page_df.columns:
        page_df[delete_col] = False

    st.caption(
        "â€» LOGëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
        "ì¡°íšŒë§Œ ê°€ëŠ¥í•˜ë©°, 'ì‚­ì œ'ì— ì²´í¬ í›„ 'ì„ íƒ í–‰ ì‚­ì œ(ë¡¤ë°±)'ì„ ëˆ„ë¥´ë©´ "
        "í•´ë‹¹ ì´ë™ ì´ë ¥ì€ ì‚­ì œë˜ê³ , í†µ ì •ë³´ CSVëŠ” ë³€ê²½ ì „ ìƒíƒœë¡œ ë¡¤ë°±ë©ë‹ˆë‹¤.\n"
        "â€» ì•ˆì „ì„ ìœ„í•´ ê° í†µì˜ 'ê°€ì¥ ìµœê·¼ ì´ë™ ì´ë ¥'ë§Œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # ğŸ”¹ ëª¨ë“  ì¹¼ëŸ¼ì€ ì½ê¸° ì „ìš©, 'ì‚­ì œ'ë§Œ ì²´í¬ ê°€ëŠ¥
    edited_page = st.data_editor(
        page_df,
        use_container_width=True,
        disabled=cols_order,  # ì‹œê°„~ë³€ê²½ í›„ ìœ„ì¹˜ê¹Œì§€ ì „ë¶€ ì½ê¸° ì „ìš©
        column_config={
            delete_col: st.column_config.CheckboxColumn("ì‚­ì œ", help="ë¡¤ë°±í•  í–‰ì— ì²´í¬"),
        },
        key=f"move_log_editor_page_{ss['log_page']}",
    )

    def _save_full_log(df_updated: pd.DataFrame):
        buf = io.BytesIO()
        df_updated.to_csv(buf, index=False, encoding="utf-8-sig")
        data = buf.getvalue()
        ss["move_log_csv_bytes"] = data
        _load_move_log_core.clear()
        try:
            df_updated.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
        except Exception:
            pass
        s3_upload_bytes(MOVE_LOG_CSV, data)

    # ğŸ”¹ ì´ì œëŠ” ì‚­ì œ(ë¡¤ë°±) ë²„íŠ¼ë§Œ ì¡´ì¬
    _, col_delete = st.columns([3, 1])

    with col_delete:
        if st.button("ì„ íƒ í–‰ ì‚­ì œ (ë¡¤ë°±)", key="log_delete_rows"):
            try:
                if delete_col in edited_page.columns:
                    to_del_idx = edited_page[edited_page[delete_col] == True].index
                else:
                    to_del_idx = []

                if len(to_del_idx) == 0:
                    st.warning("ë¨¼ì € ë¡¤ë°±í•  í–‰ì„ 'ì‚­ì œ' ì¹¼ëŸ¼ì— ì²´í¬í•´ ì£¼ì„¸ìš”.")
                    return

                # ì›ë³¸ ì „ì²´ ë¡œê·¸ì—ì„œ ì‚­ì œ ëŒ€ìƒ í–‰ ì¶”ì¶œ
                rows_to_delete = df.loc[to_del_idx].copy()

                # 1) ê° í†µ(ë¡œíŠ¸ë²ˆí˜¸+í†µë²ˆí˜¸)ì˜ 'ê°€ì¥ ìµœì‹  ì´ë ¥'ì¸ì§€ í™•ì¸
                log_all = df.copy()
                log_all["__dt"] = pd.to_datetime(log_all["ì‹œê°„"], errors="coerce")

                not_latest = []
                for idx, row in rows_to_delete.iterrows():
                    lot = str(row["ë¡œíŠ¸ë²ˆí˜¸"])
                    drum_no = int(row["í†µë²ˆí˜¸"])

                    mask = (
                        log_all["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == lot
                    ) & (log_all["í†µë²ˆí˜¸"] == drum_no)
                    sub = log_all[mask]

                    if sub.empty:
                        continue

                    sub_valid = sub.dropna(subset=["__dt"])
                    if not sub_valid.empty:
                        last_idx = sub_valid["__dt"].idxmax()
                    else:
                        # ì‹œê°„ íŒŒì‹±ì´ ì•ˆ ë˜ë©´, ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ í° ê°’ = ë§ˆì§€ë§‰
                        last_idx = sub.index.max()

                    if idx != last_idx:
                        not_latest.append(f"{lot} / í†µ {drum_no}")

                if not_latest:
                    st.error(
                        "ë¡¤ë°±ì€ ê° í†µì˜ 'ê°€ì¥ ìµœê·¼ ì´ë™ ì´ë ¥'ë§Œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                        "ë‹¤ìŒ í•­ëª©ì€ ë” ìƒˆë¡œìš´ ì´ë ¥ì´ ìˆì–´ ë¡¤ë°±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n"
                        + ", ".join(not_latest)
                    )
                    return

                # 2) í†µ ì •ë³´ CSV ë¡¤ë°±
                drums_df = load_drums()
                drums_df["lot_lower"] = drums_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()

                for _, row in rows_to_delete.iterrows():
                    lot = str(row["ë¡œíŠ¸ë²ˆí˜¸"])
                    lot_lower = lot.lower()
                    drum_no = int(row["í†µë²ˆí˜¸"])

                    old_qty = float(row["ë³€ê²½ ì „ ìš©ëŸ‰"])
                    from_loc = str(row["ë³€ê²½ ì „ ìœ„ì¹˜"]) if not pd.isna(row["ë³€ê²½ ì „ ìœ„ì¹˜"]) else ""

                    mask_drum = (drums_df["lot_lower"] == lot_lower) & (drums_df["í†µë²ˆí˜¸"] == drum_no)
                    drum_idxs = drums_df.index[mask_drum]

                    if len(drum_idxs) == 0:
                        # í•´ë‹¹ í†µ ì •ë³´ê°€ CSVì— ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        continue

                    i = drum_idxs[0]
                    drums_df.at[i, "í†µìš©ëŸ‰"] = old_qty
                    if from_loc:
                        drums_df.at[i, "í˜„ì¬ìœ„ì¹˜"] = from_loc
                    # ìƒíƒœê¹Œì§€ ì™„ë²½íˆ ë³µì›í•˜ë ¤ë©´ ë¡œê·¸ì— ìƒíƒœë¥¼ ì¶”ê°€ë¡œ ê¸°ë¡í•´ì•¼ í•¨.
                    # ì§€ê¸ˆì€ í†µìš©ëŸ‰/í˜„ì¬ìœ„ì¹˜ë§Œ ë¡¤ë°±.

                if "lot_lower" in drums_df.columns:
                    drums_df = drums_df.drop(columns=["lot_lower"])
                save_drums(drums_df)

                # 3) ì´ë™ ë¡œê·¸ì—ì„œ í–‰ ì‚­ì œ + ì €ì¥
                df_updated = df.drop(index=to_del_idx)
                _save_full_log(df_updated)

                st.success(f"ì´ {len(to_del_idx)}ê°œ ì´ë™ ì´ë ¥ì´ ì‚­ì œë˜ê³ , ê´€ë ¨ í†µ ì •ë³´ê°€ ë¡¤ë°±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

            except Exception as e:
                st.error(f"í–‰ì„ ì‚­ì œ(ë¡¤ë°±)í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ==============================
# íƒ­ 5: ë°ì´í„° íŒŒì¼ ê´€ë¦¬
# ==============================
def file_status(sess_key: str, path: str) -> str:
    ss = st.session_state
    if sess_key in ss:
        return "ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš© ì¤‘"
    if os.path.exists(path):
        return f"ë¡œì»¬ íŒŒì¼ ì‚¬ìš© ì¤‘ ({path})"
    return "íŒŒì¼ ì—†ìŒ"


def render_tab_data():
    ss = st.session_state
    st.markdown("### ğŸ“ ë°ì´í„° íŒŒì¼ ê´€ë¦¬")
    st.write(
        "í•„ìš”í•  ë•Œë§ˆë‹¤ ì•„ë˜ì—ì„œ CSV/ì—‘ì…€ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì„œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ì—…ë¡œë“œí•˜ë©´ **í˜„ì¬ ì„¸ì…˜ì—ì„œ ë°”ë¡œ ë°˜ì˜**ë©ë‹ˆë‹¤."
    )

    # --- bulk_drums_extended.csv ---
    with st.expander("1) bulk_drums_extended.csv (ë©”ì¸ ë²Œí¬ CSV)", expanded=True):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("bulk_csv_bytes", CSV_PATH))
        bulk_file = st.file_uploader(
            "ìƒˆ bulk_drums_extended.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_bulk",
        )
        st.caption(last_upload_caption(CSV_PATH))

        if st.button("ì´ íŒŒì¼ë¡œ bulk CSV êµì²´", key="apply_bulk"):
            if bulk_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = bulk_file.read()
                ss["bulk_csv_bytes"] = data
                _load_drums_core.clear()
                try:
                    df_tmp = _load_drums_core(data)
                    df_tmp.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                s3_upload_bytes(CSV_PATH, data)
                st.success("bulk_drums_extended.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- production.xlsx ---
    with st.expander("2) production.xlsx (ì œì¡°ì‘ì—…ì‹¤ì í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("prod_xlsx_bytes", PRODUCTION_FILE))
        prod_file = st.file_uploader(
            "ìƒˆ production.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ production êµì²´", key="apply_prod"):
            if prod_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = prod_file.read()
                ss["prod_xlsx_bytes"] = data
                _load_production_core.clear()
                try:
                    df_tmp = _load_production_core(data)
                    df_tmp.to_excel(PRODUCTION_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(PRODUCTION_FILE, data)
                st.success("production.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- receive.xlsx ---
    with st.expander("3) receive.xlsx (ì…í•˜í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("recv_xlsx_bytes", RECEIVE_FILE))
        recv_file = st.file_uploader(
            "ìƒˆ receive.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ receive êµì²´", key="apply_recv"):
            if recv_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = recv_file.read()
                ss["recv_xlsx_bytes"] = data
                _load_receive_core.clear()
                try:
                    df_tmp = _load_receive_core(data)
                    df_tmp.to_excel(RECEIVE_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(RECEIVE_FILE, data)
                st.success("receive.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- stock.xlsx ---
    with st.expander("4) stock.xlsx (ì¼ìë³„í†µí•©ì¬ê³ í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("stock_xlsx_bytes", STOCK_FILE))
        stock_file = st.file_uploader(
            "ìƒˆ stock.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ stock êµì²´", key="apply_stock"):
            if stock_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = stock_file.read()
                ss["stock_xlsx_bytes"] = data
                _load_stock_core.clear()
                try:
                    df_tmp = _load_stock_core(data)
                    df_tmp.to_excel(STOCK_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(STOCK_FILE, data)
                st.success("stock.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- bulk_move_log.csv ---
    with st.expander("5) bulk_move_log.csv (ì´ë™ ì´ë ¥, ì„ íƒ)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("move_log_csv_bytes", MOVE_LOG_CSV))
        move_file = st.file_uploader(
            "ìƒˆ bulk_move_log.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))

        if st.button("ì´ íŒŒì¼ë¡œ ì´ë™ ì´ë ¥ êµì²´", key="apply_move"):
            if move_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = move_file.read()
                ss["move_log_csv_bytes"] = data
                _load_move_log_core.clear()
                try:
                    df_tmp = _load_move_log_core(data)
                    df_tmp.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                s3_upload_bytes(MOVE_LOG_CSV, data)
                st.success("bulk_move_log.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.caption(
        "â€» Cloudì—ì„œëŠ” ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ë©´ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. "
        "ì¤‘ìš”í•œ ë³€ê²½ ë‚´ìš©ì€ ì‚¬ì´ë“œë°”ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ CSVë¥¼ ì €ì¥í•´ ë‘ì„¸ìš”."
    )


# ==============================
# ë©”ì¸
# ==============================
def has_data(sess_key: str, path: str) -> bool:
    """
    ì„¸ì…˜, ë¡œì»¬ íŒŒì¼, S3 ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ True.
    """
    ss = st.session_state
    if sess_key in ss:
        return True
    if os.path.exists(path):
        return True
    b = s3_download_bytes(path)
    if b is not None:
        return True
    return False


def main():
    ss = st.session_state

    # 1) ë¡œê·¸ì¸ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë¡œê·¸ì¸ í™”ë©´ë§Œ í‘œì‹œ
    if "user_id" not in ss or "user_name" not in ss:
        render_login()
        return

    # 2) í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ì¤€ë¹„ ì—¬ë¶€ í™•ì¸
    files_ready = (
        has_data("bulk_csv_bytes", CSV_PATH)
        and has_data("prod_xlsx_bytes", PRODUCTION_FILE)
        and has_data("recv_xlsx_bytes", RECEIVE_FILE)
        and has_data("stock_xlsx_bytes", STOCK_FILE)
    )

    if not ss.get("data_initialized", False) and not files_ready:
        render_file_loader()
        return

    # 3) ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown(f"**ì‚¬ìš©ì:** {ss['user_name']} ({ss['user_id']})")
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
            for k in ["user_id", "user_name"]:
                if k in st.session_state:
                    del st.session_state[k]
            st.rerun()

        if "bulk_csv_bytes" in ss:
            st.download_button(
                "í˜„ì¬ bulk CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["bulk_csv_bytes"],
                file_name="bulk_drums_extended_current.csv",
                mime="text/csv",
            )
        if "move_log_csv_bytes" in ss:
            st.download_button(
                "ì´ë™ ì´ë ¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["move_log_csv_bytes"],
                file_name="bulk_move_log_current.csv",
                mime="text/csv",
            )

    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

    tab_move, tab_lookup, tab_map, tab_log, tab_data = st.tabs(
        ["ğŸ“¦ ì´ë™", "ğŸ” ì¡°íšŒ", "ğŸ—º ì§€ë„", "ğŸ“œ ì´ë™ ì´ë ¥", "ğŸ“ ë°ì´í„°"]
    )

    with tab_move:
        render_tab_move()
    with tab_lookup:
        render_tab_lookup()
    with tab_map:
        render_tab_map()
    with tab_log:
        render_tab_move_log()
    with tab_data:
        render_tab_data()


if __name__ == "__main__":
    main()
