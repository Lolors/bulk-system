import streamlit as st
import pandas as pd
import os
from datetime import datetime, date, timezone, timedelta
import io
import math
import boto3

KST = timezone(timedelta(hours=9))

def now_kst_str() -> str:
    """í•œêµ­ ì‹œê°„(KST) í˜„ì¬ ì‹œê°ì„ 'YYYY-MM-DD HH:MM:SS' ë¬¸ìì—´ë¡œ ë°˜í™˜."""
    return datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
    
# ==============================
# ì‚¬ìš©ì ê³„ì • (ë¡œê·¸ì¸ìš©)
# ==============================
USER_ACCOUNTS = {
    "ps": {"password": "0000", "display_name": "ì„í•„ì„ "},
    "by": {"password": "0000", "display_name": "ê°•ë´‰ì—°"},
    "hn": {"password": "0000", "display_name": "ê¹€í•œë‚˜"},
    "se": {"password": "0000", "display_name": "ì´ì„±ì€"},
}

# ==============================
# ê¸°ë³¸ ì„¤ì • + CSS
# ==============================
st.set_page_config(page_title="ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

st.markdown(
    """
    <style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ ì¹¸ì€ í™”ë©´ í­ê³¼ ìƒê´€ì—†ì´ ê³ ì • í¬ê¸° + í™•ì¥ ê¸ˆì§€ */
    .stTextInput > div {
        flex: 0 0 auto !important;
    }
    .stTextInput > div > div > input {
        width: 160px !important;
        max-width: 160px !important;
        min-width: 160px !important;
    }

    /* ğŸ”¹ st.form í…Œë‘ë¦¬/ë°°ê²½ ì œê±° */
    .stForm {
        border: none !important;
        box-shadow: none !important;
        padding: 0 !important;
        background-color: transparent !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


CSV_PATH = "bulk_drums_extended.csv"   # í’ˆëª©ì½”ë“œ~í˜„ì¬ìœ„ì¹˜ê¹Œì§€ ë“¤ì–´ìˆëŠ” íŒŒì¼
PRODUCTION_FILE = "production.xlsx"    # ìì‚¬: ì‘ì—…ë²ˆí˜¸ â†’ ë¡œíŠ¸/ì œì¡°ëŸ‰
MOVE_LOG_CSV = "bulk_move_log.csv"     # ì´ë™ ì´ë ¥
RECEIVE_FILE = "receive.xlsx"          # ì‚¬ê¸‰: ì…í•˜ë²ˆí˜¸ ê¸°ë°˜
STOCK_FILE = "stock.xlsx"              # ì „ì‚° ì¬ê³ 

# ==============================
# S3 ì—°ë™ ì„¤ì •
# ==============================
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "bulk-system-enc")
S3_PREFIX = os.getenv("S3_PREFIX", "bulk-app/")  # í´ë” ê²½ë¡œ


def s3_enabled() -> bool:
    return bool(S3_BUCKET_NAME)


@st.cache_resource(show_spinner=False)
def get_s3_client():
    try:
        session = boto3.session.Session()
        client = session.client("s3")
        return client
    except Exception:
        return None


def _s3_key(filename: str) -> str:
    """
    S3ì—ì„œ ì €ì¥ë˜ëŠ” ê²½ë¡œë¥¼ ê²°ì •.
    ì˜ˆ: filename="bulk_drums_extended.csv" â†’ "bulk-app/bulk_drums_extended.csv"
    """
    prefix = S3_PREFIX.rstrip("/")
    return f"{prefix}/{filename}" if prefix else filename


def s3_upload_bytes(filename: str, data: bytes):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ë°”ì´íŠ¸ë¥¼ S3ì— ì €ì¥.
    filename: ë¡œì»¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” íŒŒì¼ëª…ì„ ê·¸ëŒ€ë¡œ ë„˜ê¸°ë©´ _s3_keyë¡œ S3 ê²½ë¡œ ë³€í™˜.
    """
    if not s3_enabled():
        return
    client = get_s3_client()
    if not client:
        return
    try:
        client.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=_s3_key(filename),
            Body=data,
        )
    except Exception:
        # S3 ì˜¤ë¥˜ê°€ ë‚˜ë”ë¼ë„ ì•± ì „ì²´ëŠ” ì£½ì§€ ì•Šê²Œ ì¡°ìš©íˆ ë¬´ì‹œ
        pass


def s3_download_bytes(filename: str):
    """
    S3ì—ì„œ íŒŒì¼ì„ ì½ì–´ì™€ì„œ bytesë¡œ ë°˜í™˜.
    ì—†ê±°ë‚˜ ì˜¤ë¥˜ë©´ None ë°˜í™˜.
    """
    if not s3_enabled():
        return None
    client = get_s3_client()
    if not client:
        return None
    try:
        resp = client.get_object(
            Bucket=S3_BUCKET_NAME,
            Key=_s3_key(filename),
        )
        return resp["Body"].read()
    except Exception:
        return None


# ==============================
# ê³µí†µ ìœ í‹¸ (ì—…ë¡œë“œ/ë¡œì»¬/S3 ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_drums_core(bulk_bytes):
    """bulk_drums_extended.csv ë¡œë“œ (ì„¸ì…˜ ì—…ë¡œë“œ > ë¡œì»¬ > S3 ìˆœì„œ)."""
    # 1) ì„¸ì…˜ ì—…ë¡œë“œ ìš°ì„ 
    if bulk_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(bulk_bytes))
        except Exception as e:
            st.error(f"ì—…ë¡œë“œí•œ bulk_drums_extended.csvë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
                    "ìƒíƒœ", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰", "í˜„ì¬ìœ„ì¹˜",
                ]
            )

    # 2) ë¡œì»¬
    elif os.path.exists(CSV_PATH):
        try:
            df = pd.read_csv(CSV_PATH)
        except Exception as e:
            st.error(f"CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
                    "ìƒíƒœ", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰", "í˜„ì¬ìœ„ì¹˜",
                ]
            )

    # 3) S3
    else:
        s3_bytes = s3_download_bytes(CSV_PATH)
        if s3_bytes is not None:
            try:
                df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ bulk_drums_extended.csvë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame(
                    columns=[
                        "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
                        "ìƒíƒœ", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰", "í˜„ì¬ìœ„ì¹˜",
                    ]
                )
        else:
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
                    "ìƒíƒœ", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰", "í˜„ì¬ìœ„ì¹˜",
                ]
            )

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    required_cols = [
        "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
        "ìƒíƒœ", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰", "í˜„ì¬ìœ„ì¹˜",
    ]
    for c in required_cols:
        if c not in df.columns:
            st.error(f"CSVì— '{c}' ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ì—ì„œ ë‹¤ì‹œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.")
            return pd.DataFrame(columns=required_cols)

    # íƒ€ì… ë³´ì •
    df["í†µë²ˆí˜¸"] = pd.to_numeric(df["í†µë²ˆí˜¸"], errors="coerce").fillna(0).astype(int)
    df["í†µìš©ëŸ‰"] = pd.to_numeric(df["í†µìš©ëŸ‰"], errors="coerce").fillna(0.0).astype(float)

    # í˜„ì¬ìœ„ì¹˜ ì •ê·œí™”
    def norm_loc(x) -> str:
        if pd.isna(x):
            return ""
        s = str(x).strip()
        if not s:
            return ""

        # íŠ¹ìˆ˜ êµ¬ì—­: ê·¸ëŒ€ë¡œ (ë¯¸ì§€ì • ë¶™ì´ë©´ ì•ˆ ë¨)
        if s in ["ì™¸ì£¼", "íê¸°", "ì†Œì§„", "ì°½ê³ "]:
            return s

        # ì˜ˆì „ ë°ì´í„° í˜¸í™˜: "4ì¸µ-A1" -> "4ì¸µ A1"
        if "-" in s:
            s = s.replace("-", " ", 1).strip()

        # ì¸µë§Œ ë“¤ì–´ì˜¨ ê²½ìš° -> "Xì¸µ ë¯¸ì§€ì •"
        if s in ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"]:
            return f"{s} ë¯¸ì§€ì •"

        return s

    df["í˜„ì¬ìœ„ì¹˜"] = df["í˜„ì¬ìœ„ì¹˜"].apply(norm_loc)

    return df


def load_drums() -> pd.DataFrame:
    """ì„¸ì…˜ ìƒíƒœë¥¼ ê°ì•ˆí•´ì„œ bulk DFë¥¼ ê°€ì ¸ì˜¤ëŠ” ì™¸ë¶€ìš© í•¨ìˆ˜."""
    ss = st.session_state
    bulk_bytes = ss.get("bulk_csv_bytes", None)
    return _load_drums_core(bulk_bytes)


def save_drums(df: pd.DataFrame):
    """
    í˜„ì¬ DFë¥¼ bulk_drums_extended.csvë¡œ ì €ì¥.
    - ì„¸ì…˜ ë©”ëª¨ë¦¬(ì—…ë¡œë“œ ë°©ì‹) ê°±ì‹ 
    - ë¡œì»¬ íŒŒì¼ë„ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸° (ë¡œì»¬ ì‹¤í–‰ìš©)
    - S3ì—ë„ ì—…ë¡œë“œ
    """
    # 1) ì„¸ì…˜ ë©”ëª¨ë¦¬ ê°±ì‹ 
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()
    st.session_state["bulk_csv_bytes"] = data

    # ìºì‹œ ë¬´íš¨í™”
    _load_drums_core.clear()

    # 2) ë¡œì»¬ CSVë¡œë„ ì €ì¥ (ìˆìœ¼ë©´)
    try:
        df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
    except Exception:
        # Cloud í™˜ê²½ì—ì„œëŠ” ë³´í†µ ê¶Œí•œ/ê²½ë¡œê°€ ì—†ìœ¼ë‹ˆ ì¡°ìš©íˆ ë¬´ì‹œ
        pass

    # 3) S3 ì—…ë¡œë“œ
    s3_upload_bytes(CSV_PATH, data)

# ==============================
# ìœ„ì¹˜ ì¹´í…Œê³ ë¦¬ (ì§€ë„/ì´ë™ ê³µí†µ)
# ==============================
FLOOR_ZONES = {
    "2ì¸µ": ["A", "B", "C", "D", "E", "ë¯¸ì§€ì •"],
    "4ì¸µ": ["ë¸”ë¦¬ìŠ¤í„°", "ë¡œíƒ€ë¦¬", "ë•ìš©", "ë¯¸ì§€ì •"],
    "5ì¸µ": ["ê¸°ì´ˆ", "ë•ìš©", "ë¯¸ì§€ì •"],
    "6ì¸µ": ["ìŠ¤í‹±&íŒŒìš°ì¹˜", "ìŠ¤í‚¨íŒ©", "ë¯¸ì§€ì •"],
}
SPECIAL_AREAS = ["ì™¸ì£¼", "íê¸°", "ì†Œì§„", "ì°½ê³ "]  # ë¯¸ì§€ì • ë¶™ì´ì§€ ì•ŠìŒ

def location_picker(key_prefix: str) -> str:
    """
    ì§€ë„ íƒ­ê³¼ ë™ì¼í•œ ì¹´í…Œê³ ë¦¬ë¡œ 'í˜„ì¬ìœ„ì¹˜' ë¬¸ìì—´ì„ ë§Œë“ ë‹¤.
    - íŠ¹ìˆ˜êµ¬ì—­: ì™¸ì£¼ / íê¸° / ì†Œì§„ / ì°½ê³  â†’ ê·¸ëŒ€ë¡œ ë°˜í™˜
    - ì¸µ ì„ íƒ ì‹œ: ì„¸ë¶€êµ¬ì—­ ì„ íƒ, ì—†ìœ¼ë©´ 'ë¯¸ì§€ì •'
    - ì¸µ ë³€ê²½ ì‹œ ì„¸ë¶€êµ¬ì—­ ìë™ ë¦¬ì…‹
    """

    # 1ï¸âƒ£ ìµœìƒìœ„ ì„ íƒ (ì¸µ + íŠ¹ìˆ˜êµ¬ì—­ í†µí•©)
    top_options = list(FLOOR_ZONES.keys()) + SPECIAL_AREAS

    top_key = f"{key_prefix}_top"
    zone_key = f"{key_prefix}_zone"
    last_top_key = f"{key_prefix}_last_top"

    top = st.selectbox(
        "ì´ë™í•˜ì‹¤ ìœ„ì¹˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
        top_options,
        key=top_key,
    )

    # 2ï¸âƒ£ íŠ¹ìˆ˜êµ¬ì—­ì´ë©´ ë°”ë¡œ ë°˜í™˜
    if top in SPECIAL_AREAS:
        return top

    # 3ï¸âƒ£ ì¸µì´ ë°”ë€Œë©´ ì„¸ë¶€êµ¬ì—­ ì„ íƒê°’ ë¦¬ì…‹
    prev_top = st.session_state.get(last_top_key)
    if prev_top != top:
        st.session_state.pop(zone_key, None)
        st.session_state[last_top_key] = top

    # 4ï¸âƒ£ ì„¸ë¶€êµ¬ì—­ ì„ íƒ
    zones = FLOOR_ZONES.get(top, ["ë¯¸ì§€ì •"])
    zone = st.selectbox(
        "ì„¸ë¶€êµ¬ì—­ ì„ íƒ",
        zones,
        key=zone_key,
    )

    # 5ï¸âƒ£ fallback
    z = (zone or "").strip()
    if not z:
        z = "ë¯¸ì§€ì •"

    return f"{top} {z}"


@st.cache_data(show_spinner=False)
def _load_production_core(prod_bytes):
    if prod_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(prod_bytes))
        except Exception:
            return pd.DataFrame()
    elif os.path.exists(PRODUCTION_FILE):
        try:
            df = pd.read_excel(PRODUCTION_FILE)
        except Exception:
            return pd.DataFrame()
    else:
        # ë¡œì»¬ë„ ì—†ìœ¼ë©´ S3 ì‹œë„
        s3_bytes = s3_download_bytes(PRODUCTION_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception:
                return pd.DataFrame()
        else:
            return pd.DataFrame()

    required = ["ì‘ì—…ë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "LOTNO", "ì§€ì‹œìˆ˜ëŸ‰", "ì œì¡°ëŸ‰", "ì‘ì—…ì¼ì"]
    for c in required:
        if c not in df.columns:
            return pd.DataFrame()
    return df[required].copy()


def load_production():
    ss = st.session_state
    prod_bytes = ss.get("prod_xlsx_bytes", None)
    return _load_production_core(prod_bytes)


@st.cache_data(show_spinner=False)
def _load_receive_core(recv_bytes):
    if recv_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(recv_bytes))
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(RECEIVE_FILE):
        try:
            df = pd.read_excel(RECEIVE_FILE)
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(RECEIVE_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ receive.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame()
        else:
            return pd.DataFrame()
    return df


def load_receive():
    ss = st.session_state
    recv_bytes = ss.get("recv_xlsx_bytes", None)
    return _load_receive_core(recv_bytes)


@st.cache_data(show_spinner=False)
def _load_stock_core(stock_bytes):
    if stock_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(stock_bytes))
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(STOCK_FILE):
        try:
            df = pd.read_excel(STOCK_FILE)
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(STOCK_FILE)
        if s3_bytes is not None:
            try:
                df = pd.read_excel(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ stock.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame()
        else:
            return pd.DataFrame()
    return df


def load_stock() -> pd.DataFrame:
    ss = st.session_state
    stock_bytes = ss.get("stock_xlsx_bytes", None)
    return _load_stock_core(stock_bytes)


# ==============================
# ìì‚¬ í’ˆë²ˆë³„ ì œí’ˆë¼ì¸ ìë™ ë¶„ë¥˜
# ==============================
NEEDLESHOT_CODES = {
    "3VTCLOS-010",
    "3VTCLOS-006",
    "3VTCLOS-007",
    "3VTCLOS-008",
    "3VTCLOS-011",
    "3VTCLOS-013",
    "3VTCLOS-047",
}

FACIAL_CODES = {
    "3VTCLOS-023",
    "3VTCLOS-024",
    "3VTCLOS-060",
    "3VTCLOS-061",
    "3VTCLOS-062",
    "3VTCLOS-063",
    "3VTCLOS-064",
    "3VTCLOS-065",
}


def classify_product_line(item_code: str) -> str:
    if not isinstance(item_code, str):
        return ""
    code = item_code.strip()
    if code in NEEDLESHOT_CODES:
        return "ë¦¬ë“¤ìƒ·"
    if code in FACIAL_CODES:
        return "í˜ì´ì…œ"
    return ""


def add_tat_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    dfì— 'TAT' ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ ì œì¡°ì¼ìë¡œë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ê²½ê³¼ ê°œì›” ìˆ˜ë¥¼ ì±„ì›Œì¤€ë‹¤.
    - ì œì¡°ì¼ìê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒŒì‹± ë¶ˆê°€í•˜ë©´ TATëŠ” <NA>
    """
    if "ì œì¡°ì¼ì" not in df.columns:
        df["TAT"] = pd.NA
        return df

    # ì œì¡°ì¼ìë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ (ì—¬ëŸ¬ í¬ë§· í—ˆìš©)
    mfg_dt = pd.to_datetime(df["ì œì¡°ì¼ì"], errors="coerce")

    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = date.today()

    # ì—°/ì›” ì°¨ì´ë¡œ ê°œì›” ìˆ˜ ê³„ì‚°
    years_diff = today.year - mfg_dt.dt.year
    months_diff = today.month - mfg_dt.dt.month
    tat_months = years_diff * 12 + months_diff

    # ìŒìˆ˜ ë°©ì§€
    tat_months = tat_months.clip(lower=0)

    # ë‚ ì§œ ì—†ëŠ” ê³³ì€ NAë¡œ
    tat_months = tat_months.where(~mfg_dt.isna(), pd.NA)

    # nullable ì •ìˆ˜ë¡œ ì €ì¥
    df = df.copy()
    df["TAT"] = tat_months.astype("Int64")

    return df


def generate_drums(prod_qty_kg: float):
    """ì œì¡°ëŸ‰(kg)ì„ ë°›ì•„ì„œ í†µë²ˆí˜¸/ìš©ëŸ‰ì„ ìë™ ìƒì„±."""
    if prod_qty_kg is None:
        return []

    try:
        qty = float(prod_qty_kg)
    except Exception:
        return []

    if qty <= 0:
        return []

    drums = []
    if qty < 200:
        drums.append({"í†µë²ˆí˜¸": 1, "í†µìš©ëŸ‰": qty})
        return drums

    full = int(qty // 1000)
    rem = qty % 1000

    for i in range(full):
        drums.append({"í†µë²ˆí˜¸": i + 1, "í†µìš©ëŸ‰": 1000})

    if rem > 0:
        drums.append({"í†µë²ˆí˜¸": full + 1, "í†µìš©ëŸ‰": rem})

    return drums


def ensure_lot_in_csv(
    df: pd.DataFrame,
    lot: str,
    item_code: str,
    item_name: str,
    line: str,
    mfg_date: str,
    initial_status: str = "ìƒì‚°ëŒ€ê¸°",
    prod_qty: float = None,
) -> pd.DataFrame:
    """ì—†ë˜ ë¡œíŠ¸ë©´ í†µ ìë™ ìƒì„±í•´ì„œ CSVì— ì¶”ê°€."""
    if (df["ë¡œíŠ¸ë²ˆí˜¸"] == lot).any():
        return df

    drums = generate_drums(prod_qty)
    if not drums:
        return df

    new_rows = []
    for d in drums:
        new_rows.append(
            {
                "í’ˆëª©ì½”ë“œ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "ì œí’ˆë¼ì¸": line or "",
                "ì œì¡°ì¼ì": mfg_date or "",
                "ìƒíƒœ": initial_status or "ìƒì‚°ëŒ€ê¸°",
                "í†µë²ˆí˜¸": int(d["í†µë²ˆí˜¸"]),
                "í†µìš©ëŸ‰": float(d["í†µìš©ëŸ‰"]),
                "í˜„ì¬ìœ„ì¹˜": "2ì¸µ ë¯¸ì§€ì •",
            }
        )

    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)
    return df


# ==============================
# ì´ë™ LOG ìœ í‹¸ (ID í¬í•¨, ì—…ë¡œë“œ/ì„¸ì…˜/S3 ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_move_log_core(move_bytes):
    """ì´ë™ ì´ë ¥ CSV ë¡œë“œ."""
    default_cols = [
        "ì‹œê°„",
        "ID",          # ì´ë™ ê¸°ë¡ ì‘ì„±ì (í‘œì‹œìš© ì´ë¦„)
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]

    if move_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(move_bytes))
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            df = pd.read_csv(MOVE_LOG_CSV)
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    else:
        s3_bytes = s3_download_bytes(MOVE_LOG_CSV)
        if s3_bytes is not None:
            try:
                df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception as e:
                st.error(f"S3ì˜ ì´ë™ ì´ë ¥ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return pd.DataFrame(columns=default_cols)
        else:
            return pd.DataFrame(columns=default_cols)

    # ì˜ˆì „ ë¡œê·¸ì— IDì—´ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë³´ì •
    for c in default_cols:
        if c not in df.columns:
            if c == "ID":
                df[c] = ""
            else:
                df[c] = pd.NA

    return df[default_cols]


def load_move_log() -> pd.DataFrame:
    ss = st.session_state
    move_bytes = ss.get("move_log_csv_bytes", None)
    return _load_move_log_core(move_bytes)

def save_move_log(df: pd.DataFrame):
    """
    ì´ë™ ì´ë ¥ DataFrame ì „ì²´ë¥¼ bulk_move_log.csv ë° ì„¸ì…˜/S3ì— ì €ì¥.
    (ê¸°ì¡´ ë‚´ìš©ì„ ìœ ì§€í•œ ì±„ ë®ì–´ì“°ê¸° ë°©ì‹ìœ¼ë¡œ ì „ì²´ ì €ì¥)
    """
    ss = st.session_state

    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()

    # ì„¸ì…˜ì— ë°˜ì˜
    ss["move_log_csv_bytes"] = data

    # ìºì‹œ í´ë¦¬ì–´
    _load_move_log_core.clear()

    # ë¡œì»¬ CSV ì €ì¥
    try:
        df.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
    except Exception:
        pass

    # S3 ì—…ë¡œë“œ
    s3_upload_bytes(MOVE_LOG_CSV, data)



def write_move_log(item_code: str, item_name: str, lot: str, drum_infos, from_zone: str, to_zone: str):
    """
    ì´ë™ ì´ë ¥ì„ bulk_move_log.csvì— ê¸°ë¡.
    drum_infos:
      - ì˜› í˜•ì‹: (í†µë²ˆí˜¸, moved_qty, old_qty, new_qty)
      - ìƒˆ í˜•ì‹: (í†µë²ˆí˜¸, moved_qty, old_qty, new_qty, old_loc)
    ID ì—´ì—ëŠ” ë¡œê·¸ì¸í•œ ì‚¬ìš©ìì˜ 'í‘œì‹œ ì´ë¦„'ì„ ë‚¨ê¸´ë‹¤.
    """
    if not drum_infos:
        return

    ss = st.session_state
    user_display_name = ss.get("user_name", "")

    ts = now_kst_str()  # ğŸ”¹ í•œêµ­ ì‹œê°„ ê¸°ì¤€

    rows = []
    for info in drum_infos:
        # ğŸ”¹ íŠœí”Œ ê¸¸ì´ì— ë”°ë¼ ë¶„ê¸° (ì˜› ë°ì´í„°ì™€ í˜¸í™˜)
        if len(info) == 4:
            drum_no, moved_qty, old_qty, new_qty = info
            old_loc = from_zone
        else:
            drum_no, moved_qty, old_qty, new_qty, old_loc = info

        rows.append(
            {
                "ì‹œê°„": ts,
                "ID": user_display_name,
                "í’ˆë²ˆ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "í†µë²ˆí˜¸": drum_no,
                "ë³€ê²½ ì „ ìš©ëŸ‰": old_qty,
                "ë³€ê²½ í›„ ìš©ëŸ‰": new_qty,
                "ë³€í™”ëŸ‰": moved_qty,
                "ë³€ê²½ ì „ ìœ„ì¹˜": old_loc,
                "ë³€ê²½ í›„ ìœ„ì¹˜": to_zone,
            }
        )

    new_df = pd.DataFrame(rows)

    # ê¸°ì¡´ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì„¸ì…˜/ë¡œì»¬/S3)
    if "move_log_csv_bytes" in ss:
        try:
            old_df = pd.read_csv(io.BytesIO(ss["move_log_csv_bytes"]))
        except Exception:
            old_df = pd.DataFrame()
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            old_df = pd.read_csv(MOVE_LOG_CSV)
        except Exception:
            old_df = pd.DataFrame()
    else:
        s3_bytes = s3_download_bytes(MOVE_LOG_CSV)
        if s3_bytes is not None:
            try:
                old_df = pd.read_csv(io.BytesIO(s3_bytes))
            except Exception:
                old_df = pd.DataFrame()
        else:
            old_df = pd.DataFrame()

    log_df = pd.concat([old_df, new_df], ignore_index=True)

    # 1) ì„¸ì…˜ì— ë‹¤ì‹œ ì €ì¥
    buf = io.BytesIO()
    log_df.to_csv(buf, index=False, encoding="utf-8-sig")
    data = buf.getvalue()
    ss["move_log_csv_bytes"] = data

    _load_move_log_core.clear()

    # 2) ë¡œì»¬ CSVì—ë„ ì €ì¥ (ë¡œì»¬ ì‹¤í–‰ìš©)
    try:
        log_df.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
    except Exception:
        pass

    # 3) S3 ì—…ë¡œë“œ
    s3_upload_bytes(MOVE_LOG_CSV, data)


# ==============================
# ì—…ë¡œë“œ ì‹œê°„ í‘œì‹œ ìœ í‹¸  (S3 â†’ ë¡œì»¬ ìˆœìœ¼ë¡œ í™•ì¸)
# ==============================
from datetime import datetime as dt_for_caption


@st.cache_data(show_spinner=False, ttl=60)
def last_upload_caption(filename: str) -> str:
    """
    íŒŒì¼ì˜ ë§ˆì§€ë§‰ ì—…ë¡œë“œ ì‹œê°„ì„ KST(UTC+9) ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
    1) S3 â†’ 2) ë¡œì»¬ íŒŒì¼ â†’ 3) ì—†ìœ¼ë©´ í‘œì‹œ ì—†ìŒ
    """
    from datetime import timezone, timedelta, datetime as dt

    # KST timezone
    KST = timezone(timedelta(hours=9))

    # ------------------------
    # 1) S3 timestamp
    # ------------------------
    try:
        if s3_enabled():
            client = get_s3_client()
            if client:
                s3_path = _s3_key(filename)
                resp = client.head_object(Bucket=S3_BUCKET_NAME, Key=s3_path)

                lm = resp["LastModified"]     # timezone-aware datetime
                lm_kst = lm.astimezone(KST)   # ğŸ‘‰ KST ë¡œ ë³€í™˜

                return f"S3 ë§ˆì§€ë§‰ ìˆ˜ì •: {lm_kst.strftime('%Y-%m-%d %H:%M:%S')}"
    except Exception:
        pass

    # ------------------------
    # 2) Local file timestamp
    # ------------------------
    if os.path.exists(filename):
        try:
            ts = os.path.getmtime(filename)        # float (UTC ê¸°ì¤€ timestamp)
            lm_kst = dt.fromtimestamp(ts, KST)     # ğŸ‘‰ timestamp ë¥¼ KST ë¡œ ë³€í™˜
            return f"ë¡œì»¬ ë§ˆì§€ë§‰ ìˆ˜ì •: {lm_kst.strftime('%Y-%m-%d %H:%M:%S')}"
        except Exception:
            return "ë¡œì»¬ íŒŒì¼ ì‹œê°„ ì½ê¸° ì˜¤ë¥˜"

    # ------------------------
    # 3) No file
    # ------------------------
    return "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

# ==============================
# ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í™”ë©´ (ìµœì´ˆ 1íšŒìš©)
# ==============================
def render_file_loader():
    ss = st.session_state

    st.title("ğŸ“ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown(
        """
        Streamlit Cloud ë˜ëŠ” ì´ˆê¸° ì„¤ì • ì‹œ, GitHubì— ì˜¬ë¦¬ê¸° ì–´ë ¤ìš´ CSV/ì—‘ì…€ íŒŒì¼ë“¤ì„
        ì—¬ê¸°ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.

        ì•„ë˜ 4ê°œ íŒŒì¼ì€ **í•„ìˆ˜**ì´ê³ , ì´ë™ ì´ë ¥(`bulk_move_log.csv`)ì€ **ìˆìœ¼ë©´ ì—…ë¡œë“œ, ì—†ìœ¼ë©´ ìƒëµ**í•´ë„ ë©ë‹ˆë‹¤.
        """
    )

    col_left, col_right = st.columns(2)

    with col_left:
        bulk_file = st.file_uploader(
            "1) bulk_drums_extended.csv (í•„ìˆ˜)",
            type=["csv"],
            key="first_up_bulk",
        )
        st.caption(last_upload_caption(CSV_PATH))

        prod_file = st.file_uploader(
            "2) production.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        recv_file = st.file_uploader(
            "3) receive.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        stock_file = st.file_uploader(
            "4) stock.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

    with col_right:
        move_file = st.file_uploader(
            "5) bulk_move_log.csv (ì„ íƒ)",
            type=["csv"],
            key="first_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))
        st.caption("â€» ì—†ìœ¼ë©´ ì—…ë¡œë“œ ì•ˆ í•´ë„ ë©ë‹ˆë‹¤. ìƒˆ ë¡œê·¸ë¡œ ì‹œì‘í•´ìš”.")

    if st.button("ì—…ë¡œë“œ ì™„ë£Œ", key="first_upload_done"):
        missing = []
        if bulk_file is None:
            missing.append("bulk_drums_extended.csv")
        if prod_file is None:
            missing.append("production.xlsx")
        if recv_file is None:
            missing.append("receive.xlsx")
        if stock_file is None:
            missing.append("stock.xlsx")

        if missing:
            st.error("ë‹¤ìŒ í•„ìˆ˜ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”: " + ", ".join(missing))
            return

        # ---------- 1) ì—…ë¡œë“œ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ì„¸ì…˜ì— ì €ì¥ ----------
        bulk_bytes = bulk_file.read()
        prod_bytes = prod_file.read()
        recv_bytes = recv_file.read()
        stock_bytes = stock_file.read()
        move_bytes = move_file.read() if move_file is not None else None

        ss["bulk_csv_bytes"] = bulk_bytes
        ss["prod_xlsx_bytes"] = prod_bytes
        ss["recv_xlsx_bytes"] = recv_bytes
        ss["stock_xlsx_bytes"] = stock_bytes
        if move_bytes is not None:
            ss["move_log_csv_bytes"] = move_bytes

        # ğŸ”¹ S3 ì—…ë¡œë“œ (ì›ë³¸ ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ ë³´ê´€)
        s3_upload_bytes(CSV_PATH, bulk_bytes)
        s3_upload_bytes(PRODUCTION_FILE, prod_bytes)
        s3_upload_bytes(RECEIVE_FILE, recv_bytes)
        s3_upload_bytes(STOCK_FILE, stock_bytes)
        if move_bytes is not None:
            s3_upload_bytes(MOVE_LOG_CSV, move_bytes)

        # ---------- 2) ì„œë²„ ë¡œì»¬ íŒŒì¼ë¡œë„ ì €ì¥ (ì´í›„ ì„¸ì…˜ì—ì„œ ì¬ì‚¬ìš©) ----------
        try:
            _load_drums_core.clear()
            df_bulk = _load_drums_core(bulk_bytes)
            df_bulk.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
        except Exception:
            pass

        try:
            _load_production_core.clear()
            df_prod = _load_production_core(prod_bytes)
            df_prod.to_excel(PRODUCTION_FILE, index=False)
        except Exception:
            pass

        try:
            _load_receive_core.clear()
            df_recv = _load_receive_core(recv_bytes)
            df_recv.to_excel(RECEIVE_FILE, index=False)
        except Exception:
            pass

        try:
            _load_stock_core.clear()
            df_stock = _load_stock_core(stock_bytes)
            df_stock.to_excel(STOCK_FILE, index=False)
        except Exception:
            pass

        if move_bytes is not None:
            try:
                _load_move_log_core.clear()
                df_move = _load_move_log_core(move_bytes)
                df_move.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
            except Exception:
                pass

        # ---------- 3) í”Œë˜ê·¸ ì„¸íŒ… í›„ ë©”ì¸ìœ¼ë¡œ ----------
        ss["data_initialized"] = True

        st.success("íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.rerun()


# ==============================
# ë¡œê·¸ì¸ í™”ë©´
# ==============================
def render_login():
    ss = st.session_state

    # ğŸ”¹ ì´ì „ì— ë¡œê·¸ì¸í–ˆë˜ IDê°€ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ê¸°
    #    (ë‹¨, ì´ë²ˆ ì„¸ì…˜ì—ì„œ login_idê°€ ì•„ì§ ì•ˆ ë§Œë“¤ì–´ì¡Œì„ ë•Œë§Œ)
    if "last_login_id" in ss and "login_id" not in ss:
        ss["login_id"] = ss["last_login_id"]

    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë¡œê·¸ì¸")
    st.markdown("ì‘ì—… ì „ IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    # âœ… form ì‚¬ìš©: ì—”í„°ë¡œë„ ë¡œê·¸ì¸, ë²„íŠ¼ìœ¼ë¡œë„ ë¡œê·¸ì¸
    with st.form("login_form"):
        login_id = st.text_input("ID", key="login_id")
        login_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")

        login_submitted = st.form_submit_button("ë¡œê·¸ì¸")

    # í¼ ì œì¶œ(ì—”í„° ë˜ëŠ” ë²„íŠ¼ í´ë¦­) ì‹œ ë¡œê·¸ì¸ ì²˜ë¦¬
    if login_submitted:
        user = USER_ACCOUNTS.get((login_id or "").strip())

        if user and login_pw == user["password"]:
            ss["user_id"] = (login_id or "").strip()
            ss["user_name"] = user["display_name"]

            # ğŸ”¹ ë§ˆì§€ë§‰ì— ì„±ê³µì ìœ¼ë¡œ ë¡œê·¸ì¸í•œ ID ê¸°ì–µ
            ss["last_login_id"] = (login_id or "").strip()

            # í˜¹ì‹œ ì˜ˆì „ì— ì“°ë˜ ë¡œê·¸ì¸ ìœ ì§€ ê´€ë ¨ í‚¤ê°€ ìˆë‹¤ë©´ ì •ë¦¬ (ì„ íƒ ì‚¬í•­)
            for k in ["remember_me", "login_remember_checkbox"]:
                if k in ss:
                    del ss[k]

            st.success(f"{user['display_name']}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.")
            st.rerun()
        else:
            st.error("ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def get_stock_summary(item_code: str, lot: str):
    """
    stock.xlsxì—ì„œ 'í’ˆë²ˆ + ë¡œíŠ¸ë²ˆí˜¸' ê¸°ì¤€ìœ¼ë¡œ ì „ì‚° ì¬ê³  ìš”ì•½ì„ êµ¬í•œë‹¤.

    stock.xlsx ì»¬ëŸ¼ êµ¬ì¡° (ì¤‘ìš”):
      - Aì—´: ì°½ê³ /ì‘ì—…ì¥
      - Bì—´: ì°½ê³ /ì‘ì—…ì¥ëª…
      - Cì—´: í’ˆë²ˆ
      - Gì—´: ë¡œíŠ¸ë²ˆí˜¸
      - Kì—´: ì‹¤ì¬ê³ ìˆ˜ëŸ‰
    """
    stock_df = load_stock()
    if stock_df is None or stock_df.empty:
        return None, ""

    df = stock_df.copy()

    # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³ , ì´ë¦„ í†µì¼
    required_cols = ["ì°½ê³ /ì‘ì—…ì¥", "ì°½ê³ /ì‘ì—…ì¥ëª…", "í’ˆë²ˆ", "ë¡œíŠ¸ë²ˆí˜¸", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]
    for c in required_cols:
        if c not in df.columns:
            # í•„ìš”í•œ ì»¬ëŸ¼ì´ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ìš”ì•½ ë¶ˆê°€
            return None, ""

    # ë¬¸ìì—´ ì •ë¦¬
    df["í’ˆë²ˆ"] = df["í’ˆë²ˆ"].astype(str).str.strip()
    df["ë¡œíŠ¸ë²ˆí˜¸"] = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.strip().str.upper()

    item_key = str(item_code).strip()
    lot_key = str(lot).strip().upper()

    # í’ˆë²ˆ + ë¡œíŠ¸ë²ˆí˜¸ ì™„ì „ ì¼ì¹˜
    df = df[(df["í’ˆë²ˆ"] == item_key) & (df["ë¡œíŠ¸ë²ˆí˜¸"] == lot_key)]

    if df.empty:
        return None, ""

    # ì‹¤ì¬ê³ ìˆ˜ëŸ‰ ìˆ«ìí™” + 0 ì œì™¸
    df["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"] = pd.to_numeric(df["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
    df = df[df["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"] != 0]

    if df.empty:
        return None, ""

    # ----- ëŒ€ë¶„ë¥˜ ë§¤í•‘ -----
    ONSITE_CODES = {"WC301", "WC501", "WC502", "WC503", "WC504"}
    WAREHOUSE_CODES = {"WH201", "WH701", "WH301", "WH601", "WH401", "WH506"}
    DEFECT_CODES = {"WH001", "WH102"}

    def classify(code: str) -> str:
        code = str(code).strip()
        if code in ONSITE_CODES:
            return "ìì‚¬"
        if code in WAREHOUSE_CODES:
            return "ì°½ê³ "
        if code in DEFECT_CODES:
            return "ë¶ˆëŸ‰"
        return "ì™¸ì£¼"

    df["ëŒ€ë¶„ë¥˜"] = df["ì°½ê³ /ì‘ì—…ì¥"].apply(classify)

    # í™”ë©´ì—ì„œ ì“°ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
    summary = df[["ì°½ê³ /ì‘ì—…ì¥", "ì°½ê³ /ì‘ì—…ì¥ëª…", "í’ˆë²ˆ", "ë¡œíŠ¸ë²ˆí˜¸", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰", "ëŒ€ë¶„ë¥˜"]].copy()
    summary = summary.rename(
        columns={
            "ì°½ê³ /ì‘ì—…ì¥": "ì°½ê³ ì½”ë“œ",
            "ì°½ê³ /ì‘ì—…ì¥ëª…": "ì°½ê³ ëª…",
        }
    )

    # ì¬ê³  ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    summary = summary.sort_values("ì‹¤ì¬ê³ ìˆ˜ëŸ‰", ascending=False).reset_index(drop=True)

    return summary, ""




# ==============================
# íƒ­ 1: ì´ë™ - ì…ë ¥ê°’ ì´ˆê¸°í™”
# ==============================
def clear_move_inputs():
    """ì´ë™ íƒ­ ì…ë ¥ê°’/ê²€ìƒ‰ ìƒíƒœ ì´ˆê¸°í™” ì½œë°±."""
    ss = st.session_state

    for k in [
        "mv_last_lot",
        "mv_last_barcode",
        "mv_search_by_lot",
        "mv_searched_csv",
        "mv_show_stock_detail",
        "mv_show_move_history_here",
        "clicked_zone_csv",
        "mv_just_searched",
    ]:
        if k in ss:
            del ss[k]

            
# ==============================
# íƒ­ 1: ì´ë™
# ==============================
def render_tab_move():
    st.markdown("### ğŸ“¦ ë²Œí¬ ì´ë™")

    ss = st.session_state
    ss.setdefault("mv_searched_csv", False)
    ss.setdefault("mv_search_by_lot", False)
    ss.setdefault("mv_show_stock_detail", False)
    ss.setdefault("mv_show_move_history_here", False)
    ss.setdefault("mv_input_version", 0)
    input_ver = ss["mv_input_version"]

    # ğŸ”¹ ë²Œí¬ êµ¬ë¶„ì€ í¼ ë°–ì—ì„œ ì¦‰ì‹œ ë°˜ì˜ë˜ê²Œ
    bulk_type = st.radio(
        "ë²Œí¬ êµ¬ë¶„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
        ["ìì‚¬", "ì‚¬ê¸‰"],
        horizontal=True,
        key="mv_bulk_type_csv",
    )

    # ================== ê²€ìƒ‰ í¼ (ì—”í„° + ë²„íŠ¼ ë‘˜ ë‹¤ ê°€ëŠ¥) ==================
    with st.form("move_search_form"):
        barcode_label = (
            "ì‘ì—…ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
            if bulk_type == "ìì‚¬"
            else "ì…í•˜ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
        )

        # ğŸ”¹ ì…ë ¥ì¹¸ ë‘ ê°œ ë‚˜ë€íˆ
        col_in1, col_in2, _sp = st.columns([1, 1, 2.5])
        with col_in1:
            barcode = st.text_input(
                barcode_label,
                key=f"mv_barcode_{input_ver}",
                placeholder="ì˜ˆ: W24012345",
            )
        with col_in2:
            lot_input = st.text_input(
                "ë¡œíŠ¸ë²ˆí˜¸",
                key=f"mv_lot_{input_ver}",
                placeholder="ì˜ˆ: 2E075K",
            )

        # ğŸ”¹ ì¡°íšŒí•˜ê¸° / ì´ˆê¸°í™” ë²„íŠ¼ í•œ ì¤„
        col_b1, col_b2, _sp2 = st.columns([1, 1, 6])
        with col_b1:
            search_submit = st.form_submit_button("ì¡°íšŒí•˜ê¸°", use_container_width=True)
        with col_b2:
            reset_submit = st.form_submit_button("ì´ˆê¸°í™”", use_container_width=True)

    # ----- ì´ˆê¸°í™” ë²„íŠ¼ ì²˜ë¦¬ -----
    if reset_submit:
        clear_move_inputs()          # ê²€ìƒ‰ ìƒíƒœ ì´ˆê¸°í™” (ì…ë ¥ì¹¸ì€ ë²„ì „ìœ¼ë¡œ ë¦¬ì…‹)
        ss["mv_input_version"] += 1  # ğŸ‘‰ ìƒˆ í‚¤ë¡œ ìœ„ì ¯ ì¬ìƒì„± â†’ ê°’ ì™„ì „ ì‚­ì œ
        st.rerun()

    # ----- ì¡°íšŒ ë²„íŠ¼: ì´ë²ˆ ì…ë ¥ì„ "ë§ˆì§€ë§‰ ì¡°íšŒ ì¡°ê±´"ìœ¼ë¡œ ì €ì¥ -----
    if search_submit:
        lot_val = (lot_input or "").strip()
        barcode_val = (barcode or "").strip()

        ss["mv_last_lot"] = lot_val
        ss["mv_last_barcode"] = barcode_val
        ss["mv_search_by_lot"] = bool(lot_val)  # ë¡œíŠ¸ê°€ ìˆìœ¼ë©´ ë¡œíŠ¸ ê¸°ì¤€ ì¡°íšŒ
        ss["mv_searched_csv"] = True
        ss["mv_just_searched"] = True

    # ğŸ”¹ í•œ ë²ˆë„ ì¡°íšŒí•œ ì  ì—†ìœ¼ë©´ ì•„ë˜ëŠ” ì•ˆ ê·¸ë¦¼
    if not ss.get("mv_searched_csv", False):
        return

    # ì—¬ê¸°ë¶€í„°ëŠ” "ë§ˆì§€ë§‰ ì¡°íšŒ ì¡°ê±´" ê¸°ë°˜ìœ¼ë¡œ í•­ìƒ í™”ë©´ ê·¸ë¦¼
    bulk_type = ss.get("mv_bulk_type_csv", "ìì‚¬")
    df = load_drums()
    prod_df = load_production()
    recv_df = load_receive()

    lot = ""
    item_code = ""
    item_name = ""
    prod_date = ""
    prod_qty = None
    line = ""
    barcode_used = ""
    lot_lower = ""

    search_by_lot = ss.get("mv_search_by_lot", False)

    # ================== ë¡œíŠ¸ / ì‘ì—…ë²ˆí˜¸ / ì…í•˜ë²ˆí˜¸ í•´ì„ ==================
    if search_by_lot:
        lot_input = (ss.get("mv_last_lot") or "").strip()
        if not lot_input:
            st.warning("ë¡œíŠ¸ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return

        # LOTëŠ” í•­ìƒ ëŒ€ë¬¸ìë¡œ ì €ì¥
        lot = lot_input.upper()
        # ê²€ìƒ‰ìš© LOTëŠ” ì†Œë¬¸ìë¡œ
        lot_lower = lot_input.lower()
        barcode_used = lot_input

    else:
        barcode_query = (ss.get("mv_last_barcode") or "").strip()
        if not barcode_query:
            st.warning("ì‘ì—…ë²ˆí˜¸/ì…í•˜ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return

        barcode_used = barcode_query
        q = barcode_query.strip().lower()

        if bulk_type == "ìì‚¬":
            if prod_df.empty:
                st.error("production.xlsx íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ ì‘ì—…ë²ˆí˜¸ ê¸°ë°˜ ì¡°íšŒ ë¶ˆê°€í•©ë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            prod_df["_ì‘ë²ˆ_norm"] = prod_df["ì‘ì—…ë²ˆí˜¸"].astype(str).str.strip().str.lower()
            hit = prod_df[prod_df["_ì‘ë²ˆ_norm"] == q]

            if hit.empty:
                st.warning("í•´ë‹¹ ì‘ì—…ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]

            lot = str(r["LOTNO"]).strip().upper()
            lot_lower = lot.lower()
            item_code = str(r["í’ˆë²ˆ"]).strip()
            item_name = str(r["í’ˆëª…"]).strip()
            prod_qty = float(r["ì œì¡°ëŸ‰"]) if not pd.isna(r["ì œì¡°ëŸ‰"]) else None
            prod_date = "" if pd.isna(r["ì‘ì—…ì¼ì"]) else str(r["ì‘ì—…ì¼ì"])
            line = classify_product_line(item_code)

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

        else:
            # ì‚¬ê¸‰
            if recv_df.empty:
                st.error("receive.xlsx íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            recv_df["_ì…í•˜_norm"] = recv_df["ì…í•˜ë²ˆí˜¸"].astype(str).str.strip().str.lower()
            hit = recv_df[recv_df["_ì…í•˜_norm"] == q]

            if hit.empty:
                st.warning("í•´ë‹¹ ì…í•˜ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]

            item_code = str(r["í’ˆë²ˆ"]).strip()
            item_name = str(r["í’ˆëª…"]).strip()
            lot = str(r["ë¡œíŠ¸ë²ˆí˜¸"]).strip().upper()
            lot_lower = lot.lower()

            # ì…í•˜ëŸ‰ â†’ ì œì¡°ëŸ‰ì²˜ëŸ¼ ì‚¬ìš©
            if "ì…í•˜ëŸ‰" in recv_df.columns:
                prod_qty = float(r["ì…í•˜ëŸ‰"]) if not pd.isna(r["ì…í•˜ëŸ‰"]) else None
            else:
                prod_qty = None

            # ì œì¡°ì¼ì ê³„ì—´ ì²˜ë¦¬
            if "ì œì¡°ì¼ì" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ì¼ì"]) else str(r["ì œì¡°ì¼ì"])
            elif "ì œì¡°ë…„ì›”ì¼" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ë…„ì›”ì¼"]) else str(r["ì œì¡°ë…„ì›”ì¼"])
            else:
                prod_date = ""

            # stock.xlsxì—ì„œ ìœ /ë¬´ìƒ ìë™ íŒë‹¨
            line = "ì‚¬ê¸‰"
            trade_type = ""

            try:
                stock_df = load_stock()
            except Exception:
                stock_df = pd.DataFrame()

            if not stock_df.empty:
                cond = (
                    stock_df["í’ˆë²ˆ"].astype(str).str.strip() == item_code
                ) & (
                    stock_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.strip().str.upper() == lot
                )

                sub = stock_df[cond]
                if not sub.empty and "ìœ /ë¬´ìƒ" in sub.columns:
                    trade_type = str(sub.iloc[0]["ìœ /ë¬´ìƒ"]).strip()

            # stockì— ì—†ìœ¼ë©´ receiveì˜ ê°’ ì‚¬ìš©
            if not trade_type:
                trade_type = str(r.get("ìœ /ë¬´ìƒ", "")).strip()

            if trade_type == "ìœ ìƒ":
                line = "ì‚¬ê¸‰(ìœ ìƒ)"
            elif trade_type == "ë¬´ìƒ":
                line = "ì‚¬ê¸‰(ë¬´ìƒ)"
            else:
                line = "ì‚¬ê¸‰"

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

            # ==============================
            # stock.xlsx ê¸°ì¤€ìœ¼ë¡œ ìœ /ë¬´ìƒ íŒë‹¨
            # ==============================
            line = "ì‚¬ê¸‰"  # ê¸°ë³¸ê°’

            try:
                stock_df = load_stock()
            except Exception:
                stock_df = pd.DataFrame()

            trade_type = ""

            if not stock_df.empty:
                # ì»¬ëŸ¼ëª…: A=ì°½ê³ /ì‘ì—…ì¥, B=ì°½ê³ /ì‘ì—…ì¥ëª…, C=í’ˆë²ˆ, G=ë¡œíŠ¸ë²ˆí˜¸, K=ì‹¤ì¬ê³ ìˆ˜ëŸ‰, T=ìœ /ë¬´ìƒ
                # â†’ ì—¬ê¸°ì„œ C(í’ˆë²ˆ), G(ë¡œíŠ¸ë²ˆí˜¸), T(ìœ /ë¬´ìƒ) ì‚¬ìš©
                cond = (
                    stock_df["í’ˆë²ˆ"].astype(str) == item_code
                ) & (
                    stock_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == lot
                )

                sub = stock_df[cond]
                if not sub.empty and "ìœ /ë¬´ìƒ" in sub.columns:
                    # ì—¬ëŸ¬ í–‰ì´ë©´ ì²« í–‰ ê¸°ì¤€
                    trade_type = str(sub.iloc[0]["ìœ /ë¬´ìƒ"]).strip()

            # stockì— ê°’ì´ ì—†ìœ¼ë©´ receiveì˜ ìœ /ë¬´ìƒì„ ë°±ì—…ìœ¼ë¡œ ì‚¬ìš©
            if not trade_type:
                trade_type = str(r.get("ìœ /ë¬´ìƒ", "")).strip()

            if trade_type == "ìœ ìƒ":
                line = "ì‚¬ê¸‰(ìœ ìƒ)"
            elif trade_type == "ë¬´ìƒ":
                line = "ì‚¬ê¸‰(ë¬´ìƒ)"
            else:
                line = "ì‚¬ê¸‰"

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

    # ---------- LOT ê¸°ì¤€ìœ¼ë¡œ CSV ì¡°íšŒ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) ----------
    df = load_drums()
    df["lot_lower"] = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
    lot_df = df[df["lot_lower"] == lot_lower].copy()

    if lot_df.empty:
        st.warning("CSVì—ì„œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ í†µ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ss["mv_searched_csv"] = False
        return

    combos = lot_df[["í’ˆëª©ì½”ë“œ", "í’ˆëª…"]].drop_duplicates().reset_index(drop=True)
    if len(combos) == 1:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])
    elif len(combos) > 1 and ss.get("mv_search_by_lot", False):
        st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì— ì—¬ëŸ¬ í’ˆëª…ì´ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        options = [
            f"{row['í’ˆëª©ì½”ë“œ']} / {row['í’ˆëª…']}"
            for _, row in combos.iterrows()
        ]
        selected_label = st.selectbox(
            "í’ˆëª…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            options,
            key=f"mv_lot_item_select_{lot}",
        )
        sel_idx = options.index(selected_label)
        item_code = str(combos.at[sel_idx, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[sel_idx, "í’ˆëª…"])
        lot_df = lot_df[
            (lot_df["í’ˆëª©ì½”ë“œ"].astype(str) == item_code)
            & (lot_df["í’ˆëª…"].astype(str) == item_name)
        ].copy()
    else:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])

    if not prod_date:
        dates = (
            lot_df["ì œì¡°ì¼ì"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if dates:
            prod_date = dates[0]

    if not line:
        lines = (
            lot_df["ì œí’ˆë¼ì¸"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if lines:
            line = lines[0]

    lot_df = lot_df.sort_values("í†µë²ˆí˜¸")

    lot_df = lot_df.sort_values("í†µë²ˆí˜¸")

    loc_unique = lot_df["í˜„ì¬ìœ„ì¹˜"].dropna().unique().tolist()
    if len(loc_unique) == 1:
        current_zone = loc_unique[0]
    elif len(loc_unique) == 0:
        current_zone = "ë¯¸ì§€ì •"
    else:
        current_zone = "í˜¼í•©"

    # stock.xlsx ê¸°ë°˜ ì „ì‚° ì¬ê³  ìš”ì•½
    stock_summary_df, _ = get_stock_summary(item_code, lot)
    if stock_summary_df is not None and not stock_summary_df.empty:
        top = stock_summary_df.iloc[0]
        # ì˜ˆ: ìì‚¬(ìŠ¤í‹±,íŒŒìš°ì¹˜ ì¶©í¬ì¥ì‹¤) 10kg
        qty_int = int(top["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]) if pd.notna(top["ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]) else 0
        stock_loc_display = f"{top['ëŒ€ë¶„ë¥˜']}({top['ì°½ê³ ëª…']}) {qty_int}kg"
    else:
        stock_loc_display = current_zone


    # ì´ë™ì— ì‚¬ìš©í•  ë³€ìˆ˜ (ì¢Œ/ìš° ì»¬ëŸ¼ì—ì„œ ê°™ì´ ì”€)
    selected_drums = []
    drum_new_qty = {}

    col_left2, col_right2 = st.columns(2)

    # ===== ì™¼ìª½: ì¡°íšŒ ì •ë³´ + í†µ ì„ íƒ =====
    with col_left2:
        st.markdown("### ğŸ§¾ ì¡°íšŒ ì •ë³´")
        st.success("ì¡°íšŒê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.markdown(
            f"""
            **ë²Œí¬ êµ¬ë¶„:** {bulk_type}  
            **ì‹ë³„ê°’:** {barcode_used}  
            **í’ˆëª©ì½”ë“œ:** {item_code}  
            **í’ˆëª…:** {item_name}  
            **ë¡œíŠ¸ë²ˆí˜¸:** {lot}  
            **ì œì¡°ì¼ì:** {prod_date}  
            """
        )

        # í˜„ì¬ ìœ„ì¹˜ + [ìƒì„¸ë³´ê¸°] + [ì´ë™ì´ë ¥]
        loc_col1, loc_col2 = st.columns([3, 2])
        with loc_col1:
            st.markdown(f"**í˜„ì¬ ìœ„ì¹˜(ì „ì‚° ê¸°ì¤€):** {stock_loc_display}")
        with loc_col2:
            b1_col, b_sp, b2_col = st.columns([1, 0.05, 1])
            with b1_col:
                if st.button("ìƒì„¸ë³´ê¸°", key=f"stock_detail_btn_{lot}"):
                    ss["mv_show_stock_detail"] = not ss.get("mv_show_stock_detail", False)
            with b2_col:
                if st.button("ì´ë™ì´ë ¥", key=f"move_hist_btn_{lot}"):
                    ss["mv_show_move_history_here"] = not ss.get("mv_show_move_history_here", False)

        # ğŸ” ì „ì‚° ì¬ê³  ìƒì„¸ (ìƒì„¸ë³´ê¸° ëˆŒë €ì„ ë•Œë§Œ)
        if ss.get("mv_show_stock_detail", False):
            if stock_summary_df is not None and not stock_summary_df.empty:
                st.markdown("#### ğŸ” ì „ì‚° ì¬ê³  ìƒì„¸")

                # ì›ë³¸ ë³µì‚¬
                detail_df = stock_summary_df.copy()

                # ì‹¤ì œ ë³´ì—¬ì¤„ ì»¬ëŸ¼ë§Œ ìœ ì§€
                detail_df = detail_df[["ì°½ê³ ì½”ë“œ", "ì°½ê³ ëª…", "ì‹¤ì¬ê³ ìˆ˜ëŸ‰"]].reset_index(drop=True)

                # í–‰ ìˆ˜ì— ë§ì¶˜ ë™ì  ë†’ì´ ê³„ì‚°
                header_height = 40
                row_height = 32
                n_rows = len(detail_df)
                table_height = header_height + row_height * max(n_rows, 1)

                st.dataframe(
                    detail_df,
                    use_container_width=True,
                    height=table_height,
                )
            else:
                st.info("ì „ì‚° ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ğŸ”´ ì—¬ê¸°ë¶€í„°ëŠ” ìƒì„¸ë³´ê¸°ì™€ ìƒê´€ì—†ì´ í•­ìƒ ë³´ì—¬ì•¼ í•˜ëŠ” ì˜ì—­
        st.markdown("### âœ… í†µ ì„ íƒ ë° ì”ëŸ‰ ì…ë ¥")

        selected_drums = []
        drum_new_qty = {}

        # âœ… index ê¸°ì¤€ìœ¼ë¡œ keyë¥¼ ë§Œë“¤ì–´ì„œ ì¤‘ë³µ ë°©ì§€
        lot_df = lot_df.reset_index(drop=True)
        index_list = lot_df.index.tolist()

        c1, c_sp, c2, _c_gap = st.columns([2, 0.5, 2, 7])
        with c1:
            if st.button("ëª¨ë‘ ì„ íƒ", key=f"mv_select_all_{lot}", use_container_width=False):
                for idx in index_list:
                    st.session_state[f"mv_sel_{lot}_{idx}"] = True
        with c2:
            if st.button("ëª¨ë‘ í•´ì œ", key=f"mv_select_none_{lot}", use_container_width=False):
                for idx in index_list:
                    st.session_state[f"mv_sel_{lot}_{idx}"] = False

        for idx, row in lot_df.iterrows():
            drum_no = int(row["í†µë²ˆí˜¸"])
            old_qty = float(row["í†µìš©ëŸ‰"])
            drum_loc = str(row.get("í˜„ì¬ìœ„ì¹˜", "") or "").strip()

            if drum_loc:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg (ìœ„ì¹˜: {drum_loc})"
            else:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg"

            cb_key = f"mv_sel_{lot}_{idx}"
            checked = st.checkbox(label, key=cb_key)
            if checked:
                selected_drums.append(drum_no)
                new_val = st.number_input(
                    f"í†µ {drum_no}ì˜ í˜„ì¬ ìš©ëŸ‰(kg)",
                    min_value=0.0,
                    max_value=old_qty,
                    value=old_qty,
                    step=10.0,
                    format="%.0f",
                    key=f"mv_qty_{lot}_{drum_no}",
                )
                drum_new_qty[drum_no] = float(new_val)


    # ===== ì˜¤ë¥¸ìª½: ì´ë™ ìœ„ì¹˜ + ìƒíƒœ + ë¹„ê³  + ì €ì¥ =====
    with col_right2:
        st.markdown("### ğŸšš ì´ë™ ìœ„ì¹˜ ì„ íƒ")

        col1, col2 = st.columns(2)
        with col1:
            from_zone = st.text_input(
                "í˜„ì¬ ìœ„ì¹˜",
                value=current_zone if current_zone != "í˜¼í•©" else "",
                help="ì˜ˆ: 4ì¸µ ë¡œíƒ€ë¦¬, ì™¸ì£¼ ë“±",
                key="mv_from_zone_csv",
            )
        with col2:
            to_zone = location_picker("mv_to")

        if to_zone == "ì™¸ì£¼":
            move_status = "ì™¸ì£¼"
            st.info("ì´ë™ ìœ„ì¹˜ê°€ 'ì™¸ì£¼'ì´ë¯€ë¡œ ìƒíƒœëŠ” ìë™ìœ¼ë¡œ 'ì™¸ì£¼'ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
        else:
            move_status = st.radio(
                "ì´ë™ í›„ ìƒíƒœë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
                ["ì”ëŸ‰", "ìƒì‚°ëŒ€ê¸°", "ìƒì‚°ì¢…ë£Œ"],
                horizontal=True,
                key="mv_status_csv",
            )

        note = st.text_area("ë¹„ê³ (ì„ íƒ ì…ë ¥)", height=80, key="mv_note_csv")

        if st.button("ì´ë™ ë‚´ìš© ì €ì¥ (CSV ë°˜ì˜)", key="mv_save_csv"):
            if not selected_drums:
                st.warning("ì´ë™í•˜ì‹¤ í†µì„ í•œ ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                return

            df_all = load_drums()
            df_all["lot_lower"] = df_all["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
            lot_mask = df_all["lot_lower"] == lot_lower
            
            # ğŸ”¹ ì‚¬ê¸‰ ë²Œí¬ì¸ ê²½ìš°, ìµœì´ˆ ì…ê³  ìƒíƒœ(í˜„ì¬ìœ„ì¹˜ = 'ë¯¸ì§€ì •')ì˜ í†µì—ë§Œ ì œí’ˆë¼ì¸ì„ ê¸°ë¡
            if bulk_type == "ì‚¬ê¸‰" and line:
                df_all.loc[lot_mask & (df_all["í˜„ì¬ìœ„ì¹˜"] == "ë¯¸ì§€ì •"), "ì œí’ˆë¼ì¸"] = line

            drum_logs = []

            for dn in selected_drums:
                idx = df_all.index[lot_mask & (df_all["í†µë²ˆí˜¸"] == dn)]
                if len(idx) == 0:
                    continue
                i = idx[0]
                old_qty = float(df_all.at[i, "í†µìš©ëŸ‰"])
                old_loc = str(df_all.at[i, "í˜„ì¬ìœ„ì¹˜"])
                new_qty = drum_new_qty.get(dn, old_qty)
                moved = old_qty - new_qty

                df_all.at[i, "í†µìš©ëŸ‰"] = new_qty
                df_all.at[i, "í˜„ì¬ìœ„ì¹˜"] = to_zone

                if to_zone == "ì™¸ì£¼":
                    df_all.at[i, "ìƒíƒœ"] = "ì™¸ì£¼"
                else:
                    df_all.at[i, "ìƒíƒœ"] = move_status

                # (í†µë²ˆí˜¸, ë³€í™”ëŸ‰, ë³€ê²½ ì „ ìš©ëŸ‰, ë³€ê²½ í›„ ìš©ëŸ‰, ë³€ê²½ ì „ ìœ„ì¹˜)
                drum_logs.append((dn, moved, old_qty, new_qty, old_loc))

            save_drums(df_all)

            write_move_log(
                item_code=item_code,
                item_name=item_name,
                lot=lot,
                drum_infos=drum_logs,
                from_zone=from_zone,
                to_zone=to_zone,
            )

            st.success(f"ì´ {len(drum_logs)}ê°œì˜ í†µ ì •ë³´ê°€ CSV ë° ì´ë™ ì´ë ¥ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ================== ì´ë™ íƒ­ ë‚´ë¶€ LOT ì´ë™ ì´ë ¥ ==================
    if ss.get("mv_show_move_history_here", False):
        log_df = load_move_log()
        if log_df.empty:
            st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sub = log_df[log_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower() == lot_lower].copy()
            if sub.empty:
                st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("### ğŸ“œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ ì´ë™ ì´ë ¥")
                sub = sub.sort_values("ì‹œê°„", ascending=False).head(50)
                st.dataframe(sub, use_container_width=True)

# ==============================
# íƒ­ 2: ì¡°íšŒ
# ==============================
def render_tab_lookup():
    st.markdown("### ğŸ” ë²Œí¬ ì¡°íšŒ")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì œì¡°ì¼ì ê¸°ì¤€ TAT(ê°œì›”) ì»¬ëŸ¼ ì¶”ê°€
    df = add_tat_column(df)

    query = st.text_input("ë¡œíŠ¸ë²ˆí˜¸, í’ˆëª©ì½”ë“œ ë˜ëŠ” í’ˆëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    if query:
        q = query.strip()
        mask = (
            df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.contains(q, case=False, na=False)
            | df["í’ˆëª©ì½”ë“œ"].astype(str).str.contains(q, case=False, na=False)
            | df["í’ˆëª…"].astype(str).str.contains(q, case=False, na=False)
        )
        df_view = df[mask]
    else:
        df_view = df

    # ìš©ëŸ‰ 0 í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸: ë¯¸í¬í•¨)
    include_zero = st.checkbox("ìš©ëŸ‰ 0 í¬í•¨", value=False)

    if not include_zero:
        df_view = df_view[df_view["í†µìš©ëŸ‰"] > 0]

    # =========================
    # 1ì°¨: bulk CSV ì—ì„œ ê²€ìƒ‰
    # =========================
    # ğŸ”» 1ì°¨: CSVì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ production.xlsxì—ì„œ 2ì°¨ ê²€ìƒ‰
    if df_view.empty:
        if not query:
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        prod_df = load_production()
        if prod_df.empty:
            st.info("bulk CSVì™€ production.xlsx ëª¨ë‘ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        q = query.strip()

        # LOTNO / í’ˆëª… ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
        mask_prod = (
            prod_df["LOTNO"].astype(str).str.contains(q, case=False, na=False)
            | prod_df["í’ˆëª…"].astype(str).str.contains(q, case=False, na=False)
        )
        prod_view = prod_df[mask_prod].copy()

        # ğŸ”¹ ì œì¡°ì¼ì(ì‘ì—…ì¼ì) ê¸°ì¤€ ìµœê·¼ 30ì¼ ì´ë‚´ë§Œ ë‚¨ê¸°ê¸°
        today = datetime.today()
        prod_view["ì‘ì—…ì¼ì"] = pd.to_datetime(prod_view["ì‘ì—…ì¼ì"], errors="coerce")
        prod_view = prod_view[
            (today - prod_view["ì‘ì—…ì¼ì"]).dt.days <= 30
        ]

        if prod_view.empty:
            st.info("ìµœê·¼ 1ê°œì›” ì´ë‚´ ì œì¡°ëœ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ===== production ê¸°ë°˜ ê°€ìƒ ë²Œí¬í†µ ìƒì„± =====
        drums_rows = []

        for _, r in prod_view.iterrows():
            item_code = str(r["í’ˆë²ˆ"])
            item_name = str(r["í’ˆëª…"])
            lot = str(r["LOTNO"]).strip().upper()

            # ì œì¡°ì¼ì(ì‘ì—…ì¼ì)ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ
            raw_date = r["ì‘ì—…ì¼ì"]
            try:
                mfg_date = str(pd.to_datetime(raw_date).date())  # YYYY-MM-DD
            except Exception:
                mfg_date = str(raw_date)

            prod_qty = float(r["ì œì¡°ëŸ‰"]) if not pd.isna(r["ì œì¡°ëŸ‰"]) else None

            # ì œì¡°ëŸ‰ â†’ í†µë²ˆí˜¸ ìë™ ìƒì„±
            drums = generate_drums(prod_qty)

            for d in drums:
                drums_rows.append(
                    {
                        "í’ˆëª©ì½”ë“œ": item_code,
                        "í’ˆëª…": item_name,
                        "ë¡œíŠ¸ë²ˆí˜¸": lot,
                        "ì œì¡°ì¼ì": mfg_date,
                        "ìƒíƒœ": "ìƒì‚°ëŒ€ê¸°",
                        "í†µë²ˆí˜¸": int(d["í†µë²ˆí˜¸"]),
                        "í†µìš©ëŸ‰": float(d["í†µìš©ëŸ‰"]),
                        "í˜„ì¬ìœ„ì¹˜": "ìì‚¬(ì œì¡°ì‹¤)",
                    }
                )

        if not drums_rows:
            st.info("production.xlsx ì— ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜ ì œì¡°ëŸ‰ì´ ì—†ì–´ í†µ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return

        drums_df = pd.DataFrame(drums_rows)

        # TAT ê³„ì‚°
        drums_df = add_tat_column(drums_df)

        st.markdown("#### ğŸ“„ ì œì¡°ì‹¤ ì¬ê³  ê²€ìƒ‰ ê²°ê³¼")

        show_cols = [
            "í’ˆëª©ì½”ë“œ",
            "í’ˆëª…",
            "ë¡œíŠ¸ë²ˆí˜¸",
            "ì œì¡°ì¼ì",
            "ìƒíƒœ",
            "í†µë²ˆí˜¸",
            "í†µìš©ëŸ‰",
            "í˜„ì¬ìœ„ì¹˜",
            "TAT",
        ]
        show_cols = [c for c in show_cols if c in drums_df.columns]

        st.data_editor(
            drums_df[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
            use_container_width=True,
            hide_index=True,
            column_config={
                "í’ˆëª©ì½”ë“œ": st.column_config.TextColumn("í’ˆëª©ì½”ë“œ", width="small"),
                "ë¡œíŠ¸ë²ˆí˜¸": st.column_config.TextColumn("ë¡œíŠ¸ë²ˆí˜¸", width="small"),
                "ì œì¡°ì¼ì": st.column_config.TextColumn("ì œì¡°ì¼ì", width="small"),
                "ìƒíƒœ": st.column_config.TextColumn("ìƒíƒœ", width="small"),
                "í†µë²ˆí˜¸": st.column_config.NumberColumn("í†µë²ˆí˜¸", width="small"),
                "í†µìš©ëŸ‰": st.column_config.NumberColumn("í†µìš©ëŸ‰", width="small"),
                "í˜„ì¬ìœ„ì¹˜": st.column_config.TextColumn("í˜„ì¬ìœ„ì¹˜", width="small"),
                "TAT": st.column_config.NumberColumn("TAT", width="small"),

                # âœ… í’ˆëª…ì— ìµœëŒ€ í­ ëª°ì•„ì£¼ê¸°
                "í’ˆëª…": st.column_config.TextColumn(
                    "í’ˆëª…",
                    width="large",
                ),
            },
        )

        st.caption(
            "â€» ì´ ë²Œí¬ëŠ” ì•„ì§ ì´ë™ ì´ë ¥ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ìœ¼ë©° "
            "ì œì¡°ì‘ì—…ì‹¤ì í˜„í™© ê¸°ë°˜ì˜ ì •ë³´ì…ë‹ˆë‹¤."
        )
        return


        # =========================
        # 2ì°¨: production.xlsx ì—ì„œ ê²€ìƒ‰
        # =========================
        prod_df = load_production()
        if prod_df.empty:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        q = query.strip()

        # LOTNO(Mì—´) / í’ˆëª…(Kì—´) ê¸°ì¤€ ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
        mask_prod = (
            prod_df["LOTNO"].astype(str).str.contains(q, case=False, na=False)
            | prod_df["í’ˆëª…"].astype(str).str.contains(q, case=False, na=False)
        )
        prod_view = prod_df[mask_prod].copy()

        if prod_view.empty:
            st.info("bulk CSVì™€ production.xlsx ì–´ë””ì—ì„œë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        st.markdown("#### ğŸ“„ ì œì¡°ì‹¤ ì¬ê³  ê²€ìƒ‰ ê²°ê³¼")

        # ìœ„ì¹˜ ì»¬ëŸ¼ ì¶”ê°€ (ê³ ì •ê°’: ìì‚¬(ì œì¡°ì‹¤))
        prod_view = prod_view.copy()
        prod_view["ìœ„ì¹˜"] = "ìì‚¬(ì œì¡°ì‹¤)"

        # ë³´ì—¬ì¤„ ê¸°ë³¸ ì»¬ëŸ¼ë“¤ (ì œì¡°ëŸ‰ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜ ì»¬ëŸ¼ ë°°ì¹˜)
        show_cols = ["ì‘ì—…ë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "LOTNO", "ì œì¡°ëŸ‰", "ìœ„ì¹˜", "ì‘ì—…ì¼ì"]
        show_cols = [c for c in show_cols if c in prod_view.columns]

        st.dataframe(
            prod_view[show_cols].sort_values("ì‘ì—…ì¼ì", ascending=False),
            use_container_width=True,
        )
        st.caption("â€» ì´ ë¡œíŠ¸ëŠ” ì•„ì§ bulk_drums_extended.csv ì— ë“±ë¡ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    # ğŸ”» ì—¬ê¸°ë¶€í„°ëŠ” CSVì—ì„œ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ
    st.markdown("#### ğŸ“„ í–‰ë³„ ìƒì„¸")
    st.dataframe(df_view, use_container_width=True)

    st.markdown("---")
    st.markdown("#### ğŸ“Š í˜„ì¬ìœ„ì¹˜ë³„ ìš©ëŸ‰ ìš”ì•½")

    def show_summary_table(df_part: pd.DataFrame, title: str, width: int = 400):
        st.markdown(f"##### {title}")
        if df_part.empty:
            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        summary = (
            df_part.groupby("í˜„ì¬ìœ„ì¹˜", dropna=False)
            .agg(
                í†µê°œìˆ˜=("í†µë²ˆí˜¸", "count"),
                ì´ìš©ëŸ‰_kg=("í†µìš©ëŸ‰", "sum"),
            )
            .reset_index()
            .sort_values("í˜„ì¬ìœ„ì¹˜")
        )

        # í•©ê³„ í–‰ ì¶”ê°€
        total_row = pd.DataFrame({
            "í˜„ì¬ìœ„ì¹˜": ["í•©ê³„"],
            "í†µê°œìˆ˜": [summary["í†µê°œìˆ˜"].sum()],
            "ì´ìš©ëŸ‰_kg": [summary["ì´ìš©ëŸ‰_kg"].sum()],
        })
        summary = pd.concat([summary, total_row], ignore_index=True)

        row_height = 35
        header_height = 40
        dynamic_height = header_height + row_height * (len(summary) + 1)

        st.dataframe(summary, width=width, height=dynamic_height)

    # ì¸µ(ë˜ëŠ” êµ¬ì—­) ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜ìš© ì»¬ëŸ¼
    tmp = df_view.copy()
    tmp["ì¸µ"] = tmp["í˜„ì¬ìœ„ì¹˜"].astype(str).str.split(" ").str[0]

    # 1) ìì‚¬ ìœ„ì¹˜: 2ì¸µ, 4ì¸µ, 5ì¸µ, 6ì¸µ
    df_onsite = tmp[tmp["ì¸µ"].isin(["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"])]

    # 2) ì™¸ì£¼
    df_outsourcing = tmp[tmp["ì¸µ"] == "ì™¸ì£¼"]

    # 3) ì°½ê³ 
    df_warehouse = tmp[tmp["ì¸µ"] == "ì°½ê³ "]

    # 4) ì†Œì§„ + íê¸°
    df_consumed = tmp[tmp["ì¸µ"].isin(["ì†Œì§„", "íê¸°"])]

    # í‘œ 4ê°œ ì¶œë ¥
    show_summary_table(df_onsite, "1) ìì‚¬ ìœ„ì¹˜ (2ì¸µ / 4ì¸µ / 5ì¸µ / 6ì¸µ)")
    show_summary_table(df_outsourcing, "2) ì™¸ì£¼")
    show_summary_table(df_warehouse, "3) ì°½ê³ ")
    show_summary_table(df_consumed, "4) ì†Œì§„ / íê¸°")

    st.markdown("---")
    if st.button("í˜„ì¬ CSVë¥¼ ê·¸ëŒ€ë¡œ ë°±ì—… ì €ì¥í•˜ê¸°"):
        # ğŸ”¹ í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ íƒ€ì„ìŠ¤íƒ¬í”„
        KST = timezone(timedelta(hours=9))
        ts = datetime.now(KST).strftime("%Y%m%d_%H%M%S")
        backup_name = f"bulk_drums_extended_backup_{ts}.csv"

        df.to_csv(backup_name, index=False, encoding="utf-8-sig")
        st.success(f"ë°±ì—… íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {backup_name}")

    if st.button("ê°„ë‹¨ ë°ì´í„° ì ê²€"):
        df_all = load_drums()

        prob1 = df_all[(df_all["í†µìš©ëŸ‰"] == 0) & ~df_all["í˜„ì¬ìœ„ì¹˜"].isin(["ì†Œì§„", "íê¸°"])]
        if not prob1.empty:
            st.warning("ìš©ëŸ‰ 0ì¸ë° ì†Œì§„/íê¸°ê°€ ì•„ë‹Œ í†µ")
            st.dataframe(prob1, use_container_width=True)

        prob2 = df_all[(df_all["í˜„ì¬ìœ„ì¹˜"] == "ì™¸ì£¼") & (df_all["ìƒíƒœ"] != "ì™¸ì£¼")]
        if not prob2.empty:
            st.warning("ìœ„ì¹˜ëŠ” ì™¸ì£¼ì¸ë° ìƒíƒœê°€ ì™¸ì£¼ê°€ ì•„ë‹Œ í†µ")
            st.dataframe(prob2, use_container_width=True)


# ==============================
# íƒ­ 3: ì§€ë„ (A1~C3 ë²„íŠ¼)
# ==============================
def render_tab_map():
    st.markdown("### ğŸ—º ë²Œí¬ ìœ„ì¹˜ ì§€ë„ (CSV ê¸°ì¤€)")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # -----------------------------
    # (1) í˜„ì¬ìœ„ì¹˜ íŒŒì‹±: ì¸µ / ì„¸ë¶€êµ¬ì—­
    # -----------------------------
    def parse_loc(loc) -> tuple[str, str]:
        """
        return: (floor, zone)
        - "4ì¸µ ë¡œíƒ€ë¦¬" -> ("4ì¸µ", "ë¡œíƒ€ë¦¬")
        - "5ì¸µ ë¯¸ì§€ì •" -> ("5ì¸µ", "ë¯¸ì§€ì •")
        - "ì™¸ì£¼" -> ("ì™¸ì£¼", "")
        - "4ì¸µ" -> ("4ì¸µ", "ë¯¸ì§€ì •")  # ë³´í—˜ ì²˜ë¦¬
        """
        if pd.isna(loc):
            return ("", "")
        s = str(loc).strip()
        if not s:
            return ("", "")

        # íŠ¹ìˆ˜ ìƒíƒœ
        if s in ("ì™¸ì£¼", "íê¸°", "ì†Œì§„"):
            return (s, "")

        parts = s.split(" ", 1)
        if len(parts) == 1:
            # "4ì¸µ" ê°™ì´ ì¸µë§Œ ë“¤ì–´ì˜¨ ê²½ìš°
            return (parts[0], "ë¯¸ì§€ì •")

        floor, zone = parts[0].strip(), parts[1].strip()
        if not zone:
            zone = "ë¯¸ì§€ì •"
        return (floor, zone)

    df[["ì¸µ", "ì„¸ë¶€êµ¬ì—­"]] = df["í˜„ì¬ìœ„ì¹˜"].apply(lambda x: pd.Series(parse_loc(x)))

    floors = (
        df["ì¸µ"]
        .dropna()
        .astype(str)
        .replace("", pd.NA)
        .dropna()
        .unique()
        .tolist()
    )
    floors = sorted(floors)

    # (ê¸°ì¡´ ë¡œì§ ìœ ì§€) 1ì¸µ ì œê±°
    floors = [f for f in floors if f != "1ì¸µ"]

    if not floors:
        st.info("ì¸µ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    sel_floor = st.selectbox("í™•ì¸í•˜ì‹¤ ì¸µ/êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", floors, key="map_floor_csv")

    fdf = df[df["ì¸µ"] == sel_floor].copy()
    if fdf.empty:
        st.info("í•´ë‹¹ ì¸µ/êµ¬ì—­ì— ë“±ë¡ëœ ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # -----------------------------
    # (2) íŠ¹ìˆ˜ êµ¬ì—­: ì™¸ì£¼/íê¸°/ì†Œì§„
    # -----------------------------
    special_floors = {"ì™¸ì£¼", "íê¸°", "ì†Œì§„"}
    if sel_floor in special_floors:
        st.markdown(f"#### {sel_floor} êµ¬ì—­ í˜„í™©")

        drums = len(fdf)
        vol = fdf["í†µìš©ëŸ‰"].sum()

        st.write(f"**í†µ ê°œìˆ˜:** {drums}í†µ")
        st.write(f"**ì´ ìš©ëŸ‰:** {int(vol)}kg")

        st.markdown("---")
        st.markdown("### ğŸ” ìƒì„¸ ëª©ë¡")

        show_cols = [
            "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
            "ìƒíƒœ", "í˜„ì¬ìœ„ì¹˜", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰",
        ]
        st.dataframe(
            fdf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
            use_container_width=True,
        )
        return

    # -----------------------------
    # (3) ì¸µë³„ ì„¸ë¶€êµ¬ì—­ ì •ì˜ (ìƒˆ ì§€ë„ êµ¬ì¡°)
    # -----------------------------
    floor_zones = {
        "2ì¸µ": ["A", "B", "C", "D", "E", "ë¯¸ì§€ì •"],
        "4ì¸µ": ["ë¸”ë¦¬ìŠ¤í„°", "ë¡œíƒ€ë¦¬", "ë•ìš©", "ë¯¸ì§€ì •"],
        "5ì¸µ": ["ê¸°ì´ˆ", "ë•ìš©", "ë¯¸ì§€ì •"],
        "6ì¸µ": ["ìŠ¤í‹±&íŒŒìš°ì¹˜", "ìŠ¤í‚¨íŒ©", "ë¯¸ì§€ì •"],
    }

    zones = floor_zones.get(sel_floor)
    if not zones:
        st.info("ì´ ì¸µì€ ì•„ì§ ì„¸ë¶€êµ¬ì—­ ì •ì˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ì½”ë“œì˜ floor_zonesì— ì¶”ê°€í•´ ì£¼ì„¸ìš”.)")
        return

    # ì„¸ë¶€êµ¬ì—­ì´ ì •ì˜ì— ì—†ìœ¼ë©´ "ë¯¸ì§€ì •"ìœ¼ë¡œ í¡ìˆ˜ (ì•ˆì „ë§)
    fdf["zone_label"] = fdf["ì„¸ë¶€êµ¬ì—­"].apply(lambda z: z if z in zones else "ë¯¸ì§€ì •")

    # -----------------------------
    # (4) Zoneë³„ ì§‘ê³„ + ë²„íŠ¼ UI
    # -----------------------------
    zone_stats = {}
    max_vol = 0.0
    for z in zones:
        sub = fdf[fdf["zone_label"] == z]
        drums = len(sub)
        vol = sub["í†µìš©ëŸ‰"].sum()
        zone_stats[z] = {"drums": drums, "volume": vol}
        max_vol = max(max_vol, vol)

    def badge(volume):
        if volume <= 0:
            return "âšª"
        if max_vol <= 0:
            return "ğŸŸ¡"
        ratio = volume / max_vol
        if ratio > 0.7:
            return "ğŸ”´"
        elif ratio > 0.3:
            return "ğŸŸ "
        else:
            return "ğŸŸ¡"

    st.markdown(f"#### {sel_floor} êµ¬ì—­ë³„ í˜„í™© (í†µ ê°œìˆ˜ / ì´ ìš©ëŸ‰)")

    # ë²„íŠ¼ì„ ë³´ê¸° ì¢‹ê²Œ Nì—´ë¡œ ë°°ì¹˜ (2ì¸µì€ 3ì—´, ë‚˜ë¨¸ì§„ 2~3ì—´)
    ncols = 3 if sel_floor == "2ì¸µ" else 3
    rows = [zones[i:i+ncols] for i in range(0, len(zones), ncols)]

    for r_idx, row_zones in enumerate(rows):
        cols = st.columns(ncols)
        for c_idx in range(ncols):
            col = cols[c_idx]
            if c_idx >= len(row_zones):
                col.empty()
                continue

            z = row_zones[c_idx]
            info = zone_stats.get(z, {"drums": 0, "volume": 0})
            txt = (
                f"{z} {badge(info['volume'])}\n"
                f"{info['drums']}í†µ / {int(info['volume'])}kg"
            )
            if col.button(txt, key=f"map_btn_{sel_floor}_{z}_{r_idx}_{c_idx}"):
                st.session_state["clicked_zone_csv"] = f"{sel_floor}|{z}"

    st.markdown("---")
    st.markdown("### ğŸ” êµ¬ì—­ ìƒì„¸ ë³´ê¸°")

    clicked = st.session_state.get("clicked_zone_csv", None)
    if not clicked:
        st.info("í™•ì¸í•˜ì‹¤ êµ¬ì—­ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
        return

    cfloor, cz = clicked.split("|", 1)
    if cfloor != sel_floor:
        # ë‹¤ë¥¸ ì¸µì—ì„œ ëˆ„ë¥¸ ë²„íŠ¼ì´ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì •ë¦¬
        st.session_state["clicked_zone_csv"] = None
        st.info("í™•ì¸í•˜ì‹¤ êµ¬ì—­ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
        return

    st.success(f"ì„ íƒëœ êµ¬ì—­: {sel_floor} {cz}")

    ddf = fdf[fdf["zone_label"] == cz].copy()
    if ddf.empty:
        st.info("í•´ë‹¹ êµ¬ì—­ì—ëŠ” ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    show_cols = [
        "í’ˆëª©ì½”ë“œ", "í’ˆëª…", "ë¡œíŠ¸ë²ˆí˜¸", "ì œí’ˆë¼ì¸", "ì œì¡°ì¼ì",
        "ìƒíƒœ", "í˜„ì¬ìœ„ì¹˜", "í†µë²ˆí˜¸", "í†µìš©ëŸ‰",
    ]
    st.dataframe(
        ddf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
        use_container_width=True,
    )

# ==============================
# íƒ­ 4: ì´ë™ ì´ë ¥ (ìˆ˜ì • + í–‰ ì‚­ì œ ê°€ëŠ¥)
# ==============================
def render_tab_move_log():
    st.markdown("### ğŸ“œ ì´ë™ ì´ë ¥ (ë¡¤ë°± ì „ìš© / ì‚­ì œë§Œ ê°€ëŠ¥)")

    df = load_move_log()
    if df.empty:
        st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    ss = st.session_state
    ss.setdefault("log_lot_filter", "")
    ss.setdefault("log_page", 1)

    def reset_log_filter():
        ss["log_lot_filter"] = ""
        ss["log_page"] = 1

    col1, col2 = st.columns([3, 1])
    with col1:
        lot_filter = st.text_input(
            "ë¡œíŠ¸ë²ˆí˜¸ë¡œ ê²€ìƒ‰ (ë¶€ë¶„ ì¼ì¹˜)",
            key="log_lot_filter",
            placeholder="ì˜ˆ: 2E075K",
        )
    with col2:
        st.button("ê²€ìƒ‰ ì´ˆê¸°í™”", key="log_reset", on_click=reset_log_filter)

    if lot_filter:
        q = lot_filter.strip().lower()
        df["lot_lower"] = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()
        mask = df["lot_lower"].str.contains(q, na=False)
        df_view = df[mask].copy()
    else:
        df_view = df.copy()

    if df_view.empty:
        st.info("ê²€ìƒ‰ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_view = df_view.sort_values("ì‹œê°„", ascending=False)

    page_size = 50
    total_rows = len(df_view)
    total_pages = max(1, math.ceil(total_rows / page_size))

    # í˜„ì¬ í˜ì´ì§€ê°€ ì „ì²´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ë³´ì •
    ss["log_page"] = min(max(1, ss.get("log_page", 1)), total_pages)

    # í˜ì´ì§€ë„¤ì´ì…˜ UI (ìŠ¬ë¼ì´ë” í•œ ì¤„)
    colp = st.columns([3])
    with colp[0]:
        ss["log_page"] = st.slider(
            "í˜ì´ì§€ ì„ íƒ",
            min_value=1,
            max_value=total_pages,
            value=ss["log_page"],
            step=1,
        )

    # âœ… ìŠ¬ë¼ì´ë” ê°’ í™•ì •ëœ ë’¤ í•œ ë²ˆë§Œ start/end ê³„ì‚°
    start = (ss["log_page"] - 1) * page_size
    end = start + page_size

    st.markdown(
        f"**í˜ì´ì§€ {ss['log_page']} / {total_pages}** &nbsp;&nbsp; "
        f"(ì´ {total_rows}ê±´, í˜ì´ì§€ë‹¹ {page_size}ê±´)",
        unsafe_allow_html=True,
    )

    # âœ… í•´ë‹¹ êµ¬ê°„ ë°ì´í„°ë§Œ ì˜ë¼ì„œ ì‚¬ìš©
    page_df = df_view.iloc[start:end].copy()

    st.markdown(
        f"<div style='text-align:center; font-size:0.9rem; margin-top:-10px;'>"
        f"í˜ì´ì§€ {ss['log_page']} / {total_pages} (ì´ {total_rows}ê±´)"
        f"</div>",
        unsafe_allow_html=True,
    )
    
    start = (ss["log_page"] - 1) * page_size
    end = start + page_size
    page_df = df_view.iloc[start:end].copy()

    cols_order = [
        "ì‹œê°„",
        "ID",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]
    page_df = page_df[cols_order]

    delete_col = "ì‚­ì œ"
    if delete_col not in page_df.columns:
        page_df[delete_col] = False

    st.caption(
        "â€» LOGëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
        "ì¡°íšŒë§Œ ê°€ëŠ¥í•˜ë©°, 'ì‚­ì œ'ì— ì²´í¬ í›„ 'ì„ íƒ í–‰ ì‚­ì œ(ë¡¤ë°±)'ì„ ëˆ„ë¥´ë©´ "
        "í•´ë‹¹ ì´ë™ ì´ë ¥ì€ ì‚­ì œë˜ê³ , í†µ ì •ë³´ CSVëŠ” ë³€ê²½ ì „ ìƒíƒœë¡œ ë¡¤ë°±ë©ë‹ˆë‹¤.\n"
        "â€» ì•ˆì „ì„ ìœ„í•´ ê° í†µì˜ 'ê°€ì¥ ìµœê·¼ ì´ë™ ì´ë ¥'ë§Œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # ğŸ”¹ ëª¨ë“  ì¹¼ëŸ¼ì€ ì½ê¸° ì „ìš©, 'ì‚­ì œ'ë§Œ ì²´í¬ ê°€ëŠ¥
    edited_page = st.data_editor(
        page_df,
        use_container_width=True,
        disabled=cols_order,  # ì‹œê°„~ë³€ê²½ í›„ ìœ„ì¹˜ê¹Œì§€ ì „ë¶€ ì½ê¸° ì „ìš©
        column_config={
            delete_col: st.column_config.CheckboxColumn("ì‚­ì œ", help="ë¡¤ë°±í•  í–‰ì— ì²´í¬"),
        },
        key=f"move_log_editor_page_{ss['log_page']}",
    )

    def _save_full_log(df_updated: pd.DataFrame):
        buf = io.BytesIO()
        df_updated.to_csv(buf, index=False, encoding="utf-8-sig")
        data = buf.getvalue()
        ss["move_log_csv_bytes"] = data
        _load_move_log_core.clear()
        try:
            df_updated.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
        except Exception:
            pass
        s3_upload_bytes(MOVE_LOG_CSV, data)

    # ğŸ”¹ ì´ì œëŠ” ì‚­ì œ(ë¡¤ë°±) ë²„íŠ¼ë§Œ ì¡´ì¬
    _, col_delete = st.columns([3, 1])

    with col_delete:
        if st.button("ì„ íƒ í–‰ ì‚­ì œ (ë¡¤ë°±)", key="log_delete_rows"):
            try:
                if delete_col in edited_page.columns:
                    to_del_idx = edited_page[edited_page[delete_col] == True].index
                else:
                    to_del_idx = []

                if len(to_del_idx) == 0:
                    st.warning("ë¨¼ì € ë¡¤ë°±í•  í–‰ì„ 'ì‚­ì œ' ì¹¼ëŸ¼ì— ì²´í¬í•´ ì£¼ì„¸ìš”.")
                    return

                # ì›ë³¸ ì „ì²´ ë¡œê·¸ì—ì„œ ì‚­ì œ ëŒ€ìƒ í–‰ ì¶”ì¶œ
                rows_to_delete = df.loc[to_del_idx].copy()

                # 1) ê° í†µ(ë¡œíŠ¸ë²ˆí˜¸+í†µë²ˆí˜¸)ì˜ 'ê°€ì¥ ìµœì‹  ì´ë ¥'ì¸ì§€ í™•ì¸
                log_all = df.copy()
                log_all["__dt"] = pd.to_datetime(log_all["ì‹œê°„"], errors="coerce")

                not_latest = []
                for idx, row in rows_to_delete.iterrows():
                    lot = str(row["ë¡œíŠ¸ë²ˆí˜¸"])
                    drum_no = int(row["í†µë²ˆí˜¸"])

                    mask = (
                        log_all["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == lot
                    ) & (log_all["í†µë²ˆí˜¸"] == drum_no)
                    sub = log_all[mask]

                    if sub.empty:
                        continue

                    sub_valid = sub.dropna(subset=["__dt"])
                    if not sub_valid.empty:
                        last_idx = sub_valid["__dt"].idxmax()
                    else:
                        # ì‹œê°„ íŒŒì‹±ì´ ì•ˆ ë˜ë©´, ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ í° ê°’ = ë§ˆì§€ë§‰
                        last_idx = sub.index.max()

                    if idx != last_idx:
                        not_latest.append(f"{lot} / í†µ {drum_no}")

                if not_latest:
                    st.error(
                        "ë¡¤ë°±ì€ ê° í†µì˜ 'ê°€ì¥ ìµœê·¼ ì´ë™ ì´ë ¥'ë§Œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                        "ë‹¤ìŒ í•­ëª©ì€ ë” ìƒˆë¡œìš´ ì´ë ¥ì´ ìˆì–´ ë¡¤ë°±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n"
                        + ", ".join(not_latest)
                    )
                    return

                # 2) í†µ ì •ë³´ CSV ë¡¤ë°±
                drums_df = load_drums()
                drums_df["lot_lower"] = drums_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.lower()

                for _, row in rows_to_delete.iterrows():
                    lot = str(row["ë¡œíŠ¸ë²ˆí˜¸"])
                    lot_lower = lot.lower()
                    drum_no = int(row["í†µë²ˆí˜¸"])

                    old_qty = float(row["ë³€ê²½ ì „ ìš©ëŸ‰"])
                    from_loc = str(row["ë³€ê²½ ì „ ìœ„ì¹˜"]) if not pd.isna(row["ë³€ê²½ ì „ ìœ„ì¹˜"]) else ""

                    mask_drum = (drums_df["lot_lower"] == lot_lower) & (drums_df["í†µë²ˆí˜¸"] == drum_no)
                    drum_idxs = drums_df.index[mask_drum]

                    if len(drum_idxs) == 0:
                        # í•´ë‹¹ í†µ ì •ë³´ê°€ CSVì— ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        continue

                    i = drum_idxs[0]
                    drums_df.at[i, "í†µìš©ëŸ‰"] = old_qty
                    if from_loc:
                        drums_df.at[i, "í˜„ì¬ìœ„ì¹˜"] = from_loc
                    # ìƒíƒœê¹Œì§€ ì™„ë²½íˆ ë³µì›í•˜ë ¤ë©´ ë¡œê·¸ì— ìƒíƒœë¥¼ ì¶”ê°€ë¡œ ê¸°ë¡í•´ì•¼ í•¨.
                    # ì§€ê¸ˆì€ í†µìš©ëŸ‰/í˜„ì¬ìœ„ì¹˜ë§Œ ë¡¤ë°±.

                if "lot_lower" in drums_df.columns:
                    drums_df = drums_df.drop(columns=["lot_lower"])
                save_drums(drums_df)

                # 3) ì´ë™ ë¡œê·¸ì—ì„œ í–‰ ì‚­ì œ + ì €ì¥
                df_updated = df.drop(index=to_del_idx)
                _save_full_log(df_updated)

                st.success(f"ì´ {len(to_del_idx)}ê°œ ì´ë™ ì´ë ¥ì´ ì‚­ì œë˜ê³ , ê´€ë ¨ í†µ ì •ë³´ê°€ ë¡¤ë°±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

            except Exception as e:
                st.error(f"í–‰ì„ ì‚­ì œ(ë¡¤ë°±)í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ==============================
# íƒ­ 5: ë°ì´í„° íŒŒì¼ ê´€ë¦¬
# ==============================
def file_status(sess_key: str, path: str) -> str:
    ss = st.session_state
    if sess_key in ss:
        return "ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš© ì¤‘"
    if os.path.exists(path):
        return f"ë¡œì»¬ íŒŒì¼ ì‚¬ìš© ì¤‘ ({path})"
    return "íŒŒì¼ ì—†ìŒ"


def render_tab_data():
    ss = st.session_state
    st.markdown("### ğŸ“ ë°ì´í„° íŒŒì¼ ê´€ë¦¬")
    st.write(
        "í•„ìš”í•  ë•Œë§ˆë‹¤ ì•„ë˜ì—ì„œ CSV/ì—‘ì…€ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì„œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ì—…ë¡œë“œí•˜ë©´ **í˜„ì¬ ì„¸ì…˜ì—ì„œ ë°”ë¡œ ë°˜ì˜**ë©ë‹ˆë‹¤."
    )

    # --- bulk_drums_extended.csv ---
    with st.expander("1) bulk_drums_extended.csv (ë©”ì¸ ë²Œí¬ CSV)", expanded=True):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("bulk_csv_bytes", CSV_PATH))
        bulk_file = st.file_uploader(
            "ìƒˆ bulk_drums_extended.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_bulk",
        )
        st.caption(last_upload_caption(CSV_PATH))

        if st.button("ì´ íŒŒì¼ë¡œ bulk CSV êµì²´", key="apply_bulk"):
            if bulk_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = bulk_file.read()
                ss["bulk_csv_bytes"] = data
                _load_drums_core.clear()
                try:
                    df_tmp = _load_drums_core(data)
                    df_tmp.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                s3_upload_bytes(CSV_PATH, data)
                st.success("bulk_drums_extended.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- production.xlsx ---
    with st.expander("2) production.xlsx (ì œì¡°ì‘ì—…ì‹¤ì í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("prod_xlsx_bytes", PRODUCTION_FILE))
        prod_file = st.file_uploader(
            "ìƒˆ production.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ production êµì²´", key="apply_prod"):
            if prod_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = prod_file.read()
                ss["prod_xlsx_bytes"] = data
                _load_production_core.clear()
                try:
                    df_tmp = _load_production_core(data)
                    df_tmp.to_excel(PRODUCTION_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(PRODUCTION_FILE, data)
                st.success("production.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- receive.xlsx ---
    with st.expander("3) receive.xlsx (ì…í•˜í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("recv_xlsx_bytes", RECEIVE_FILE))
        recv_file = st.file_uploader(
            "ìƒˆ receive.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ receive êµì²´", key="apply_recv"):
            if recv_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = recv_file.read()
                ss["recv_xlsx_bytes"] = data
                _load_receive_core.clear()
                try:
                    df_tmp = _load_receive_core(data)
                    df_tmp.to_excel(RECEIVE_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(RECEIVE_FILE, data)
                st.success("receive.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- stock.xlsx ---
    with st.expander("4) stock.xlsx (ì¼ìë³„í†µí•©ì¬ê³ í˜„í™©)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("stock_xlsx_bytes", STOCK_FILE))
        stock_file = st.file_uploader(
            "ìƒˆ stock.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ stock êµì²´", key="apply_stock"):
            if stock_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = stock_file.read()
                ss["stock_xlsx_bytes"] = data
                _load_stock_core.clear()
                try:
                    df_tmp = _load_stock_core(data)
                    df_tmp.to_excel(STOCK_FILE, index=False)
                except Exception:
                    pass
                s3_upload_bytes(STOCK_FILE, data)
                st.success("stock.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- bulk_move_log.csv ---
    with st.expander("5) bulk_move_log.csv (ì´ë™ ì´ë ¥, ì„ íƒ)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("move_log_csv_bytes", MOVE_LOG_CSV))
        move_file = st.file_uploader(
            "ìƒˆ bulk_move_log.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))

        if st.button("ì´ íŒŒì¼ë¡œ ì´ë™ ì´ë ¥ êµì²´", key="apply_move"):
            if move_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = move_file.read()
                ss["move_log_csv_bytes"] = data
                _load_move_log_core.clear()
                try:
                    df_tmp = _load_move_log_core(data)
                    df_tmp.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                s3_upload_bytes(MOVE_LOG_CSV, data)
                st.success("bulk_move_log.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.caption(
        "â€» Cloudì—ì„œëŠ” ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ë©´ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. "
        "ì¤‘ìš”í•œ ë³€ê²½ ë‚´ìš©ì€ ì‚¬ì´ë“œë°”ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ CSVë¥¼ ì €ì¥í•´ ë‘ì„¸ìš”."
    )


# ==============================
# ë©”ì¸
# ==============================
def has_data(sess_key: str, path: str) -> bool:
    """
    ì„¸ì…˜, ë¡œì»¬ íŒŒì¼, S3 ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ True.
    """
    ss = st.session_state
    if sess_key in ss:
        return True
    if os.path.exists(path):
        return True
    b = s3_download_bytes(path)
    if b is not None:
        return True
    return False


def main():
    ss = st.session_state

    # 1) ë¡œê·¸ì¸ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë¡œê·¸ì¸ í™”ë©´ë§Œ í‘œì‹œ
    if "user_id" not in ss or "user_name" not in ss:
        render_login()
        return

    # 2) í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ì¤€ë¹„ ì—¬ë¶€ í™•ì¸
    files_ready = (
        has_data("bulk_csv_bytes", CSV_PATH)
        and has_data("prod_xlsx_bytes", PRODUCTION_FILE)
        and has_data("recv_xlsx_bytes", RECEIVE_FILE)
        and has_data("stock_xlsx_bytes", STOCK_FILE)
    )

    if not ss.get("data_initialized", False) and not files_ready:
        render_file_loader()
        return

    # 3) ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown(f"**ì‚¬ìš©ì:** {ss['user_name']} ({ss['user_id']})")
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
            for k in ["user_id", "user_name"]:
                if k in st.session_state:
                    del st.session_state[k]
            st.rerun()

        if "bulk_csv_bytes" in ss:
            st.download_button(
                "í˜„ì¬ bulk CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["bulk_csv_bytes"],
                file_name="bulk_drums_extended_current.csv",
                mime="text/csv",
            )
        if "move_log_csv_bytes" in ss:
            st.download_button(
                "ì´ë™ ì´ë ¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["move_log_csv_bytes"],
                file_name="bulk_move_log_current.csv",
                mime="text/csv",
            )

    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

    tab_move, tab_lookup, tab_map, tab_log, tab_data = st.tabs(
        ["ğŸ“¦ ì´ë™", "ğŸ” ì¡°íšŒ", "ğŸ—º ì§€ë„", "ğŸ“œ ì´ë™ ì´ë ¥", "ğŸ“ ë°ì´í„°"]
    )

    with tab_move:
        render_tab_move()
    with tab_lookup:
        render_tab_lookup()
    with tab_map:
        render_tab_map()
    with tab_log:
        render_tab_move_log()
    with tab_data:
        render_tab_data()


if __name__ == "__main__":
    main()
