import streamlit as st
import pandas as pd
import os
from datetime import datetime, date
import io
import math

# ==============================
# ì‚¬ìš©ì ê³„ì • (ë¡œê·¸ì¸ìš©)
# ==============================
USER_ACCOUNTS = {
    "ps": {"password": "0000", "display_name": "ì„í•„ì„ "},
    "by": {"password": "0000", "display_name": "ê°•ë´‰ì—°"},
    "hn": {"password": "0000", "display_name": "ê¹€í•œë‚˜"},
}

# ==============================
# ê¸°ë³¸ ì„¤ì • + CSS
# ==============================
st.set_page_config(page_title="ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

st.markdown(
    """
    <style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ ì¹¸ì€ í™”ë©´ í­ê³¼ ìƒê´€ì—†ì´ ê³ ì • í¬ê¸° + í™•ì¥ ê¸ˆì§€ */
    .stTextInput > div {
        flex: 0 0 auto !important;
    }
    .stTextInput > div > div > input {
        width: 160px !important;
        max-width: 160px !important;
        min-width: 160px !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

CSV_PATH = "bulk_drums_extended.csv"   # í’ˆëª©ì½”ë“œ~í˜„ì¬ìœ„ì¹˜ê¹Œì§€ ë“¤ì–´ìˆëŠ” íŒŒì¼
PRODUCTION_FILE = "production.xlsx"    # ìì‚¬: ì‘ì—…ë²ˆí˜¸ â†’ ë¡œíŠ¸/ì œì¡°ëŸ‰
MOVE_LOG_CSV = "bulk_move_log.csv"     # ì´ë™ ì´ë ¥
RECEIVE_FILE = "receive.xlsx"          # ì‚¬ê¸‰: ì…í•˜ë²ˆí˜¸ ê¸°ë°˜
STOCK_FILE = "stock.xlsx"              # ì „ì‚° ì¬ê³ 

# ==============================
# S3 ì—°ë™ ì„¤ì •
# ==============================
import boto3

S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "bulk-system-enc")
S3_PREFIX = os.getenv("S3_PREFIX", "bulk-app/")  # í´ë” ê²½ë¡œ

def s3_enabled() -> bool:
    return bool(S3_BUCKET_NAME)

@st.cache_resource(show_spinner=False)
def get_s3_client():
    try:
        session = boto3.session.Session()
        client = session.client("s3")
        return client
    except Exception:
        return None

def _s3_key(filename: str) -> str:
    """
    S3ì—ì„œ ì €ì¥ë˜ëŠ” ê²½ë¡œë¥¼ ê²°ì •.
    ì˜ˆ: filename="bulk_drums_extended.csv" â†’ "bulk-app/bulk_drums_extended.csv"
    """
    prefix = S3_PREFIX.rstrip("/")
    return f"{prefix}/{filename}" if prefix else filename


# ==============================
# ë°”ì½”ë“œ ì¸ì‹ (Dynamsoft DBR ì „ìš© - CaptureVisionRouter ì‚¬ìš©)
# ==============================
try:
    from PIL import Image, ImageOps, ImageEnhance
except ImportError:
    Image = None
    ImageOps = None
    ImageEnhance = None

# Dynamsoft Barcode Reader Python SDK (v10~)
try:
    from dynamsoft_barcode_reader_bundle import (
        LicenseManager,
        CaptureVisionRouter,
        EnumPresetTemplate,
        EnumErrorCode,
    )
except ImportError:
    LicenseManager = None
    CaptureVisionRouter = None
    EnumPresetTemplate = None
    EnumErrorCode = None


def load_dbr_license():
    """
    DBR ë¼ì´ì„ ìŠ¤ í‚¤ ë¡œë“œ:
    1) st.secrets["DBR_LICENSE"]
    2) í™˜ê²½ë³€ìˆ˜ DBR_LICENSE
    """
    lic = ""
    try:
        lic = st.secrets.get("DBR_LICENSE", "")
    except Exception:
        lic = ""
    if not lic:
        lic = os.getenv("DBR_LICENSE", "")
    if not lic:
        st.warning("DBR ë¼ì´ì„ ìŠ¤ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. st.secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ DBR_LICENSEì— ë“±ë¡í•´ ì£¼ì„¸ìš”.")
    return lic


DBR_LICENSE = load_dbr_license()

_DBR_CVR = None
_DBR_LICENSE_INIT = False


def get_dbr_router():
    """LicenseManager + CaptureVisionRouter ì´ˆê¸°í™”í•´ì„œ ì „ì—­ìœ¼ë¡œ ì¬ì‚¬ìš©."""
    global _DBR_CVR, _DBR_LICENSE_INIT

    if CaptureVisionRouter is None or LicenseManager is None or EnumErrorCode is None:
        return None

    if not _DBR_LICENSE_INIT:
        try:
            err_code, err_str = LicenseManager.init_license(DBR_LICENSE)
        except Exception:
            return None

        if err_code not in (
            EnumErrorCode.EC_OK,
            getattr(EnumErrorCode, "EC_LICENSE_CACHE_USED", EnumErrorCode.EC_OK),
            getattr(EnumErrorCode, "EC_LICENSE_WARNING", EnumErrorCode.EC_OK),
        ):
            return None

        _DBR_LICENSE_INIT = True

    if _DBR_CVR is None:
        try:
            _DBR_CVR = CaptureVisionRouter()
        except Exception:
            return None

    return _DBR_CVR


def preprocess_for_barcode(pil_img):
    """íë¦¿í•œ ë¼ë²¨ìš© ì „ì²˜ë¦¬."""
    if Image is None:
        return pil_img

    if pil_img.mode != "L":
        img = pil_img.convert("L")
    else:
        img = pil_img.copy()

    img = ImageOps.autocontrast(img)
    img = ImageEnhance.Sharpness(img).enhance(2.0)

    min_side = min(img.size)
    if min_side < 800:
        scale = 800.0 / float(min_side)
        new_size = (int(img.width * scale), int(img.height * scale))
        img = img.resize(new_size, Image.LANCZOS)

    return img


def dbr_decode(pil_img):
    """
    Dynamsoft DBR(CaptureVisionRouter)ë¡œë§Œ ë°”ì½”ë“œ ë””ì½”ë”©.
    ì„±ê³µí•˜ë©´ [(í¬ë§·, í…ìŠ¤íŠ¸), ...] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    """
    cvr = get_dbr_router()
    if cvr is None or EnumPresetTemplate is None or EnumErrorCode is None:
        return []

    img = preprocess_for_barcode(pil_img)

    buf = io.BytesIO()
    img.save(buf, format="PNG")
    data = buf.getvalue()

    try:
        result = cvr.capture(data, EnumPresetTemplate.PT_READ_BARCODES)
    except Exception:
        return []

    err = result.get_error_code()
    if err not in (
        EnumErrorCode.EC_OK,
        getattr(EnumErrorCode, "EC_UNSUPPORTED_JSON_KEY_WARNING", EnumErrorCode.EC_OK),
    ):
        return []

    barcode_result = result.get_decoded_barcodes_result()
    if barcode_result is None or barcode_result.get_items() == 0:
        return []

    items = barcode_result.get_items()
    codes = []
    for item in items:
        text = (item.get_text() or "").strip()
        fmt = (item.get_format_string() or "").strip()
        if text:
            codes.append((fmt, text))

    return codes


# ==============================
# ê³µí†µ ìœ í‹¸ (ì—…ë¡œë“œ/ë¡œì»¬ ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_drums_core(bulk_bytes):
    """bulk_drums_extended.csv ë¡œë“œ (ì„¸ì…˜ ì—…ë¡œë“œ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼)."""
    # 1) ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  ì‚¬ìš©
    if bulk_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(bulk_bytes))
        except Exception as e:
            st.error(f"ì—…ë¡œë“œí•œ bulk_drums_extended.csvë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ",
                    "í’ˆëª…",
                    "ë¡œíŠ¸ë²ˆí˜¸",
                    "ì œí’ˆë¼ì¸",
                    "ì œì¡°ì¼ì",
                    "ìƒíƒœ",
                    "í†µë²ˆí˜¸",
                    "í†µìš©ëŸ‰",
                    "í˜„ì¬ìœ„ì¹˜",
                ]
            )
    # 2) ì—…ë¡œë“œ íŒŒì¼ì´ ì—†ê³ , ë¡œì»¬ CSVê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
    elif os.path.exists(CSV_PATH):
        try:
            df = pd.read_csv(CSV_PATH)
        except Exception as e:
            st.error(f"CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(
                columns=[
                    "í’ˆëª©ì½”ë“œ",
                    "í’ˆëª…",
                    "ë¡œíŠ¸ë²ˆí˜¸",
                    "ì œí’ˆë¼ì¸",
                    "ì œì¡°ì¼ì",
                    "ìƒíƒœ",
                    "í†µë²ˆí˜¸",
                    "í†µìš©ëŸ‰",
                    "í˜„ì¬ìœ„ì¹˜",
                ]
            )
    # 3) ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ DF
    else:
        return pd.DataFrame(
            columns=[
                "í’ˆëª©ì½”ë“œ",
                "í’ˆëª…",
                "ë¡œíŠ¸ë²ˆí˜¸",
                "ì œí’ˆë¼ì¸",
                "ì œì¡°ì¼ì",
                "ìƒíƒœ",
                "í†µë²ˆí˜¸",
                "í†µìš©ëŸ‰",
                "í˜„ì¬ìœ„ì¹˜",
            ]
        )

    required_cols = [
        "í’ˆëª©ì½”ë“œ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "ì œí’ˆë¼ì¸",
        "ì œì¡°ì¼ì",
        "ìƒíƒœ",
        "í†µë²ˆí˜¸",
        "í†µìš©ëŸ‰",
        "í˜„ì¬ìœ„ì¹˜",
    ]
    for c in required_cols:
        if c not in df.columns:
            st.error(f"CSVì— '{c}' ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ì—ì„œ ë‹¤ì‹œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.")
            return pd.DataFrame(columns=required_cols)

    df["í†µë²ˆí˜¸"] = pd.to_numeric(df["í†µë²ˆí˜¸"], errors="coerce").fillna(0).astype(int)
    df["í†µìš©ëŸ‰"] = pd.to_numeric(df["í†µìš©ëŸ‰"], errors="coerce").fillna(0.0).astype(float)

    def norm_loc(x: str) -> str:
        if pd.isna(x):
            return ""
        s = str(x).strip()
        if "-" not in s:
            if s in ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"]:
                return f"{s}-A1"
        return s

    df["í˜„ì¬ìœ„ì¹˜"] = df["í˜„ì¬ìœ„ì¹˜"].apply(norm_loc)

    return df


def load_drums() -> pd.DataFrame:
    """ì„¸ì…˜ ìƒíƒœë¥¼ ê°ì•ˆí•´ì„œ bulk DFë¥¼ ê°€ì ¸ì˜¤ëŠ” ì™¸ë¶€ìš© í•¨ìˆ˜."""
    ss = st.session_state
    bulk_bytes = ss.get("bulk_csv_bytes", None)
    return _load_drums_core(bulk_bytes)


def save_drums(df: pd.DataFrame):
    """
    í˜„ì¬ DFë¥¼ bulk_drums_extended.csvë¡œ ì €ì¥.
    - ì„¸ì…˜ ë©”ëª¨ë¦¬(ì—…ë¡œë“œ ë°©ì‹) ê°±ì‹ 
    - ë¡œì»¬ íŒŒì¼ë„ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸° (ë¡œì»¬ ì‹¤í–‰ìš©)
    """
    # 1) ì„¸ì…˜ ë©”ëª¨ë¦¬ ê°±ì‹ 
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.session_state["bulk_csv_bytes"] = buf.getvalue()

    # ìºì‹œ ë¬´íš¨í™”
    _load_drums_core.clear()

    # 2) ë¡œì»¬ CSVë¡œë„ ì €ì¥ (ìˆìœ¼ë©´)
    try:
        df.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
    except Exception:
        # Cloud í™˜ê²½ì—ì„œëŠ” ë³´í†µ ê¶Œí•œ/ê²½ë¡œê°€ ì—†ìœ¼ë‹ˆ ì¡°ìš©íˆ ë¬´ì‹œ
        pass


@st.cache_data(show_spinner=False)
def _load_production_core(prod_bytes):
    if prod_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(prod_bytes))
        except Exception:
            return pd.DataFrame()
    elif os.path.exists(PRODUCTION_FILE):
        try:
            df = pd.read_excel(PRODUCTION_FILE)
        except Exception:
            return pd.DataFrame()
    else:
        return pd.DataFrame()

    required = ["ì‘ì—…ë²ˆí˜¸", "í’ˆë²ˆ", "í’ˆëª…", "LOTNO", "ì§€ì‹œìˆ˜ëŸ‰", "ì œì¡°ëŸ‰", "ì‘ì—…ì¼ì"]
    for c in required:
        if c not in df.columns:
            return pd.DataFrame()
    return df[required].copy()


def load_production():
    ss = st.session_state
    prod_bytes = ss.get("prod_xlsx_bytes", None)
    return _load_production_core(prod_bytes)


@st.cache_data(show_spinner=False)
def _load_receive_core(recv_bytes):
    if recv_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(recv_bytes))
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(RECEIVE_FILE):
        try:
            df = pd.read_excel(RECEIVE_FILE)
        except Exception as e:
            st.error(f"receive.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        return pd.DataFrame()
    return df


def load_receive():
    ss = st.session_state
    recv_bytes = ss.get("recv_xlsx_bytes", None)
    return _load_receive_core(recv_bytes)


@st.cache_data(show_spinner=False)
def _load_stock_core(stock_bytes):
    if stock_bytes is not None:
        try:
            df = pd.read_excel(io.BytesIO(stock_bytes))
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    elif os.path.exists(STOCK_FILE):
        try:
            df = pd.read_excel(STOCK_FILE)
        except Exception as e:
            st.error(f"stock.xlsx íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame()
    else:
        return pd.DataFrame()
    return df


def load_stock() -> pd.DataFrame:
    ss = st.session_state
    stock_bytes = ss.get("stock_xlsx_bytes", None)
    return _load_stock_core(stock_bytes)


# ==============================
# ìì‚¬ í’ˆë²ˆë³„ ì œí’ˆë¼ì¸ ìë™ ë¶„ë¥˜
# ==============================
NEEDLESHOT_CODES = {
    "3VTCLOS-010",
    "3VTCLOS-006",
    "3VTCLOS-007",
    "3VTCLOS-008",
    "3VTCLOS-011",
    "3VTCLOS-013",
    "3VTCLOS-047",
}

FACIAL_CODES = {
    "3VTCLOS-023",
    "3VTCLOS-024",
    "3VTCLOS-060",
    "3VTCLOS-061",
    "3VTCLOS-062",
    "3VTCLOS-063",
    "3VTCLOS-064",
    "3VTCLOS-065",
}


def classify_product_line(item_code: str) -> str:
    if not isinstance(item_code, str):
        return ""
    code = item_code.strip()
    if code in NEEDLESHOT_CODES:
        return "ë¦¬ë“¤ìƒ·"
    if code in FACIAL_CODES:
        return "í˜ì´ì…œ"
    return ""
def add_tat_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    dfì— 'TAT' ì»¬ëŸ¼ì„ ì¶”ê°€í•´ì„œ ì œì¡°ì¼ìë¡œë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ê²½ê³¼ ê°œì›” ìˆ˜ë¥¼ ì±„ì›Œì¤€ë‹¤.
    - ì œì¡°ì¼ìê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒŒì‹± ë¶ˆê°€í•˜ë©´ TATëŠ” <NA>
    """
    if "ì œì¡°ì¼ì" not in df.columns:
        df["TAT"] = pd.NA
        return df

    # ì œì¡°ì¼ìë¥¼ datetimeìœ¼ë¡œ ë³€í™˜ (ì—¬ëŸ¬ í¬ë§· í—ˆìš©)
    mfg_dt = pd.to_datetime(df["ì œì¡°ì¼ì"], errors="coerce")

    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = date.today()

    # ì—°/ì›” ì°¨ì´ë¡œ ê°œì›” ìˆ˜ ê³„ì‚°
    years_diff = today.year - mfg_dt.dt.year
    months_diff = today.month - mfg_dt.dt.month
    tat_months = years_diff * 12 + months_diff

    # ìŒìˆ˜ ë°©ì§€
    tat_months = tat_months.clip(lower=0)

    # ë‚ ì§œ ì—†ëŠ” ê³³ì€ NAë¡œ
    tat_months = tat_months.where(~mfg_dt.isna(), pd.NA)

    # nullable ì •ìˆ˜ë¡œ ì €ì¥
    df = df.copy()
    df["TAT"] = tat_months.astype("Int64")

    return df

def generate_drums(prod_qty_kg: float):
    """ì œì¡°ëŸ‰(kg)ì„ ë°›ì•„ì„œ í†µë²ˆí˜¸/ìš©ëŸ‰ì„ ìë™ ìƒì„±."""
    if prod_qty_kg is None:
        return []

    try:
        qty = float(prod_qty_kg)
    except Exception:
        return []

    if qty <= 0:
        return []

    drums = []
    if qty < 200:
        drums.append({"í†µë²ˆí˜¸": 1, "í†µìš©ëŸ‰": qty})
        return drums

    full = int(qty // 1000)
    rem = qty % 1000

    for i in range(full):
        drums.append({"í†µë²ˆí˜¸": i + 1, "í†µìš©ëŸ‰": 1000})

    if rem > 0:
        drums.append({"í†µë²ˆí˜¸": full + 1, "í†µìš©ëŸ‰": rem})

    return drums


def ensure_lot_in_csv(
    df: pd.DataFrame,
    lot: str,
    item_code: str,
    item_name: str,
    line: str,
    mfg_date: str,
    initial_status: str = "ìƒì‚°ëŒ€ê¸°",
    prod_qty: float = None,
) -> pd.DataFrame:
    """ì—†ë˜ ë¡œíŠ¸ë©´ í†µ ìë™ ìƒì„±í•´ì„œ CSVì— ì¶”ê°€."""
    if (df["ë¡œíŠ¸ë²ˆí˜¸"] == lot).any():
        return df

    drums = generate_drums(prod_qty)
    if not drums:
        return df

    new_rows = []
    for d in drums:
        new_rows.append(
            {
                "í’ˆëª©ì½”ë“œ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "ì œí’ˆë¼ì¸": line or "",
                "ì œì¡°ì¼ì": mfg_date or "",
                "ìƒíƒœ": initial_status or "ìƒì‚°ëŒ€ê¸°",
                "í†µë²ˆí˜¸": int(d["í†µë²ˆí˜¸"]),
                "í†µìš©ëŸ‰": float(d["í†µìš©ëŸ‰"]),
                "í˜„ì¬ìœ„ì¹˜": "ë¯¸ì§€ì •",
            }
        )

    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)
    return df


# ==============================
# ì´ë™ LOG ìœ í‹¸ (ID í¬í•¨, ì—…ë¡œë“œ/ì„¸ì…˜ ê²¸ìš©)
# ==============================
@st.cache_data(show_spinner=False)
def _load_move_log_core(move_bytes):
    """ì´ë™ ì´ë ¥ CSV ë¡œë“œ."""
    default_cols = [
        "ì‹œê°„",
        "ID",          # ì´ë™ ê¸°ë¡ ì‘ì„±ì (í‘œì‹œìš© ì´ë¦„)
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]

    if move_bytes is not None:
        try:
            df = pd.read_csv(io.BytesIO(move_bytes))
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼(ì—…ë¡œë“œ)ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            df = pd.read_csv(MOVE_LOG_CSV)
        except Exception as e:
            st.error(f"ì´ë™ ì´ë ¥ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return pd.DataFrame(columns=default_cols)
    else:
        return pd.DataFrame(columns=default_cols)

    # ì˜ˆì „ ë¡œê·¸ì— IDì—´ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë³´ì •
    for c in default_cols:
        if c not in df.columns:
            if c == "ID":
                df[c] = ""
            else:
                df[c] = pd.NA

    return df[default_cols]


def load_move_log() -> pd.DataFrame:
    ss = st.session_state
    move_bytes = ss.get("move_log_csv_bytes", None)
    return _load_move_log_core(move_bytes)


def write_move_log(item_code: str, item_name: str, lot: str, drum_infos, from_zone: str, to_zone: str):
    """
    ì´ë™ ì´ë ¥ì„ bulk_move_log.csvì— ê¸°ë¡.
    drum_infos: [(í†µë²ˆí˜¸, moved_qty, old_qty, new_qty), ...]
    ID ì—´ì—ëŠ” ë¡œê·¸ì¸í•œ ì‚¬ìš©ìì˜ 'í‘œì‹œ ì´ë¦„'ì„ ë‚¨ê¸´ë‹¤.
    """
    if not drum_infos:
        return

    ss = st.session_state
    user_display_name = ss.get("user_name", "")

    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    rows = []
    for drum_no, moved_qty, old_qty, new_qty in drum_infos:
        rows.append(
            {
                "ì‹œê°„": ts,
                "ID": user_display_name,
                "í’ˆë²ˆ": item_code,
                "í’ˆëª…": item_name,
                "ë¡œíŠ¸ë²ˆí˜¸": lot,
                "í†µë²ˆí˜¸": drum_no,
                "ë³€ê²½ ì „ ìš©ëŸ‰": old_qty,
                "ë³€ê²½ í›„ ìš©ëŸ‰": new_qty,
                "ë³€í™”ëŸ‰": moved_qty,
                "ë³€ê²½ ì „ ìœ„ì¹˜": from_zone,
                "ë³€ê²½ í›„ ìœ„ì¹˜": to_zone,
            }
        )

    new_df = pd.DataFrame(rows)

    # ê¸°ì¡´ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì„¸ì…˜/ë¡œì»¬)
    if "move_log_csv_bytes" in ss:
        try:
            old_df = pd.read_csv(io.BytesIO(ss["move_log_csv_bytes"]))
        except Exception:
            old_df = pd.DataFrame()
    elif os.path.exists(MOVE_LOG_CSV):
        try:
            old_df = pd.read_csv(MOVE_LOG_CSV)
        except Exception:
            old_df = pd.DataFrame()
    else:
        old_df = pd.DataFrame()

    log_df = pd.concat([old_df, new_df], ignore_index=True)

    # 1) ì„¸ì…˜ì— ë‹¤ì‹œ ì €ì¥
    buf = io.BytesIO()
    log_df.to_csv(buf, index=False, encoding="utf-8-sig")
    ss["move_log_csv_bytes"] = buf.getvalue()

    _load_move_log_core.clear()

    # 2) ë¡œì»¬ CSVì—ë„ ì €ì¥ (ë¡œì»¬ ì‹¤í–‰ìš©)
    try:
        log_df.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
    except Exception:
        pass

# ==============================
# ì—…ë¡œë“œ ì‹œê°„ í‘œì‹œ ìœ í‹¸  (S3 â†’ ë¡œì»¬ ìˆœìœ¼ë¡œ í™•ì¸)
# ==============================
from datetime import datetime

def last_upload_caption(filename: str) -> str:
    """
    1) S3 ê°ì²´ê°€ ìˆìœ¼ë©´ ê·¸ ê°ì²´ì˜ LastModified ì‹œê°„ì„ í‘œì‹œ
    2) ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼ ìˆ˜ì •ì‹œê°„ì„ í‘œì‹œ
    3) ë‘˜ ë‹¤ ì—†ìœ¼ë©´ 'ì—…ë¡œë“œëœ íŒŒì¼ ì—†ìŒ'
    """
    # 1) S3 LastModified -----------------------------------------
    try:
        if s3_enabled():
            client = get_s3_client()
            if client:
                s3_path = _s3_key(filename)
                resp = client.head_object(Bucket=S3_BUCKET_NAME, Key=s3_path)
                lm = resp["LastModified"]  # timezone aware datetime
                ts_str = lm.astimezone().strftime("%Y-%m-%d %H:%M:%S")
                return f"S3 ë§ˆì§€ë§‰ ìˆ˜ì •: {ts_str}"
    except Exception:
        pass

    # 2) ë¡œì»¬ íŒŒì¼ mtime -----------------------------------------
    if os.path.exists(filename):
        try:
            ts = os.path.getmtime(filename)
            dt = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
            return f"ë¡œì»¬ ë§ˆì§€ë§‰ ìˆ˜ì •: {dt}"
        except Exception:
            return "ë¡œì»¬ íŒŒì¼ ì‹œê°„ ì½ê¸° ì˜¤ë¥˜"

    # 3) ë‘˜ ë‹¤ ì—†ìŒ ----------------------------------------------
    return "ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."



# ==============================
# ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í™”ë©´ (ìµœì´ˆ 1íšŒìš©)
# ==============================
def render_file_loader():
    ss = st.session_state

    st.title("ğŸ“ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ")
    st.markdown(
        """
        Streamlit Cloud ë˜ëŠ” ì´ˆê¸° ì„¤ì • ì‹œ, GitHubì— ì˜¬ë¦¬ê¸° ì–´ë ¤ìš´ CSV/ì—‘ì…€ íŒŒì¼ë“¤ì„
        ì—¬ê¸°ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.

        ì•„ë˜ 4ê°œ íŒŒì¼ì€ **í•„ìˆ˜**ì´ê³ , ì´ë™ ì´ë ¥(`bulk_move_log.csv`)ì€ **ìˆìœ¼ë©´ ì—…ë¡œë“œ, ì—†ìœ¼ë©´ ìƒëµ**í•´ë„ ë©ë‹ˆë‹¤.
        """
    )

    col_left, col_right = st.columns(2)

    with col_left:
        bulk_file = st.file_uploader(
            "1) bulk_drums_extended.csv (í•„ìˆ˜)",
            type=["csv"],
            key="first_up_bulk",
        )
        st.caption(last_upload_caption(CSV_PATH))

        prod_file = st.file_uploader(
            "2) production.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        recv_file = st.file_uploader(
            "3) receive.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        stock_file = st.file_uploader(
            "4) stock.xlsx (í•„ìˆ˜)",
            type=["xlsx"],
            key="first_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

    with col_right:
        move_file = st.file_uploader(
            "5) bulk_move_log.csv (ì„ íƒ)",
            type=["csv"],
            key="first_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))
        st.caption("â€» ì—†ìœ¼ë©´ ì—…ë¡œë“œ ì•ˆ í•´ë„ ë©ë‹ˆë‹¤. ìƒˆ ë¡œê·¸ë¡œ ì‹œì‘í•´ìš”.")

    if st.button("ì—…ë¡œë“œ ì™„ë£Œ", key="first_upload_done"):
        missing = []
        if bulk_file is None:
            missing.append("bulk_drums_extended.csv")
        if prod_file is None:
            missing.append("production.xlsx")
        if recv_file is None:
            missing.append("receive.xlsx")
        if stock_file is None:
            missing.append("stock.xlsx")

        if missing:
            st.error("ë‹¤ìŒ í•„ìˆ˜ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”: " + ", ".join(missing))
            return

        # ---------- 1) ì—…ë¡œë“œ íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ì„¸ì…˜ì— ì €ì¥ ----------
        bulk_bytes = bulk_file.read()
        prod_bytes = prod_file.read()
        recv_bytes = recv_file.read()
        stock_bytes = stock_file.read()
        move_bytes = move_file.read() if move_file is not None else None

        ss["bulk_csv_bytes"] = bulk_bytes
        ss["prod_xlsx_bytes"] = prod_bytes
        ss["recv_xlsx_bytes"] = recv_bytes
        ss["stock_xlsx_bytes"] = stock_bytes
        if move_bytes is not None:
            ss["move_log_csv_bytes"] = move_bytes

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.caption(last_upload_caption(CSV_PATH))
        st.caption(last_upload_caption(PRODUCTION_FILE))
        st.caption(last_upload_caption(RECEIVE_FILE))
        st.caption(last_upload_caption(STOCK_FILE))
        st.caption(last_upload_caption(MOVE_LOG_CSV))


        # ---------- 2) ì„œë²„ ë¡œì»¬ íŒŒì¼ë¡œë„ ì €ì¥ (ì´í›„ ì„¸ì…˜ì—ì„œ ì¬ì‚¬ìš©) ----------
        try:
            _load_drums_core.clear()
            df_bulk = _load_drums_core(bulk_bytes)
            df_bulk.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
        except Exception:
            pass

        try:
            _load_production_core.clear()
            df_prod = _load_production_core(prod_bytes)
            df_prod.to_excel(PRODUCTION_FILE, index=False)
        except Exception:
            pass

        try:
            _load_receive_core.clear()
            df_recv = _load_receive_core(recv_bytes)
            df_recv.to_excel(RECEIVE_FILE, index=False)
        except Exception:
            pass

        try:
            _load_stock_core.clear()
            df_stock = _load_stock_core(stock_bytes)
            df_stock.to_excel(STOCK_FILE, index=False)
        except Exception:
            pass

        if move_bytes is not None:
            try:
                _load_move_log_core.clear()
                df_move = _load_move_log_core(move_bytes)
                df_move.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
            except Exception:
                pass

        # ---------- 3) í”Œë˜ê·¸ ì„¸íŒ… í›„ ë©”ì¸ìœ¼ë¡œ ----------
        ss["data_initialized"] = True

        st.success("íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.rerun()


# ==============================
# ë¡œê·¸ì¸ í™”ë©´
# ==============================
def render_login():
    ss = st.session_state
    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë¡œê·¸ì¸")

    st.markdown("ì‘ì—… ì „ IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    login_id = st.text_input("ID", key="login_id")
    login_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")

    if st.button("ë¡œê·¸ì¸", key="login_btn"):
        user = USER_ACCOUNTS.get((login_id or "").strip())
        if user and login_pw == user["password"]:
            ss["user_id"] = (login_id or "").strip()
            ss["user_name"] = user["display_name"]
            st.success(f"{user['display_name']}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.")
            st.rerun()
        else:
            st.error("ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")


# ==============================
# (ìƒëµëë˜) get_stock_summary ë”ë¯¸ ì •ì˜
# ==============================
def get_stock_summary(item_code: str, lot: str):
    """
    ì›ë˜ ì½”ë“œì— ìˆë˜ get_stock_summaryê°€ ì§ˆë¬¸ ì½”ë“œì—ëŠ” ì—†ì–´ì„œ
    ìµœì†Œí•œì˜ ë”ë¯¸ë¡œ ë„£ì–´ ë‘¡ë‹ˆë‹¤.
    ì‹¤ì œ ì „ì‚° ì¬ê³  ì—°ë™ ë¡œì§ì´ ìˆë‹¤ë©´ ì´ ë¶€ë¶„ì„ êµì²´í•´ ì£¼ì„¸ìš”.
    """
    return None, ""


# ==============================
# íƒ­ 1: ì´ë™
# ==============================
def clear_move_inputs():
    """ì¡°íšŒ/ì´ˆê¸°í™” ë²„íŠ¼ ì˜†ì—ì„œ ì‚¬ìš©í•  ì…ë ¥ê°’ ì´ˆê¸°í™” ì½œë°±."""
    ss = st.session_state
    ss["mv_barcode"] = ""
    ss["mv_lot"] = ""
    ss["mv_scanned_barcode"] = ""


def render_tab_move():
    st.markdown("### ğŸ“¦ ë²Œí¬ ì´ë™")

    ss = st.session_state
    ss.setdefault("mv_scanned_barcode", "")
    ss.setdefault("mv_searched_csv", False)
    ss.setdefault("mv_search_by_lot", False)
    ss.setdefault("mv_last_lot", "")
    ss.setdefault("mv_last_barcode", "")
    ss.setdefault("mv_show_stock_detail", False)
    ss.setdefault("mv_show_move_history_here", False)

    bulk_type = st.radio(
        "ë²Œí¬ êµ¬ë¶„ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
        ["ìì‚¬", "ì‚¬ê¸‰"],
        horizontal=True,
        key="mv_bulk_type_csv",
    )
    barcode_label = "ì‘ì—…ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”." if bulk_type == "ìì‚¬" else "ì…í•˜ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."

    # ================== ìƒë‹¨ ì…ë ¥ ==================

    # 1ì¤„: ì‘ì—…ë²ˆí˜¸/ì…í•˜ë²ˆí˜¸ + ë¡œíŠ¸ë²ˆí˜¸ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
    col_in1, col_in2, _sp = st.columns([0.49, 0.49, 2.5])

    with col_in1:
        barcode = st.text_input(
            barcode_label,
            key="mv_barcode",
            placeholder="ì˜ˆ: W24012345",
        )

    with col_in2:
        lot_input = st.text_input(
            "ë¡œíŠ¸ë²ˆí˜¸",
            key="mv_lot",
            placeholder="ì˜ˆ: 2E075K",
        )

    # ================== 2ì¤„: ë°”ì½”ë“œ ìŠ¤ìº” ì—…ë¡œë“œ (ì ˆë°˜ ë„ˆë¹„) ==================
    st.write("")

    scan_col, empty_col = st.columns([1.2, 3])   # â† ì—¬ê¸°ì„œ ë„ˆë¹„ê°€ ê²°ì •ëœë‹¤!

    with scan_col:
        st.caption("ë¼ë²¨ ì‚¬ì§„ ì—…ë¡œë“œ (ì„ íƒ)")
        scan_file = st.file_uploader(
            "ë°”ì½”ë“œ ì¸ì‹",
            type=["png", "jpg", "jpeg"],
            key="mv_barcode_image",
        )

        if scan_file is not None:
            if Image is None or CaptureVisionRouter is None or LicenseManager is None:
                st.error("ë°”ì½”ë“œ ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                try:
                    img = Image.open(io.BytesIO(scan_file.read()))
                    st.image(img, caption=scan_file.name, width=220)
                    codes = dbr_decode(img)
                    if codes:
                        _, text_code = codes[0]
                        ss["mv_scanned_barcode"] = text_code.strip()
                        st.success(f"ì¸ì‹ë¨: {text_code}")
                    else:
                        st.warning("ë°”ì½”ë“œë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")

    # ================== 3ì¤„: ì¡°íšŒ / ì´ˆê¸°í™” ë²„íŠ¼ ==================
    st.write("")
    btn_col1, btn_col2, _ = st.columns([0.5, 0.5, 3])

    search_clicked = False
    with btn_col1:
        if st.button("ì¡°íšŒí•˜ê¸°", key="mv_search_btn_csv"):
            search_clicked = True

    with btn_col2:
        st.button("ì´ˆê¸°í™”", key="mv_clear_btn", on_click=clear_move_inputs)


    # ì¡°íšŒ ë²„íŠ¼ ì²˜ë¦¬
    if "search_clicked" in locals() and search_clicked:
        barcode_val = (barcode or "").strip()
        lot_val = (lot_input or "").strip()
        scanned_val = ss.get("mv_scanned_barcode", "").strip()

        if not lot_val and not barcode_val and not scanned_val:
            st.warning("ë¨¼ì € ì‘ì—…ë²ˆí˜¸/ì…í•˜ë²ˆí˜¸ ë˜ëŠ” ë¡œíŠ¸ë²ˆí˜¸ë¥¼ ì…ë ¥(ë˜ëŠ” ë°”ì½”ë“œë¥¼ ìŠ¤ìº”)í•´ ì£¼ì„¸ìš”.")
            ss["mv_searched_csv"] = False
            return

        search_by_lot = bool(lot_val)

        if not search_by_lot:
            if not barcode_val and scanned_val:
                barcode_val = scanned_val

        ss["mv_last_lot"] = lot_val
        ss["mv_last_barcode"] = barcode_val
        ss["mv_search_by_lot"] = search_by_lot
        ss["mv_searched_csv"] = True
        ss["mv_scanned_barcode"] = ""
        ss["mv_show_move_history_here"] = False

    if not ss["mv_searched_csv"]:
        return

    # ===================== ê²€ìƒ‰ í›„ ë¡œì§ =====================
    df = load_drums()
    prod_df = load_production()
    recv_df = load_receive()

    search_by_lot = ss.get("mv_search_by_lot", False)
    lot = ""
    item_code = ""
    item_name = ""
    prod_date = ""
    prod_qty = None
    line = ""
    barcode_used = ""

    if search_by_lot:
        lot = (ss.get("mv_last_lot") or "").strip()
        if not lot:
            st.warning("ë¡œíŠ¸ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return
        barcode_used = lot
    else:
        barcode_query = (ss.get("mv_last_barcode") or "").strip()
        if not barcode_query:
            st.warning("ì‘ì—…ë²ˆí˜¸/ì…í•˜ë²ˆí˜¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            ss["mv_searched_csv"] = False
            return

        if bulk_type == "ìì‚¬":
            if prod_df.empty:
                st.error("production.xlsx íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ì–´ì„œ ì‘ì—…ë²ˆí˜¸ ê¸°ë°˜ ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            hit = prod_df[prod_df["ì‘ì—…ë²ˆí˜¸"].astype(str) == barcode_query]
            if hit.empty:
                st.warning("í•´ë‹¹ ì‘ì—…ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]
            lot = str(r["LOTNO"])
            item_code = str(r["í’ˆë²ˆ"])
            item_name = str(r["í’ˆëª…"])
            prod_qty = float(r["ì œì¡°ëŸ‰"]) if not pd.isna(r["ì œì¡°ëŸ‰"]) else None
            prod_date = str(r["ì‘ì—…ì¼ì"])
            line = classify_product_line(item_code)

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

        else:  # ì‚¬ê¸‰
            if recv_df.empty:
                st.error("receive.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            if "ì…í•˜ë²ˆí˜¸" not in recv_df.columns:
                st.error("receive.xlsxì— 'ì…í•˜ë²ˆí˜¸' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            hit = recv_df[recv_df["ì…í•˜ë²ˆí˜¸"].astype(str) == barcode_query]
            if hit.empty:
                st.warning("í•´ë‹¹ ì…í•˜ë²ˆí˜¸ë¥¼ receive.xlsxì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            r = hit.iloc[0]
            if "í’ˆë²ˆ" not in recv_df.columns or "í’ˆëª…" not in recv_df.columns or "ë¡œíŠ¸ë²ˆí˜¸" not in recv_df.columns:
                st.error("receive.xlsxì— í’ˆë²ˆ/í’ˆëª…/ë¡œíŠ¸ë²ˆí˜¸ ê´€ë ¨ ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                ss["mv_searched_csv"] = False
                return

            item_code = str(r["í’ˆë²ˆ"])
            item_name = str(r["í’ˆëª…"])
            lot = str(r["ë¡œíŠ¸ë²ˆí˜¸"])

            if "ì…í•˜ëŸ‰" in recv_df.columns:
                prod_qty = float(r["ì…í•˜ëŸ‰"]) if not pd.isna(r["ì…í•˜ëŸ‰"]) else None
            else:
                prod_qty = None

            if "ì œì¡°ì¼ì" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ì¼ì"]) else str(r["ì œì¡°ì¼ì"])
            elif "ì œì¡°ë…„ì›”ì¼" in recv_df.columns:
                prod_date = "" if pd.isna(r["ì œì¡°ë…„ì›”ì¼"]) else str(r["ì œì¡°ë…„ì›”ì¼"])
            else:
                prod_date = ""

            trade_type = str(r.get("ìœ /ë¬´ìƒ", "")).strip()
            if trade_type == "ìœ ìƒ":
                line = "ì‚¬ê¸‰(ìœ ìƒ)"
            elif trade_type == "ë¬´ìƒ":
                line = "ì‚¬ê¸‰(ë¬´ìƒ)"
            else:
                line = "ì‚¬ê¸‰"

            df = ensure_lot_in_csv(
                df,
                lot=lot,
                item_code=item_code,
                item_name=item_name,
                line=line,
                mfg_date=prod_date,
                initial_status="ìƒì‚°ëŒ€ê¸°",
                prod_qty=prod_qty,
            )
            save_drums(df)

        barcode_used = barcode_query

    df = load_drums()
    lot_df = df[df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == lot].copy()
    if lot_df.empty:
        st.warning("CSVì—ì„œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ í†µ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        ss["mv_searched_csv"] = False
        return

    combos = lot_df[["í’ˆëª©ì½”ë“œ", "í’ˆëª…"]].drop_duplicates().reset_index(drop=True)
    if len(combos) == 1:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])
    elif len(combos) > 1 and ss.get("mv_search_by_lot", False):
        st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì— ì—¬ëŸ¬ í’ˆëª…ì´ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        options = [
            f"{row['í’ˆëª©ì½”ë“œ']} / {row['í’ˆëª…']}"
            for _, row in combos.iterrows()
        ]
        selected_label = st.selectbox(
            "í’ˆëª…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.",
            options,
            key=f"mv_lot_item_select_{lot}",
        )
        sel_idx = options.index(selected_label)
        item_code = str(combos.at[sel_idx, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[sel_idx, "í’ˆëª…"])
        lot_df = lot_df[
            (lot_df["í’ˆëª©ì½”ë“œ"].astype(str) == item_code)
            & (lot_df["í’ˆëª…"].astype(str) == item_name)
        ].copy()
    else:
        item_code = str(combos.at[0, "í’ˆëª©ì½”ë“œ"])
        item_name = str(combos.at[0, "í’ˆëª…"])

    if not prod_date:
        dates = (
            lot_df["ì œì¡°ì¼ì"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if dates:
            prod_date = dates[0]

    if not line:
        lines = (
            lot_df["ì œí’ˆë¼ì¸"]
            .dropna()
            .astype(str)
            .replace("", pd.NA)
            .dropna()
            .unique()
            .tolist()
        )
        if lines:
            line = lines[0]

    lot_df = lot_df.sort_values("í†µë²ˆí˜¸")

    loc_unique = lot_df["í˜„ì¬ìœ„ì¹˜"].dropna().unique().tolist()
    if len(loc_unique) == 1:
        current_zone = loc_unique[0]
    elif len(loc_unique) == 0:
        current_zone = "ë¯¸ì§€ì •"
    else:
        current_zone = "í˜¼í•©"

    stock_summary_df, stock_summary_text = get_stock_summary(item_code, lot)
    if stock_summary_df is not None and not stock_summary_df.empty:
        top = stock_summary_df.iloc[0]
        stock_loc_display = f"{top['ëŒ€ë¶„ë¥˜']}({top['ì°½ê³ ëª…']})"
    else:
        stock_loc_display = current_zone

    col_left2, col_right2 = st.columns(2)

    # ===== ì™¼ìª½: ì¡°íšŒ ì •ë³´ + í†µ ì„ íƒ =====
    with col_left2:
        st.markdown("### ğŸ§¾ ì¡°íšŒ ì •ë³´")
        st.success("ì¡°íšŒê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.markdown(
            f"""
            **ë²Œí¬ êµ¬ë¶„:** {bulk_type}  
            **ì‹ë³„ê°’:** {barcode_used}  
            **í’ˆëª©ì½”ë“œ:** {item_code}  
            **í’ˆëª…:** {item_name}  
            **ë¡œíŠ¸ë²ˆí˜¸:** {lot}  
            **ì œì¡°ì¼ì:** {prod_date}  
            """
        )

        # í˜„ì¬ ìœ„ì¹˜ + [ìƒì„¸ë³´ê¸°] + [ì´ë™ì´ë ¥] ë²„íŠ¼
        loc_col1, loc_col2 = st.columns([3, 2])
        with loc_col1:
            st.markdown(f"**í˜„ì¬ ìœ„ì¹˜(ì „ì‚° ê¸°ì¤€):** {stock_loc_display}")
        with loc_col2:
            b1_col, b_sp, b2_col = st.columns([1, 0.05, 1])
            # âœ… í•­ìƒ ë³´ì´ëŠ” ìƒì„¸ë³´ê¸° ë²„íŠ¼
            with b1_col:
                if st.button("ìƒì„¸ë³´ê¸°", key=f"stock_detail_btn_{lot}"):
                    ss["mv_show_stock_detail"] = not ss.get("mv_show_stock_detail", False)
            with b2_col:
                if st.button("ì´ë™ì´ë ¥", key=f"move_hist_btn_{lot}"):
                    ss["mv_show_move_history_here"] = not ss.get("mv_show_move_history_here", False)

        # âœ… ì „ì‚° ì¬ê³  ìƒì„¸ í† ê¸€
        if ss.get("mv_show_stock_detail", False):
            if stock_summary_df is not None and not stock_summary_df.empty:
                st.markdown("#### ğŸ” ì „ì‚° ì¬ê³  ìƒì„¸")
                st.dataframe(stock_summary_df, use_container_width=True, height=240)
            else:
                st.info("ì „ì‚° ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ›¢ í†µ ì„ íƒ ë° ì”ëŸ‰ ì…ë ¥")


        selected_drums = []
        drum_new_qty = {}

        drum_list = lot_df["í†µë²ˆí˜¸"].tolist()
        # ëª¨ë‘ ì„ íƒ / ëª¨ë‘ í•´ì œ  - ë²„íŠ¼ í­ì„ ì¡°ê¸ˆë§Œ ì‚¬ìš©í•˜ëŠ” ì¢ì€ ì»¬ëŸ¼
        c1, c_sp, c2, _c_gap = st.columns([1.5, 0.5, 1.5, 7])
        with c1:
            if st.button("ëª¨ë‘ ì„ íƒ", key=f"mv_select_all_{lot}", use_container_width=False):
                for dn in drum_list:
                    st.session_state[f"mv_sel_{lot}_{dn}"] = True
        with c2:
            if st.button("ëª¨ë‘ í•´ì œ", key=f"mv_select_none_{lot}", use_container_width=False):
                for dn in drum_list:
                    st.session_state[f"mv_sel_{lot}_{dn}"] = False


        for _, row in lot_df.iterrows():
            drum_no = int(row["í†µë²ˆí˜¸"])
            old_qty = float(row["í†µìš©ëŸ‰"])
            drum_loc = str(row.get("í˜„ì¬ìœ„ì¹˜", "") or "").strip()

            if drum_loc:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg (ìœ„ì¹˜: {drum_loc})"
            else:
                label = f"{drum_no}ë²ˆ í†µ â€” ê¸°ì¡´ {old_qty:.0f}kg"

            cb_key = f"mv_sel_{lot}_{drum_no}"
            checked = st.checkbox(label, key=cb_key)
            if checked:
                selected_drums.append(drum_no)
                new_val = st.number_input(
                    f"í†µ {drum_no}ì˜ í˜„ì¬ ìš©ëŸ‰(kg)",
                    min_value=0.0,
                    max_value=old_qty,
                    value=old_qty,
                    step=10.0,
                    format="%.0f",
                    key=f"mv_qty_{lot}_{drum_no}",
                )
                drum_new_qty[drum_no] = float(new_val)

    # ===== ì˜¤ë¥¸ìª½: ì´ë™ ìœ„ì¹˜ + ìƒíƒœ + ë¹„ê³  + ì €ì¥ =====
    with col_right2:
        st.markdown("### ğŸšš ì´ë™ ìœ„ì¹˜ ì„ íƒ")

        col1, col2 = st.columns(2)
        with col1:
            from_zone = st.text_input(
                "í˜„ì¬ ìœ„ì¹˜",
                value=current_zone if current_zone != "í˜¼í•©" else "",
                help="ì˜ˆ: 4ì¸µ-A1, ì™¸ì£¼ ë“±",
                key="mv_from_zone_csv",
            )
        with col2:
            floor_list = ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ", "ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]
            sel_floor = st.selectbox(
                "ì´ë™í•˜ì‹¤ ì¸µ/êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", floor_list, key="mv_floor_csv"
            )
            if sel_floor in ["ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]:
                sel_zone = ""
            else:
                zone_list = ["A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"]
                sel_zone = st.selectbox(
                    "ì´ë™í•˜ì‹¤ êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", zone_list, key="mv_zone_csv"
                )

            if sel_floor in ["ì°½ê³ ", "ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼"]:
                to_zone = sel_floor
            else:
                to_zone = f"{sel_floor}-{sel_zone}"

        if to_zone == "ì™¸ì£¼":
            move_status = "ì™¸ì£¼"
            st.info("ì´ë™ ìœ„ì¹˜ê°€ 'ì™¸ì£¼'ì´ë¯€ë¡œ ìƒíƒœëŠ” ìë™ìœ¼ë¡œ 'ì™¸ì£¼'ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
        else:
            move_status = st.radio(
                "ì´ë™ í›„ ìƒíƒœë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.",
                ["ì”ëŸ‰", "ìƒì‚°ì¢…ë£Œ"],
                horizontal=True,
                key="mv_status_csv",
            )

        note = st.text_area("ë¹„ê³ (ì„ íƒ ì…ë ¥)", height=80, key="mv_note_csv")

        if st.button("ì´ë™ ë‚´ìš© ì €ì¥ (CSV ë°˜ì˜)", key="mv_save_csv"):
            if not selected_drums:
                st.warning("ì´ë™í•˜ì‹¤ í†µì„ í•œ ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                return

            df_all = load_drums()
            lot_mask = df_all["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == lot

            drum_logs = []

            for dn in selected_drums:
                idx = df_all.index[lot_mask & (df_all["í†µë²ˆí˜¸"] == dn)]
                if len(idx) == 0:
                    continue
                i = idx[0]
                old_qty = float(df_all.at[i, "í†µìš©ëŸ‰"])
                new_qty = drum_new_qty.get(dn, old_qty)
                moved = old_qty - new_qty

                df_all.at[i, "í†µìš©ëŸ‰"] = new_qty
                df_all.at[i, "í˜„ì¬ìœ„ì¹˜"] = to_zone

                if to_zone == "ì™¸ì£¼":
                    df_all.at[i, "ìƒíƒœ"] = "ì™¸ì£¼"
                else:
                    df_all.at[i, "ìƒíƒœ"] = move_status

                drum_logs.append((dn, moved, old_qty, new_qty))

            save_drums(df_all)

            # CSV + ì´ë™ ì´ë ¥ ë¡œê·¸ ì €ì¥
            write_move_log(
                item_code=item_code,
                item_name=item_name,
                lot=lot,
                drum_infos=drum_logs,
                from_zone=from_zone,
                to_zone=to_zone,
            )

            st.success(f"ì´ {len(drum_logs)}ê°œì˜ í†µ ì •ë³´ê°€ CSV ë° ì´ë™ ì´ë ¥ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ì´ë™ íƒ­ ë‚´ë¶€ì—ì„œ í˜„ì¬ LOT ì´ë™ ì´ë ¥ í‘œì‹œ
    if ss.get("mv_show_move_history_here", False):
        log_df = load_move_log()
        if log_df.empty:
            st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sub = log_df[log_df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str) == str(lot)].copy()
            if sub.empty:
                st.info("í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ì˜ ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("### ğŸ“œ í•´ë‹¹ ë¡œíŠ¸ë²ˆí˜¸ ì´ë™ ì´ë ¥")
                sub = sub.sort_values("ì‹œê°„", ascending=False).head(50)
                st.dataframe(sub, use_container_width=True)



# ==============================
# íƒ­ 2: ì¡°íšŒ
# ==============================
def render_tab_lookup():
    st.markdown("### ğŸ” ë²Œí¬ ì¡°íšŒ")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # âœ… ì œì¡°ì¼ì ê¸°ì¤€ TAT(ê°œì›”) ì»¬ëŸ¼ ì¶”ê°€
    df = add_tat_column(df)
    
    query = st.text_input("ë¡œíŠ¸ë²ˆí˜¸, í’ˆëª©ì½”ë“œ ë˜ëŠ” í˜„ì¬ìœ„ì¹˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    if query:
        q = query.strip()
        mask = (
            df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.contains(q, na=False)
            | df["í’ˆëª©ì½”ë“œ"].astype(str).str.contains(q, na=False)
            | df["í˜„ì¬ìœ„ì¹˜"].astype(str).str.contains(q, na=False)
        )
        df_view = df[mask]
    else:
        df_view = df

    if df_view.empty:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("#### ğŸ“„ í–‰ë³„ ìƒì„¸")
    st.dataframe(df_view, use_container_width=True)

    st.markdown("---")
    st.markdown("#### ğŸ“Š í˜„ì¬ìœ„ì¹˜ë³„ ìš©ëŸ‰ ìš”ì•½")

    summary = (
        df_view.groupby("í˜„ì¬ìœ„ì¹˜", dropna=False)
        .agg(
            í†µê°œìˆ˜=("í†µë²ˆí˜¸", "count"),
            ì´ìš©ëŸ‰_kg=("í†µìš©ëŸ‰", "sum"),
        )
        .reset_index()
        .sort_values("í˜„ì¬ìœ„ì¹˜")
    )

    # í–‰ ê°œìˆ˜ì— ë§ì¶° ë†’ì´ ìë™ ì¡°ì •
    row_height = 35
    header_height = 40
    dynamic_height = header_height + row_height * (len(summary) + 1)

    st.dataframe(summary, width=300, height=dynamic_height)

    st.markdown("---")
    if st.button("í˜„ì¬ CSVë¥¼ ê·¸ëŒ€ë¡œ ë°±ì—… ì €ì¥í•˜ê¸°"):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"bulk_drums_extended_backup_{ts}.csv"
        df.to_csv(backup_name, index=False, encoding="utf-8-sig")
        st.success(f"ë°±ì—… íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {backup_name}")


# ==============================
# íƒ­ 3: ì§€ë„
# ==============================
def render_tab_map():
    st.markdown("### ğŸ—º ë²Œí¬ ìœ„ì¹˜ ì§€ë„ (CSV ê¸°ì¤€)")

    df = load_drums()
    if df.empty:
        st.info("CSVì— ë“±ë¡ëœ ë²Œí¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    def get_floor(loc: str) -> str:
        if pd.isna(loc):
            return ""
        s = str(loc).strip()
        if "-" in s:
            return s.split("-")[0]
        return s

    df["ì¸µ"] = df["í˜„ì¬ìœ„ì¹˜"].apply(get_floor)

    floors = (
        df["ì¸µ"]
        .dropna()
        .astype(str)
        .replace("", pd.NA)
        .dropna()
        .unique()
        .tolist()
    )
    floors = sorted(floors)

    if not floors:
        st.info("ì¸µ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    sel_floor = st.selectbox("í™•ì¸í•˜ì‹¤ ì¸µ/êµ¬ì—­ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.", floors, key="map_floor_csv")

    fdf = df[df["ì¸µ"] == sel_floor].copy()
    if fdf.empty:
        st.info("í•´ë‹¹ ì¸µ/êµ¬ì—­ì— ë“±ë¡ëœ ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì†Œì§„ / ë¯¸ì§€ì • / íê¸° / ì™¸ì£¼ / ì°½ê³  ëŠ” ë‹¨ì¼ êµ¬ì—­ìœ¼ë¡œ ì²˜ë¦¬
    special_floors = {"ì†Œì§„", "ë¯¸ì§€ì •", "íê¸°", "ì™¸ì£¼", "ì°½ê³ "}
    if sel_floor in special_floors:
        st.markdown(f"#### {sel_floor} êµ¬ì—­ í˜„í™©")

        drums = len(fdf)
        vol = fdf["í†µìš©ëŸ‰"].sum()

        st.write(f"**í†µ ê°œìˆ˜:** {drums}í†µ")
        st.write(f"**ì´ ìš©ëŸ‰:** {int(vol)}kg")

        st.markdown("---")
        st.markdown("### ğŸ” ìƒì„¸ ëª©ë¡")

        show_cols = [
            "í’ˆëª©ì½”ë“œ",
            "í’ˆëª…",
            "ë¡œíŠ¸ë²ˆí˜¸",
            "ì œí’ˆë¼ì¸",
            "ì œì¡°ì¼ì",
            "ìƒíƒœ",
            "í˜„ì¬ìœ„ì¹˜",
            "í†µë²ˆí˜¸",
            "í†µìš©ëŸ‰",
        ]
        st.dataframe(
            fdf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
            use_container_width=True,
        )
        return

    def get_zone_label(loc: str) -> str:
        if pd.isna(loc):
            return ""
        s = str(loc).strip()
        if "-" in s:
            return s.split("-")[1]
        if s in ["2ì¸µ", "4ì¸µ", "5ì¸µ", "6ì¸µ"]:
            return "A1"
        return s

    fdf["zone_label"] = fdf["í˜„ì¬ìœ„ì¹˜"].apply(get_zone_label)

    labels_all = [f"{r}{c}" for r in ["A", "B", "C"] for c in [1, 2, 3]]

    zone_stats = {}
    max_vol = 0.0
    for label in labels_all:
        sub = fdf[fdf["zone_label"] == label]
        drums = len(sub)
        vol = sub["í†µìš©ëŸ‰"].sum()
        zone_stats[label] = {"drums": drums, "volume": vol}
        max_vol = max(max_vol, vol)

    def badge(volume):
        if volume <= 0:
            return "âšª"
        if max_vol <= 0:
            return "ğŸŸ¡"
        ratio = volume / max_vol
        if ratio > 0.7:
            return "ğŸ”´"
        elif ratio > 0.3:
            return "ğŸŸ "
        else:
            return "ğŸŸ¡"

    st.markdown(f"#### {sel_floor} Zoneë³„ í˜„í™© (í†µ ê°œìˆ˜ / ì´ ìš©ëŸ‰)")

    for row in ["A", "B", "C"]:
        cols = st.columns(3)
        for i, col in enumerate(cols):
            label = f"{row}{i+1}"
            info = zone_stats.get(label, {"drums": 0, "volume": 0})
            txt = (
                f"{label} {badge(info['volume'])}\n"
                f"{info['drums']}í†µ / {int(info['volume'])}kg"
            )
            if col.button(txt, key=f"map_btn_{sel_floor}_{label}"):
                st.session_state["clicked_zone_csv"] = f"{sel_floor}-{label}"

    st.markdown("---")
    st.markdown("### ğŸ” Zone ìƒì„¸ ë³´ê¸°")

    clicked = st.session_state.get("clicked_zone_csv", None)
    if not clicked:
        st.info("í™•ì¸í•˜ì‹¤ Zone ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
        return

    st.success(f"ì„ íƒëœ Zone: {clicked}")
    _, cz_label = clicked.split("-")

    ddf = fdf[fdf["zone_label"] == cz_label].copy()
    if ddf.empty:
        st.info("í•´ë‹¹ Zoneì—ëŠ” ë²Œí¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    show_cols = [
        "í’ˆëª©ì½”ë“œ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "ì œí’ˆë¼ì¸",
        "ì œì¡°ì¼ì",
        "ìƒíƒœ",
        "í˜„ì¬ìœ„ì¹˜",
        "í†µë²ˆí˜¸",
        "í†µìš©ëŸ‰",
    ]
    st.dataframe(
        ddf[show_cols].sort_values(["ë¡œíŠ¸ë²ˆí˜¸", "í†µë²ˆí˜¸"]),
        use_container_width=True,
    )


# ==============================
# íƒ­ 4: ì´ë™ ì´ë ¥ (ìˆ˜ì • + í–‰ ì‚­ì œ ê°€ëŠ¥)
# ==============================
def render_tab_move_log():
    st.markdown("### ğŸ“œ ì´ë™ ì´ë ¥ (ìˆ˜ì • / ì‚­ì œ ê°€ëŠ¥)")

    df = load_move_log()
    if df.empty:
        st.info("ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    ss = st.session_state
    ss.setdefault("log_lot_filter", "")
    ss.setdefault("log_page", 1)

    # â–¶ ê²€ìƒ‰ ì´ˆê¸°í™” ì½œë°± (ì—¬ê¸°ì„œë§Œ state ìˆ˜ì •)
    def reset_log_filter():
        ss["log_lot_filter"] = ""
        ss["log_page"] = 1

    col1, col2 = st.columns([3, 1])
    with col1:
        lot_filter = st.text_input(
            "ë¡œíŠ¸ë²ˆí˜¸ë¡œ ê²€ìƒ‰ (ë¶€ë¶„ ì¼ì¹˜)",
            key="log_lot_filter",
            placeholder="ì˜ˆ: 2E075K",
        )
    with col2:
        st.button("ê²€ìƒ‰ ì´ˆê¸°í™”", key="log_reset", on_click=reset_log_filter)

    # í•„í„° ì ìš©
    if lot_filter:
        mask = df["ë¡œíŠ¸ë²ˆí˜¸"].astype(str).str.contains(lot_filter.strip(), na=False)
        df_view = df[mask].copy()
    else:
        df_view = df.copy()

    if df_view.empty:
        st.info("ê²€ìƒ‰ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì´ë™ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‹œê°„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    df_view = df_view.sort_values("ì‹œê°„", ascending=False)

    # --- í˜ì´ì§€ë„¤ì´ì…˜ ---
    page_size = 50
    total_rows = len(df_view)
    total_pages = max(1, math.ceil(total_rows / page_size))

    ss["log_page"] = min(max(1, ss.get("log_page", 1)), total_pages)

    colp1, colp2, colp3 = st.columns([1, 2, 1])
    with colp1:
        if st.button("â—€ ì´ì „", key="log_prev") and ss["log_page"] > 1:
            ss["log_page"] -= 1
    with colp2:
        st.write(f"í˜ì´ì§€ {ss['log_page']} / {total_pages} (ì´ {total_rows}ê±´)")
    with colp3:
        if st.button("ë‹¤ìŒ â–¶", key="log_next") and ss["log_page"] < total_pages:
            ss["log_page"] += 1

    start = (ss["log_page"] - 1) * page_size
    end = start + page_size
    page_df = df_view.iloc[start:end].copy()

    # í‘œì‹œ/í¸ì§‘í•  ì»¬ëŸ¼ + ì‚­ì œ ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€
    cols_order = [
        "ì‹œê°„",
        "ID",
        "í’ˆë²ˆ",
        "í’ˆëª…",
        "ë¡œíŠ¸ë²ˆí˜¸",
        "í†µë²ˆí˜¸",
        "ë³€ê²½ ì „ ìš©ëŸ‰",
        "ë³€ê²½ í›„ ìš©ëŸ‰",
        "ë³€í™”ëŸ‰",
        "ë³€ê²½ ì „ ìœ„ì¹˜",
        "ë³€ê²½ í›„ ìœ„ì¹˜",
    ]
    page_df = page_df[cols_order]

    delete_col = "ì‚­ì œ"
    if delete_col not in page_df.columns:
        page_df[delete_col] = False

    st.caption(
        "â€» 'ì‹œê°„'ê³¼ 'ID'ëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
        "ë‚˜ë¨¸ì§€ ì¹¼ëŸ¼ì€ ìˆ˜ì • ê°€ëŠ¥í•˜ë©°, 'ì‚­ì œ' ì²´í¬ í›„ 'ì„ íƒ í–‰ ì‚­ì œ'ë¥¼ ëˆ„ë¥´ë©´ í•´ë‹¹ í–‰ì´ ì‚­ì œë©ë‹ˆë‹¤."
    )

    edited_page = st.data_editor(
        page_df,
        use_container_width=True,
        disabled=["ì‹œê°„", "ID"],   # ì´ ë‘ ì»¬ëŸ¼ì€ ìˆ˜ì • ë¶ˆê°€
        column_config={
            delete_col: st.column_config.CheckboxColumn("ì‚­ì œ", help="ì‚­ì œí•  í–‰ì— ì²´í¬"),
        },
        key=f"move_log_editor_page_{ss['log_page']}",
    )

    # ê³µí†µ ì €ì¥ í•¨ìˆ˜
    def _save_full_log(df_updated: pd.DataFrame):
        buf = io.BytesIO()
        df_updated.to_csv(buf, index=False, encoding="utf-8-sig")
        ss["move_log_csv_bytes"] = buf.getvalue()
        _load_move_log_core.clear()
        try:
            df_updated.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
        except Exception:
            pass

    col_save, col_delete = st.columns(2)

    # âœ… ë‚´ìš© ìˆ˜ì • ì €ì¥
    with col_save:
        if st.button("ë³€ê²½ ë‚´ìš© ì €ì¥", key="log_save_changes"):
            try:
                df_updated = df.copy()

                if delete_col in edited_page.columns:
                    edited_for_update = edited_page.drop(columns=[delete_col])
                else:
                    edited_for_update = edited_page

                df_updated.update(edited_for_update)
                _save_full_log(df_updated)
                st.success("ì´ë™ ì´ë ¥ ë³€ê²½ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ë³€ê²½ ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # ğŸ—‘ ì„ íƒ í–‰ ì‚­ì œ
    with col_delete:
        if st.button("ì„ íƒ í–‰ ì‚­ì œ", key="log_delete_rows"):
            try:
                if delete_col in edited_page.columns:
                    to_del_idx = edited_page[edited_page[delete_col] == True].index
                else:
                    to_del_idx = []

                if len(to_del_idx) == 0:
                    st.warning("ì‚­ì œí•  í–‰ì„ ë¨¼ì € 'ì‚­ì œ' ì¹¼ëŸ¼ì— ì²´í¬í•´ ì£¼ì„¸ìš”.")
                else:
                    df_updated = df.drop(index=to_del_idx)
                    _save_full_log(df_updated)
                    st.success(f"ì´ {len(to_del_idx)}ê°œ í–‰ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
            except Exception as e:
                st.error(f"í–‰ì„ ì‚­ì œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ==============================
# íƒ­ 5: ë°ì´í„° íŒŒì¼ ê´€ë¦¬ (ë©”ì¸ íƒ­ ì¤‘ ë°ì´í„° íƒ­)
# ==============================
def file_status(sess_key: str, path: str) -> str:
    ss = st.session_state
    if sess_key in ss:
        return "ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš© ì¤‘"
    if os.path.exists(path):
        return f"ë¡œì»¬ íŒŒì¼ ì‚¬ìš© ì¤‘ ({path})"
    return "íŒŒì¼ ì—†ìŒ"


def render_tab_data():
    ss = st.session_state
    st.markdown("### ğŸ“ ë°ì´í„° íŒŒì¼ ê´€ë¦¬")
    st.write(
        "í•„ìš”í•  ë•Œë§ˆë‹¤ ì•„ë˜ì—ì„œ CSV/ì—‘ì…€ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì„œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ì—…ë¡œë“œí•˜ë©´ **í˜„ì¬ ì„¸ì…˜ì—ì„œ ë°”ë¡œ ë°˜ì˜**ë©ë‹ˆë‹¤."
    )

    # --- bulk_drums_extended.csv ---
    with st.expander("1) bulk_drums_extended.csv (ë©”ì¸ ë²Œí¬ CSV)", expanded=True):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("bulk_csv_bytes", CSV_PATH))
        bulk_file = st.file_uploader(
            "ìƒˆ bulk_drums_extended.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_bulk",
        )
        # ğŸ”½ ì‹¤ì œ íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ ìº¡ì…˜
        st.caption(last_upload_caption(CSV_PATH))

        if st.button("ì´ íŒŒì¼ë¡œ bulk CSV êµì²´", key="apply_bulk"):
            if bulk_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = bulk_file.read()
                ss["bulk_csv_bytes"] = data
                _load_drums_core.clear()
                try:
                    df_tmp = _load_drums_core(data)
                    df_tmp.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                st.success("bulk_drums_extended.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- production.xlsx ---
    with st.expander("2) production.xlsx (ìì‚¬ ì‘ì—…ë²ˆí˜¸)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("prod_xlsx_bytes", PRODUCTION_FILE))
        prod_file = st.file_uploader(
            "ìƒˆ production.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_prod",
        )
        st.caption(last_upload_caption(PRODUCTION_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ production êµì²´", key="apply_prod"):
            if prod_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = prod_file.read()
                ss["prod_xlsx_bytes"] = data
                _load_production_core.clear()
                try:
                    df_tmp = _load_production_core(data)
                    df_tmp.to_excel(PRODUCTION_FILE, index=False)
                except Exception:
                    pass
                st.success("production.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- receive.xlsx ---
    with st.expander("3) receive.xlsx (ì‚¬ê¸‰ ì…í•˜ë²ˆí˜¸)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("recv_xlsx_bytes", RECEIVE_FILE))
        recv_file = st.file_uploader(
            "ìƒˆ receive.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_recv",
        )
        st.caption(last_upload_caption(RECEIVE_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ receive êµì²´", key="apply_recv"):
            if recv_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = recv_file.read()
                ss["recv_xlsx_bytes"] = data
                _load_receive_core.clear()
                try:
                    df_tmp = _load_receive_core(data)
                    df_tmp.to_excel(RECEIVE_FILE, index=False)
                except Exception:
                    pass
                st.success("receive.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- stock.xlsx ---
    with st.expander("4) stock.xlsx (ì „ì‚° ì¬ê³ )", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("stock_xlsx_bytes", STOCK_FILE))
        stock_file = st.file_uploader(
            "ìƒˆ stock.xlsx ì—…ë¡œë“œ",
            type=["xlsx"],
            key="data_up_stock",
        )
        st.caption(last_upload_caption(STOCK_FILE))

        if st.button("ì´ íŒŒì¼ë¡œ stock êµì²´", key="apply_stock"):
            if stock_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = stock_file.read()
                ss["stock_xlsx_bytes"] = data
                _load_stock_core.clear()
                try:
                    df_tmp = _load_stock_core(data)
                    df_tmp.to_excel(STOCK_FILE, index=False)
                except Exception:
                    pass
                st.success("stock.xlsxê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- bulk_move_log.csv ---
    with st.expander("5) bulk_move_log.csv (ì´ë™ ì´ë ¥, ì„ íƒ)", expanded=False):
        st.write("í˜„ì¬ ìƒíƒœ:", file_status("move_log_csv_bytes", MOVE_LOG_CSV))
        move_file = st.file_uploader(
            "ìƒˆ bulk_move_log.csv ì—…ë¡œë“œ (csv)",
            type=["csv"],
            key="data_up_move",
        )
        st.caption(last_upload_caption(MOVE_LOG_CSV))

        if st.button("ì´ íŒŒì¼ë¡œ ì´ë™ ì´ë ¥ êµì²´", key="apply_move"):
            if move_file is None:
                st.warning("ë¨¼ì € íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                data = move_file.read()
                ss["move_log_csv_bytes"] = data
                _load_move_log_core.clear()
                try:
                    df_tmp = _load_move_log_core(data)
                    df_tmp.to_csv(MOVE_LOG_CSV, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                st.success("bulk_move_log.csvê°€ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.caption(
        "â€» Cloudì—ì„œëŠ” ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ë©´ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. "
        "ì¤‘ìš”í•œ ë³€ê²½ ë‚´ìš©ì€ ì‚¬ì´ë“œë°”ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ìœ¼ë¡œ CSVë¥¼ ì €ì¥í•´ ë‘ì„¸ìš”."
    )



# ==============================
# ë©”ì¸
# ==============================
def main():
    ss = st.session_state

    # 1) ë¡œê·¸ì¸ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë¡œê·¸ì¸ í™”ë©´ë§Œ í‘œì‹œ
    if "user_id" not in ss or "user_name" not in ss:
        render_login()
        return

    # 2) í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ì¤€ë¹„ ì—¬ë¶€ í™•ì¸
    files_ready = (
        ("bulk_csv_bytes" in ss or os.path.exists(CSV_PATH))
        and ("prod_xlsx_bytes" in ss or os.path.exists(PRODUCTION_FILE))
        and ("recv_xlsx_bytes" in ss or os.path.exists(RECEIVE_FILE))
        and ("stock_xlsx_bytes" in ss or os.path.exists(STOCK_FILE))
    )

    # data_initialized í”Œë˜ê·¸ê°€ ì—†ê³ , í•„ìˆ˜ íŒŒì¼ë„ ì—†ìœ¼ë©´ ìµœì´ˆ ì—…ë¡œë“œ í™”ë©´
    if not ss.get("data_initialized", False) and not files_ready:
        bulk_file = st.file_uploader("1) bulk_drums_extended.csv (í•„ìˆ˜)", type=["csv"])
        st.caption(last_upload_caption(CSV_PATH))

        prod_file = st.file_uploader("2) production.xlsx (í•„ìˆ˜)", type=["xlsx"])
        st.caption(last_upload_caption(PRODUCTION_FILE))

        recv_file = st.file_uploader("3) receive.xlsx (í•„ìˆ˜)", type=["xlsx"])
        st.caption(last_upload_caption(RECEIVE_FILE))

        stock_file = st.file_uploader("4) stock.xlsx (í•„ìˆ˜)", type=["xlsx"])
        st.caption(last_upload_caption(STOCK_FILE))

        move_file = st.file_uploader("5) bulk_move_log.csv (ì„ íƒ)", type=["csv"])
        st.caption(last_upload_caption(MOVE_LOG_CSV))

        return

    # 3) ì‚¬ì´ë“œë°”: ì‚¬ìš©ì ì •ë³´ + ë¡œê·¸ì•„ì›ƒ + (ì„ íƒ) CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    with st.sidebar:
        st.markdown(f"**ì‚¬ìš©ì:** {ss['user_name']} ({ss['user_id']})")
        if st.button("ë¡œê·¸ì•„ì›ƒ", key="logout_btn"):
            for k in ["user_id", "user_name"]:
                if k in st.session_state:
                    del st.session_state[k]
            st.rerun()

        # í˜„ì¬ ì„¸ì…˜ì˜ bulk/move_logë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆê²Œ
        if "bulk_csv_bytes" in ss:
            st.download_button(
                "í˜„ì¬ bulk CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["bulk_csv_bytes"],
                file_name="bulk_drums_extended_current.csv",
                mime="text/csv",
            )
        if "move_log_csv_bytes" in ss:
            st.download_button(
                "ì´ë™ ì´ë ¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=ss["move_log_csv_bytes"],
                file_name="bulk_move_log_current.csv",
                mime="text/csv",
            )

    st.title("ğŸ­ ë²Œí¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")

    tab_move, tab_lookup, tab_map, tab_log, tab_data = st.tabs(
        ["ğŸ“¦ ì´ë™", "ğŸ” ì¡°íšŒ", "ğŸ—º ì§€ë„", "ğŸ“œ ì´ë™ ì´ë ¥", "ğŸ“ ë°ì´í„°"]
    )

    with tab_move:
        render_tab_move()
    with tab_lookup:
        render_tab_lookup()
    with tab_map:
        render_tab_map()
    with tab_log:
        render_tab_move_log()
    with tab_data:
        render_tab_data()


if __name__ == "__main__":
    main()
